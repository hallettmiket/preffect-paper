{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make NB distributions of expression\n",
    "\n",
    "# testing ideas\n",
    "from scipy.stats import nbinom\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix, csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many samples to generate\n",
    "patients_to_generate = 10000\n",
    "genes_to_generate = 10000\n",
    "\n",
    "# balance between batches\n",
    "# set to 0 or 1 if you want one batch\n",
    "batch_balance = 0\n",
    "\n",
    "# other parameters\n",
    "# whether or not to draw distributions when generating simulated genes\n",
    "# note that there's no limitations to this; if you're creating 10000 genes it'll draw 10000 plots so be mindful\n",
    "draw_NB_data = False\n",
    "\n",
    "# Create gene-gene and/or sample-sample edges by duplicating rows/columns (with a small amount of added variation\n",
    "copy_neighbors = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function copies the indicated column and duplicates it with +1 to counts randomly distributed across it\n",
    "# this creates gene-gene/sample-sample edges (actual correlations occurring in the simulated data is extrememly unlikely)\n",
    "\n",
    "def copy_and_randomly_increment_neighbors(arr, col_index, samples=False):\n",
    "    '''\n",
    "    Create gene/gene or sample/sample edge by duplicating row or column (with random +1 to give variability)\n",
    "    Edges don't naturally occur because distributions are completely random, so we need this function\n",
    "    arr - pandas data frame of expression counts\n",
    "    col_index - what column will be duplicated\n",
    "    samples - whether we duplicate a gene (False) or a sample (True)\n",
    "\n",
    "    '''\n",
    "    # flip array if we want to duplicate a sample, otherwise duplicate a gene\n",
    "    if (samples is True):\n",
    "        data = arr.T\n",
    "    else:\n",
    "        data = arr\n",
    "\n",
    "    nrows = data.shape[0]  \n",
    "\n",
    "    col_index = int(np.round(col_index,0))\n",
    "    \n",
    "    # Determine which neighbor column to copy based on the column index\n",
    "    # First Column\n",
    "    if col_index == 0:\n",
    "        neighbor_col = data[:, col_index + 1]\n",
    "    # Last Column\n",
    "    elif col_index == data.shape[1] - 1:\n",
    "        neighbor_col = data[:, col_index - 1]\n",
    "    # All middle columns\n",
    "    else:\n",
    "        neighbor_col = data[:, col_index - 1] if random.choice([True, False]) else data[:, col_index + 1]\n",
    "    \n",
    "    # Copy the neighbor column into the target column\n",
    "    data[:, col_index] = neighbor_col\n",
    "    \n",
    "    # Randomly decide to increment the value by 1 for each row in the column\n",
    "    for row in range(nrows):\n",
    "        if random.choice([True, False]):\n",
    "            data[row, col_index] += 1\n",
    "    \n",
    "    if (samples is True):\n",
    "        return data.T\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this version of the code, I want to create a distribution to \"pull\" our NB Mu parameters from\n",
    "# we discussed log-normal\n",
    "mu_pull_dist_1 = 3 * 10\n",
    "mu_pull_dist_2 = 4 * 10\n",
    "\n",
    "mus_use = str(mu_pull_dist_1) + \"_\" + str(mu_pull_dist_2)\n",
    "\n",
    "sigma1 = 0.6  # standard deviation of the logarithm of the batch 1 distribution\n",
    "sigma2 = 0.2  # standard deviation of the logarithm of the batch 2 distribution\n",
    "\n",
    "# Generate a sample from the log-normal distribution\n",
    "# Generate samples for both distributions\n",
    "sample_size = patients_to_generate*100 # multiplication ensures a varied number of possible values\n",
    "samples1 = np.random.lognormal(mean=mu_pull_dist_1, sigma=sigma1, size=sample_size)\n",
    "samples2 = np.random.lognormal(mean=mu_pull_dist_2, sigma=sigma2, size=sample_size)\n",
    "\n",
    "samples1_rounded = np.round(samples1, 6)\n",
    "samples2_rounded = np.round(samples2, 6)\n",
    "\n",
    "print(min(samples1_rounded))\n",
    "\n",
    "# Plotting the samples\n",
    "plt.hist(samples1_rounded, bins=100, density=True, alpha=0.5, color='blue', label=f'Log-normal with $\\mu={mu_pull_dist_1}$')\n",
    "plt.hist(samples2_rounded, bins=100, density=True, alpha=0.5, color='orange', label=f'Log-normal with $\\mu={mu_pull_dist_2}$')\n",
    "plt.title('Selection of Mu between \"batches\"')\n",
    "plt.xlabel('Mu')\n",
    "plt.ylabel('Density')\n",
    "#plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now, theta will be simple, both batch 1 and batch 2 will have the same parameters\n",
    "# will likely make this more complex in the future\n",
    "theta_pull_dist_1 = theta_pull_dist_2 = 1 # will try 1, 2, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container for simulated data\n",
    "train_data, valid_data, gene_names = [], [], []\n",
    "gene_mu1, gene_var1, gene_mu2, gene_var2 = [], [], [], []\n",
    "\n",
    "# we have to sample from both log normals outside of the loop so that we can ensure replacement\n",
    "sampled_mus_batch1 = np.random.choice(samples1_rounded, size=genes_to_generate, replace=False)\n",
    "sampled_mus_batch2 = np.random.choice(samples2_rounded, size=genes_to_generate, replace=False)\n",
    "\n",
    "\n",
    "# Bernouli trial idea didn't work out\n",
    "# This way, all samples will get the same mu, not a partial amount\n",
    "samples_indices = np.random.binomial(n=1, p=batch_balance, size=patients_to_generate)\n",
    "\n",
    "for i in range(genes_to_generate):\n",
    "    # so we compute the p and n parameters for each batch using their respective Mu/thetas\n",
    "    mu_batch1 = sampled_mus_batch1[i]\n",
    "    var_batch1 = mu_batch1 + (mu_batch1**2 / theta_pull_dist_1)\n",
    "    n_batch1 = mu_batch1**2 / (var_batch1 - mu_batch1)\n",
    "    p_batch1 = n_batch1 / (n_batch1 + mu_batch1)\n",
    "\n",
    "    mu_batch2 = sampled_mus_batch2[i]\n",
    "    var_batch2 = mu_batch2 + (mu_batch2**2 / theta_pull_dist_2)\n",
    "    n_batch2 = mu_batch2**2 / (var_batch2 - mu_batch2)\n",
    "    p_batch2 = n_batch2 / (n_batch2 + mu_batch2)\n",
    "\n",
    "    # we then sample M (patients) values from both NBs\n",
    "    counts_batch1 = nbinom.rvs(n_batch1, p_batch1, size=patients_to_generate)\n",
    "    counts_batch2 = nbinom.rvs(n_batch2, p_batch2, size=patients_to_generate)\n",
    "\n",
    "    # and we use the Bernouli to select from which NB distribution do we take values from\n",
    "    selected_data_train = np.where(samples_indices == 0, counts_batch1, counts_batch2)\n",
    "    \n",
    "    # append it to a list of gene expression values\n",
    "    train_data.append(selected_data_train)  \n",
    "\n",
    "    # repeat for validation\n",
    "    counts_batch3 = nbinom.rvs(n_batch1, p_batch1, size=patients_to_generate)\n",
    "    counts_batch4 = nbinom.rvs(n_batch2, p_batch2, size=patients_to_generate)\n",
    "\n",
    "    # and we use the Bernouli to select from which NB distribution do we take values from\n",
    "    selected_data_val = np.where(samples_indices == 0, counts_batch3, counts_batch4)\n",
    "    \n",
    "    # append it to a list of gene expression values\n",
    "    valid_data.append(selected_data_val)  \n",
    "\n",
    "    # Saving Mus/Thetas; to be placed in the AnnData 'var' table\n",
    "    gene_mu1.append(mu_batch1)\n",
    "    gene_var1.append(theta_pull_dist_1)\n",
    "    gene_mu2.append(mu_batch2)\n",
    "    gene_var2.append(theta_pull_dist_2)\n",
    "\n",
    "    # Creating a unique gene name\n",
    "    gene_name = \"Gene_\" + str(i + 1)\n",
    "    gene_names.append(gene_name)\n",
    "\n",
    "    # draw expression selected out if desired\n",
    "    title = \"Expression for Gene \" + str(i + 1)\n",
    "\n",
    "    minval1 = min(counts_batch1)\n",
    "    minval3 = min(counts_batch3)\n",
    "    \n",
    "    #if (minval1 < 10) or (minval3 < 10):\n",
    "    #    print(minval1, minval3)\n",
    "\n",
    "    if (draw_NB_data is True):\n",
    "        plt.hist(selected_data_train, bins=50, color=\"blue\")\n",
    "        plt.xlabel(\"Expression\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(samples_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we have to save these results as an AnnData table with batch in the obs\n",
    "# training data\n",
    "\n",
    "# append genes into a single matrix, and transpose so rows are samples and not rows\n",
    "all_counts = np.array(train_data)\n",
    "counts_in_anndata_orientation = np.transpose(all_counts)\n",
    "\n",
    "# if we want, this forcing edges in gene/gene | sample/sample index by copying over its neighboring entry\n",
    "# samples = True means we create a sample/sample edge, otherwise gene/gene\n",
    "if (copy_neighbors == True):\n",
    "    copy_and_randomly_increment_neighbors(train_data, patients_to_generate/10, samples=True)\n",
    "    copy_and_randomly_increment_neighbors(train_data, patients_to_generate/9, samples=True)\n",
    "    copy_and_randomly_increment_neighbors(train_data, patients_to_generate/8, samples=True)\n",
    "    copy_and_randomly_increment_neighbors(train_data, genes_to_generate/7, samples=False)\n",
    "    copy_and_randomly_increment_neighbors(train_data, genes_to_generate/6, samples=False)\n",
    "    copy_and_randomly_increment_neighbors(train_data, genes_to_generate/5, samples=False)\n",
    "\n",
    "adata = ad.AnnData(X=counts_in_anndata_orientation, var=pd.DataFrame(index=gene_names), dtype=np.int64)\n",
    "\n",
    "# make batch labels\n",
    "#batch_labels = ['1'] * size_batch1 + ['2'] * size_batch2  # Adjust according to your data structure\n",
    "adata.obs['batch'] = samples_indices\n",
    "\n",
    "# add gene names to var\n",
    "adata.var['gene'] = gene_names\n",
    "adata.var['mu_batch1'] = gene_mu1\n",
    "adata.var['theta_batch1'] = gene_var1\n",
    "adata.var['mu_batch2'] = gene_mu2\n",
    "adata.var['theta_batch2'] = gene_var2\n",
    "\n",
    "\n",
    "# I still need to generate the gene_gene and sample_sample adjacency matrix!\n",
    "# gene/gene\n",
    "#df = pd.DataFrame(adata.X, columns=adata.var_names)\n",
    "#df_sqrt = df.applymap(lambda x: x**0.5 if x >= 0 else x) # shouldn't ever be negative\n",
    "\n",
    "# we no longer create a gene/gene matrix for the simple data\n",
    "#gene_correlation_matrix = df_sqrt.corr()\n",
    "#gene_gene_adj = (gene_correlation_matrix.abs() > 0.6).astype(int)\n",
    "#np.fill_diagonal(gene_gene_adj.values, 1) # diagonal has been 1s in our other data\n",
    "\n",
    "# sample/sample\n",
    "#df_transposed = pd.DataFrame(adata.X.T, columns=adata.obs_names, index=adata.var_names)\n",
    "#df_transposed_sqrt = df_transposed.applymap(lambda x: x**0.5 if x >= 0 else x) # shouldn't ever be negative\n",
    "# Compute the Pearson correlation matrix between samples\n",
    "#correlation_matrix_samples = df_transposed_sqrt.corr()\n",
    "\n",
    "#sample_sample_adj = (correlation_matrix_samples.abs() > 0.6).astype(int)\n",
    "\n",
    "# Optionally, remove self-loops (sample correlated with itself)\n",
    "#np.fill_diagonal(sample_sample_adj.values, 1)\n",
    "\n",
    "# Count the number of 1s in the adjacency matrix\n",
    "#num_ones_samples = np.sum(sample_sample_adj.values)\n",
    "\n",
    "# and the adjacency tables need to be 'coo'\n",
    "#sample_sample_adj_coo = csc_matrix(sample_sample_adj)\n",
    "#adata.obsm['sample_sample_adj'] = sample_sample_adj_coo\n",
    "\n",
    "# gene_gene_adj_coo = csc_matrix(gene_gene_adj)\n",
    "# adata.varm['gene_gene_adj'] = gene_gene_adj_coo\n",
    "\n",
    "\n",
    "# and lets save the data\n",
    "file_path = '/path/to/output/simulated_simple_' + str(patients_to_generate) + '_' + str(genes_to_generate) + '_theta_' + str(theta_pull_dist_1) + '_muselect' + mus_use + '_batch_balance_' + str(batch_balance) + '.test1.tau_1.h5ad'\n",
    "\n",
    "# Save the AnnData object\n",
    "adata.write(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for validation data\n",
    "all_counts = np.array(valid_data)\n",
    "counts_in_anndata_orientation = np.transpose(all_counts)\n",
    "\n",
    "adata_val = ad.AnnData(X=counts_in_anndata_orientation, var=pd.DataFrame(index=gene_names), dtype=np.int64)\n",
    "\n",
    "# make batch labels\n",
    "#batch_labels = ['1'] * size_batch1 + ['2'] * size_batch2  # Adjust according to your data structure\n",
    "adata_val.obs['batch'] = samples_indices\n",
    "\n",
    "# add gene names to var\n",
    "adata_val.var['gene'] = gene_names\n",
    "adata_val.var['mu_batch1'] = gene_mu1\n",
    "adata_val.var['theta_batch1'] = gene_var1\n",
    "adata_val.var['mu_batch2'] = gene_mu2\n",
    "adata_val.var['theta_batch2'] = gene_var2\n",
    "\n",
    "# and lets save the data\n",
    "file_path = '/path/to/output/simulated_simple_' + str(patients_to_generate) + '_' + str(genes_to_generate) + '_theta_' + str(theta_pull_dist_1) + '_muselect' + mus_use + '_batch_balance_' + str(batch_balance) + '.test2.tau_1.h5ad'\n",
    "\n",
    "# Save the AnnData object\n",
    "adata_val.write(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw library size information distrubtions\n",
    "library_sizes = np.log(adata_val.X.sum(axis=1))\n",
    "\n",
    "batches = adata_val.obs['batch']\n",
    "library_sizes_batch1 = library_sizes[batches == 0]\n",
    "library_sizes_batch2 = library_sizes[batches == 1]\n",
    "\n",
    "# Plotting the samples\n",
    "#plt.hist(library_sizes, bins=50, density=True, alpha=0.5, color='blue', label=f'Library Size [all samples]')\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(library_sizes_batch1, bins=50, density=True, alpha=0.5, color='blue', label='Library Size [Batch 1]')\n",
    "plt.hist(library_sizes_batch2, bins=50, density=True, alpha=0.5, color='orange', label='Library Size [Batch 2]')\n",
    "plt.title('Library Size of Simulated Samples Between Each Batch')\n",
    "plt.xlabel('Log Library Size (Log of Total Counts)')\n",
    "plt.ylabel('Density')\n",
    "# plt.yscale('log')  # Use a log scale for the y-axis\n",
    "#plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# you can clearly see the difference caused by the two Mus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffpe_env_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
