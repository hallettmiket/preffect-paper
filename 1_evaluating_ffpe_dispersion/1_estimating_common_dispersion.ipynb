{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af75e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EJM Script\n",
    "# I am rusty with Python, so the first thing I want to do is to import the data we need\n",
    "\n",
    "# first lets read in scipy, as I'll need the \"curve_fit\" function in optimize\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "from scipy.special import psi\n",
    "from scipy.special import factorial\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import poisson\n",
    "from scipy.special import comb\n",
    "import math\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# now the DCIS count data is found in an RDA file, which we apparently read using 'pyreadr'\n",
    "\n",
    "import pyreadr\n",
    "\n",
    "\n",
    "# and a function I use in the document\n",
    "def variance_mean(row):\n",
    "    variance = np.var(row, ddof=1) # “Delta Degrees of Freedom”\n",
    "    mean = np.mean(row)\n",
    "    std_dev = np.sqrt(variance) # sometimes this is considered dispersion\n",
    "    \n",
    "    # the formula given is Variance = mean + dispersion*mean^2\n",
    "    # re-arranged, this gives dispersion = (variance - mean)/(mean*mean)\n",
    "    dispersion = 0 # in case the mean is zero, or if variance = mean\n",
    "    if ((mean != 0) & (variance != mean)):\n",
    "        #dispersion = (variance - mean)/(mean**2)\n",
    "        dispersion = (mean**2)/(variance - mean) # did I have this backwards?\n",
    "        inverse_dispersion = dispersion**-1\n",
    "    \n",
    "    # and they define \"expected fraction zeros\" as exp(-mean) - Poisson distribution!\n",
    "    #prob_frac = math.exp(mean*-1)\n",
    "    \n",
    "    # lets do the NB formulation\n",
    "    prob_frac = 1 # if dispersion is zero, the fraction zero is 100%\n",
    "    if (dispersion >0):\n",
    "        prob_frac = ((inverse_dispersion)/(mean + inverse_dispersion))**(inverse_dispersion)\n",
    "    \n",
    "    # we will also want to know the fraction of the row that equals zero\n",
    "    zero_frac = (row == 0).sum()/len(row)\n",
    "    return pd.Series({'variance': variance, 'mean': mean, \"StDev\": std_dev, \"Dispersion\": dispersion, 'zero_fraction': zero_frac, 'prob_frac': prob_frac})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed121c2d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21998db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_mean(row):\n",
    "    variance = np.var(row, ddof=1)\n",
    "    mean = np.mean(row)\n",
    "    std_dev = np.sqrt(variance) # sometimes this is considered dispersion\n",
    "    \n",
    "    dispersion = 0 # in case the mean is zero, or if variance = mean\n",
    "    if ((mean != 0) & (variance != mean)):\n",
    "        #dispersion = (variance - mean)/(mean**2)\n",
    "        dispersion = (mean**2)/(variance - mean) # did I have this backwards?\n",
    "        inverse_dispersion = dispersion**-1\n",
    "    \n",
    "    # and they define \"expected fraction zeros\" as exp(-mean) - Poisson distribution!\n",
    "    #prob_frac = math.exp(mean*-1)\n",
    "    \n",
    "    # lets do the NB formulation\n",
    "    prob_frac = 1 # if dispersion is zero, the fraction zero is 100%\n",
    "    if (dispersion >0):\n",
    "        prob_frac = ((inverse_dispersion)/(mean + inverse_dispersion))**(inverse_dispersion)\n",
    "    \n",
    "    # we will also want to know the fraction of the row that equals zero\n",
    "    zero_frac = (row == 0).sum()/len(row)\n",
    "    return pd.Series({'variance': variance, 'mean': mean, \"StDev\": std_dev, \"Dispersion\": dispersion, 'zero_fraction': zero_frac, 'prob_frac': prob_frac})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = pyreadr.read_r('/path/to/expression_counts.Jan2023_1_2_and_2_2.rds')\n",
    "vst_norm = pyreadr.read_r('/path/to/expression_VST_Normalized.Jan2023_1_2_and_2_2.rds')\n",
    "\n",
    "# this data is loading without issue\n",
    "ship_data = pyreadr.read_r('/path/to/ship1_2_full_tbl.Jan2023.With_Stroma_Assignment.rds')\n",
    "# I wish that we could've simply used the RDA, but the counts-only RDS works and loads faster so what can you do\n",
    "# in the future, could try the package 'rpy2' instead, it's an alternative that requires R but that's okay for us\n",
    "\n",
    "# to do: import Ensemble to Refseq gene name conversion table to fix that\n",
    "gene_convert = pyreadr.read_r('/path/to/ensemble_to_refseq_gene_name_table.rds')\n",
    "\n",
    "\n",
    "\n",
    "# now we want to isolate just the expression from a particular type of tissue\n",
    "\n",
    "df = all_counts[None] # load all_counts into a pandas data frame\n",
    "\n",
    "# Eliminate any samples in the blacklist\n",
    "ship_df = ship_data[None]\n",
    "#print(ship_df['blacklist'].value_counts()) # they're all false\n",
    "\n",
    "# since ship_data already has patients filtered out, lets filter out any patient who isn't on the list\n",
    "# match by 'sample_name'\n",
    "df_blacklist_filtered = df[ship_df['sample_name']]\n",
    "\n",
    "# split the patients by tissue\n",
    "count_DCIS = df_blacklist_filtered.filter(like='_D')\n",
    "count_STROMA = df_blacklist_filtered.filter(like='_S')\n",
    "count_NORMAL = df_blacklist_filtered.filter(like='_N')\n",
    "# we will perform all our work from this point on with Normal tissues for now\n",
    "\n",
    "# I also want gene_convert to be a pandas data frame\n",
    "gene_convert = gene_convert[None]\n",
    "\n",
    "\n",
    "print(count_DCIS.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1dc4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to add a new count table, averaged by the number of reads in the entire sample\n",
    "column_sums = np.sum(count_NORMAL, axis=0)\n",
    "\n",
    "# Divide each element by the column sum\n",
    "count_NORMAL_libsizeadjust = count_NORMAL / column_sums\n",
    "\n",
    "column_sums = np.sum(count_STROMA, axis=0)\n",
    "count_STROMA_libsizeadjust = count_STROMA / column_sums\n",
    "\n",
    "\n",
    "column_sums = np.sum(count_DCIS, axis=0)\n",
    "count_DCIS_libsizeadjust = count_DCIS / column_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to filter out any genes that were eliminated when we did VST normalization\n",
    "vst_table = vst_norm[None] # we don't apply this anymore because it blocks any gene with >80% frac_zero\n",
    "filtered_count = count_NORMAL[count_NORMAL.index.isin(vst_table.index)]\n",
    "\n",
    "#print(filtered_count) # looks like it worked, rows reduced to 23203 as expected\n",
    "\n",
    "# converting Ensemble names to gene name\n",
    "#count_NORMAL = filtered_count.rename(index=dict(zip(gene_convert[\"gene_id\"], gene_convert[\"gene_name\"])))\n",
    "\n",
    "# removed filter from VST, I realize now it removed anything with >80% fraction zero\n",
    "# thus it isn't a strong representation of the data\n",
    "count_NORMAL = count_NORMAL.rename(index=dict(zip(gene_convert[\"gene_id\"], gene_convert[\"gene_name\"])))\n",
    "#print(count_NORMAL)\n",
    "\n",
    "# we should filter out anything that is an Ensemble ID, so anything that starts \"ENSG0\"\n",
    "pattern = '^ENSG0'\n",
    "count_NORMAL = count_NORMAL[~count_NORMAL.index.str.match(pattern)]\n",
    "\n",
    "# I found rounding makes a difference in the plots, shifting it slightly right\n",
    "#count_NORMAL = count_NORMAL.round(0)\n",
    "#print(count_NORMAL)\n",
    "\n",
    "count_NORMAL_libsizeadjust = count_NORMAL_libsizeadjust.rename(index=dict(zip(gene_convert[\"gene_id\"], gene_convert[\"gene_name\"])))\n",
    "#print(count_NORMAL)\n",
    "\n",
    "# we should filter out anything that is an Ensemble ID, so anything that starts \"ENSG0\"\n",
    "count_NORMAL_libsizeadjust = count_NORMAL_libsizeadjust[~count_NORMAL_libsizeadjust.index.str.match(pattern)]\n",
    "\n",
    "#print(count_NORMAL_libsizeadjust)\n",
    "\n",
    "count_STROMA = count_STROMA.rename(index=dict(zip(gene_convert[\"gene_id\"], gene_convert[\"gene_name\"])))\n",
    "count_STROMA = count_STROMA[~count_STROMA.index.str.match(pattern)]\n",
    "\n",
    "count_DCIS = count_DCIS.rename(index=dict(zip(gene_convert[\"gene_id\"], gene_convert[\"gene_name\"])))\n",
    "count_DCIS = count_DCIS[~count_DCIS.index.str.match(pattern)]\n",
    "\n",
    "\n",
    "count_STROMA_libsizeadjust = count_STROMA_libsizeadjust.rename(index=dict(zip(gene_convert[\"gene_id\"], gene_convert[\"gene_name\"])))\n",
    "count_STROMA_libsizeadjust = count_STROMA_libsizeadjust[~count_STROMA_libsizeadjust.index.str.match(pattern)]\n",
    "count_DCIS_libsizeadjust = count_DCIS_libsizeadjust.rename(index=dict(zip(gene_convert[\"gene_id\"], gene_convert[\"gene_name\"])))\n",
    "count_DCIS_libsizeadjust = count_DCIS_libsizeadjust[~count_DCIS_libsizeadjust.index.str.match(pattern)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6395c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have a table of just normal counts, with proper gene names, and Ensemble-only genes removed\n",
    "# now we should be able to actually start computing things!\n",
    "\n",
    "# lets make a function\n",
    "# Later information - this turns out to be for the Poisson distribution!\n",
    "# need to figure out how to do expected NB!\n",
    "def variance_mean(row):\n",
    "    variance = np.var(row, ddof=1)\n",
    "    mean = np.mean(row)\n",
    "    std_dev = np.sqrt(variance) # sometimes this is considered dispersion\n",
    "    \n",
    "    # I'm a bit confused exactly how I'd compute a dataset-wide dispersion from this data\n",
    "    # the formula given is Variance = mean + dispersion*mean^2\n",
    "    # re-arranged, this gives dispersion = (variance - mean)/(mean*mean)\n",
    "    # I guess we can try it\n",
    "    dispersion = 0 # in case the mean is zero\n",
    "    inverse_dispersion = 0\n",
    "    if ((mean != 0) & (variance != mean)):\n",
    "        #dispersion = (variance - mean)/(mean**2)\n",
    "        dispersion = (mean**2)/(variance - mean) # did I have this backwards?\n",
    "        inverse_dispersion = dispersion**(-1)\n",
    "    \n",
    "    # and they define \"expected fraction zeros\" as exp(-mean) - Poisson distribution!\n",
    "    #prob_frac = math.exp(mean*-1)\n",
    "    \n",
    "    # lets do the NB formulation\n",
    "    prob_frac = 1 # if dispersion is zero, the fraction zero is 100%\n",
    "    if (dispersion >0):\n",
    "        prob_frac = ((inverse_dispersion)/(mean + inverse_dispersion))**(inverse_dispersion)\n",
    "        # another version I found of this calculation\n",
    "        #prob_frac = ((1)/(1 + mean*dispersion))**(inverse_dispersion)\n",
    "    \n",
    "    # we will also want to know the fraction of the row that equals zero\n",
    "    zero_frac = (row == 0).sum()/len(row)\n",
    "    return pd.Series({'variance': variance, 'mean': mean, \"StDev\": std_dev, \"Dispersion\": dispersion, \"Invert_Disp\": inverse_dispersion, 'zero_fraction': zero_frac, 'prob_frac': prob_frac})\n",
    "\n",
    "# apply function along rows axis\n",
    "NORMAL_dispersion = count_NORMAL.apply(variance_mean, axis=1)\n",
    "NORMAL_dispersion_libadj = count_NORMAL_libsizeadjust.apply(variance_mean, axis=1)\n",
    "\n",
    "#print(NORMAL_dispersion)\n",
    "STROMA_dispersion = count_STROMA.apply(variance_mean, axis=1)\n",
    "STROMA_dispersion_libadj = count_STROMA_libsizeadjust.apply(variance_mean, axis=1)\n",
    "\n",
    "DCIS_dispersion = count_DCIS.apply(variance_mean, axis=1)\n",
    "DCIS_dispersion_libadj = count_DCIS_libsizeadjust.apply(variance_mean, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7683a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DCIS_dispersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3512b9a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many genes had 0 counts across the board for normals: 2383\n",
    "#print(NORMAL_dispersion[NORMAL_dispersion['zero_fraction'] > 0.99])\n",
    "\n",
    "#info = NORMAL_dispersion[NORMAL_dispersion['zero_fraction'] > 0.99]\n",
    "\n",
    "#if (info['mean'] > 100).any():\n",
    "#    print(info.loc[info['mean'] > 100])\n",
    "prob_over_zero = NORMAL_dispersion['prob_frac'] < 1\n",
    "probe_over_zero_filt = NORMAL_dispersion[prob_over_zero]\n",
    "print(probe_over_zero_filt.nlargest(100, 'prob_frac'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# they then used curve_fit in scipy.optimize to make the curves in Figure 1, lets try it\n",
    "\n",
    "# we need a curve function for the plot; this is from an example, I'm not sure if it's the right one yet\n",
    "def poisson_func(x, mu):\n",
    "    return poisson.pmf(prob, mu)\n",
    "\n",
    "# extract 'variance' and 'zero_count' columns\n",
    "ydata = NORMAL_dispersion['zero_fraction']\n",
    "# the \"Dispersion\" calculation based on the formula given in Svensson looks nothing like expected\n",
    "# the StDev (also called the dispersion)\n",
    "xdata = NORMAL_dispersion['StDev'] \n",
    "\n",
    "mean = NORMAL_dispersion['mean']\n",
    "prob = NORMAL_dispersion['prob_frac']\n",
    "\n",
    "\n",
    "# fit curve to data using curve_fit\n",
    "popt, pcov = curve_fit(poisson_func, prob, mean)\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "#plt.plot(xdata, poisson_func(xdata, *popt), 'r-', label='fit: mu=%5.3f' % popt[0])\n",
    "plt.xscale('log')\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Dispersion')\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# made the \"expected\" curve transparent so I could see the data under it\n",
    "# how come the left-most \"expected\" are further left of the \"obsrer\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we plot the probability computed from mean, but plot variance?\n",
    "\n",
    "# extract 'variance' and 'zero_count' columns\n",
    "ydata = NORMAL_dispersion['mean']\n",
    "# the \"Dispersion\" calculation based on the formula given in Svensson looks nothing like expected\n",
    "# the StDev (also called the dispersion)\n",
    "xdata = NORMAL_dispersion['Dispersion'] # standard deviation of the variance\n",
    "\n",
    "\n",
    "prob = NORMAL_dispersion['prob_frac'] # probability of fraction zeros with \n",
    "mean = NORMAL_dispersion['Dispersion'] # StDev \n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "#plt.scatter(mean, prob, alpha=0.02)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Mean')\n",
    "plt.xlabel('Dispersion - Normal')\n",
    "#plt.legend()\n",
    "plt.xlim(0.01, 100)\n",
    "plt.ylim(0, 200000)\n",
    "plt.title(\"DCIS Normal - Mean vs Log(Dispersion)\", fontdict=None, loc='center', pad=None)\n",
    "plt.show()\n",
    "\n",
    "# STROMA\n",
    "ydata = STROMA_dispersion['mean']\n",
    "# the \"Dispersion\" calculation based on the formula given in Svensson looks nothing like expected\n",
    "# the StDev (also called the dispersion)\n",
    "xdata = STROMA_dispersion['Dispersion'] # standard deviation of the variance\n",
    "\n",
    "\n",
    "prob = STROMA_dispersion['prob_frac'] # probability of fraction zeros with \n",
    "mean = STROMA_dispersion['Dispersion'] # StDev \n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "#plt.scatter(mean, prob, alpha=0.02)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Mean')\n",
    "plt.xlabel('Dispersion - Stroma')\n",
    "#plt.legend()\n",
    "plt.xlim(0.01, 100)\n",
    "plt.ylim(0, 200000)\n",
    "plt.title(\"DCIS Stroma - Mean vs Log(Dispersion)\", fontdict=None, loc='center', pad=None)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# DCIS\n",
    "ydata = DCIS_dispersion['mean']\n",
    "# the \"Dispersion\" calculation based on the formula given in Svensson looks nothing like expected\n",
    "# the StDev (also called the dispersion)\n",
    "xdata = DCIS_dispersion['Dispersion'] # standard deviation of the variance\n",
    "\n",
    "prob = DCIS_dispersion['prob_frac'] # probability of fraction zeros with \n",
    "mean = DCIS_dispersion['Dispersion'] # StDev \n",
    "\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "#plt.scatter(mean, prob, alpha=0.02)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Mean')\n",
    "plt.xlabel('Dispersion - DCIS')\n",
    "#plt.legend()\n",
    "plt.xlim(0.01, 100)\n",
    "plt.ylim(0, 200000)\n",
    "plt.title(\"DCIS Tumour - Mean vs Log(Dispersion)\", fontdict=None, loc='center', pad=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f9e656",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# what if we plot mean only with zero fraction\n",
    "\n",
    "# extract 'mean' and 'zero_count' columns\n",
    "ydata = NORMAL_dispersion['zero_fraction']\n",
    "# the \"Dispersion\" calculation based on the formula given in Svensson looks nothing like expected\n",
    "# the StDev (also called the dispersion)\n",
    "xdata = NORMAL_dispersion['mean'] \n",
    "\n",
    "mean = NORMAL_dispersion['mean']\n",
    "prob = NORMAL_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.02)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Fraction Zeroes')\n",
    "plt.xlabel('Mean - Normal')\n",
    "#plt.legend()\n",
    "plt.xlim(0, 1000000)\n",
    "plt.title(\"DCIS Normal - %Zeros vs Log(Mean)\", fontdict=None, loc='center', pad=None)\n",
    "plt.show()\n",
    "\n",
    "# STROMA\n",
    "ydata = STROMA_dispersion['zero_fraction']\n",
    "xdata = STROMA_dispersion['mean'] # standard deviation of the variance\n",
    "\n",
    "\n",
    "prob = STROMA_dispersion['prob_frac'] # probability of fraction zeros with \n",
    "mean = STROMA_dispersion['mean'] # StDev \n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.02)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Fraction Zeroes')\n",
    "plt.xlabel('Mean - Stroma')\n",
    "#plt.legend()\n",
    "plt.xlim(0, 1000000)\n",
    "plt.title(\"DCIS Stroma - %Zeros vs Log(Mean)\", fontdict=None, loc='center', pad=None)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# DCIS\n",
    "ydata = DCIS_dispersion['zero_fraction']\n",
    "# the \"Dispersion\" calculation based on the formula given in Svensson looks nothing like expected\n",
    "# the StDev (also called the dispersion)\n",
    "xdata = DCIS_dispersion['mean'] # standard deviation of the variance\n",
    "\n",
    "count_changes = (xdata > 6183).sum() # seeing how many times this happens\n",
    "print(count_changes)\n",
    "\n",
    "prob = DCIS_dispersion['prob_frac'] # probability of fraction zeros with \n",
    "mean = DCIS_dispersion['mean'] # StDev \n",
    "\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.02)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Fraction Zeroes')\n",
    "plt.xlabel('Mean - DCIS')\n",
    "#plt.legend()\n",
    "plt.xlim(0, 1000000)\n",
    "plt.title(\"DCIS Tumour - % Zeros vs Log(Mean)\", fontdict=None, loc='center', pad=None)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the negative binomial PDF\n",
    "def neg_binom_pdf(k, r, p):\n",
    "    return comb(k + r - 1, k) * p**r * (1 - p)**k\n",
    "\n",
    "ydata = NORMAL_dispersion['zero_fraction']\n",
    "# the \"Dispersion\" calculation based on the formula given in Svensson looks nothing like expected\n",
    "xdata = NORMAL_dispersion['Dispersion'] \n",
    "\n",
    "\n",
    "# Fit the distribution to the data\n",
    "popt, pcov = curve_fit(neg_binom_pdf, xdata, ydata)\n",
    "\n",
    "# Plot the data and fitted distribution\n",
    "plt.plot(xdata, ydata, 'bo', label='data')\n",
    "plt.plot(xdata, neg_binom_pdf(xdata, *popt), 'r-', label='fit', alpha=0.02)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('P(k)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the estimated parameters\n",
    "print('r =', popt[0])\n",
    "print('p =', popt[1])\n",
    "\n",
    "\n",
    "\n",
    "#ydata = NORMAL_dispersion['zero_fraction']\n",
    "# the \"Dispersion\" calculation based on the formula given in Svensson looks nothing like expected\n",
    "# the StDev (also called the dispersion)\n",
    "#xdata = NORMAL_dispersion['Dispersion'] \n",
    "\n",
    "#mean = NORMAL_dispersion['mean']\n",
    "#prob = NORMAL_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "##plt.scatter(xdata, ydata)\n",
    "#plt.scatter(mean, prob)\n",
    "#plt.xscale('log')\n",
    "#plt.ylabel('ZeroFraction')\n",
    "#plt.xlabel('Dispersion')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a673df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map out the distribution of counts across some patients\n",
    "\n",
    "patient1 = count_NORMAL['DCRT_348_Obs_305_N']\n",
    "\n",
    "plt.hist(patient1, range=(0, 2000), bins=2000)\n",
    "plt.yscale('log')\n",
    "# add labels and title\n",
    "plt.xlabel('#Counts')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.title('Histogram of Counts from DCRT_115_Obs_295_N')\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f64ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "patient2 = count_NORMAL['DCRT_116_Obs_338_N']\n",
    "\n",
    "plt.hist(patient2, range=(0, 2000), bins=2000)\n",
    "plt.yscale('log')\n",
    "# add labels and title\n",
    "plt.xlabel('#Counts')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.title('Histogram of Counts from DCRT_116_Obs_338_N')\n",
    "\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52ed74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "patient2 = count_NORMAL['DCRT_116_Obs_338_N']\n",
    "\n",
    "plt.hist(patient2, range=(0, 10), bins=10)\n",
    "#plt.yscale('log')\n",
    "# add labels and title\n",
    "plt.xlabel('#Counts')\n",
    "plt.ylabel('Frequency (no scale)')\n",
    "plt.title('Histogram of Counts from DCRT_116_Obs_338_N')\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cfe10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patient2[patient2 >= -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56234cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alright, lets try to plot the NORMAL_dispersion_libadj mean and fract zeros\n",
    "\n",
    "# extract 'variance' and 'zero_count' columns\n",
    "ydata = NORMAL_dispersion_libadj['zero_fraction']\n",
    "# the \"Dispersion\" calculation based on the formula given in Svensson looks nothing like expected\n",
    "# the StDev (also called the dispersion)\n",
    "xdata = NORMAL_dispersion_libadj['mean'] \n",
    "\n",
    "#mean = NORMAL_dispersion['mean']\n",
    "#prob = NORMAL_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "#plt.scatter(mean, prob, alpha=0.01)\n",
    "#plt.plot(xdata, poisson_func(xdata, *popt), 'r-', label='fit: mu=%5.3f' % popt[0])\n",
    "plt.xscale('log')\n",
    "plt.ylabel('ZeroFraction of Gene')\n",
    "plt.xlabel('Mean of Library-Adjusted Gene Expr - NORMAL')\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# STROMA\n",
    "# extract 'variance' and 'zero_count' columns\n",
    "ydata = STROMA_dispersion_libadj['zero_fraction']\n",
    "xdata = STROMA_dispersion_libadj['mean'] \n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "#plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('ZeroFraction of Gene')\n",
    "plt.xlabel('Mean of Library-Adjusted Gene Expr - STROMA')\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# DCIS\n",
    "# extract 'variance' and 'zero_count' columns\n",
    "ydata = DCIS_dispersion_libadj['zero_fraction']\n",
    "xdata = DCIS_dispersion_libadj['mean'] \n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "#plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('ZeroFraction of Gene')\n",
    "plt.xlabel('Mean of Library-Adjusted Gene Expr - DCIS')\n",
    "#plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972575ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### THIRD PARTY DATASET ###### GSE146889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb853a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## here, we will repeat our plots but for a different data set\n",
    "all_counts = pyreadr.read_r('/path/to/Third_Party_FFPE/GSE146889_GeneCount.rds')\n",
    "\n",
    "# we may want to keep this table for Ensemble -> RefSeq conversion\n",
    "gene_convert = pyreadr.read_r('/path/to/metadata/ensemble_to_refseq_gene_name_table.rds')\n",
    "\n",
    "\n",
    "\n",
    "# now we want to isolate just the expression from a particular type of tissue\n",
    "\n",
    "df = all_counts[None] # load all_counts into a pandas data frame\n",
    "\n",
    "# we need to split the tumors and normals by name\n",
    "count_TUMOR = df.filter(like='tumor')\n",
    "count_NORMAL = df.filter(like='normal')\n",
    "\n",
    "#print(df_tumor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adeb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to add a new count table, averaged by the number of reads in the entire sample\n",
    "column_sums = np.sum(count_NORMAL, axis=0)\n",
    "\n",
    "# Divide each element by the column sum\n",
    "count_NORMAL_libsizeadjust = count_NORMAL / column_sums\n",
    "\n",
    "column_sums = np.sum(count_TUMOR, axis=0)\n",
    "count_TUMOR_libsizeadjust = count_TUMOR / column_sums\n",
    "\n",
    "print(count_NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a25de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_mean(row):\n",
    "    variance = np.var(row, ddof=1)\n",
    "    mean = np.mean(row)\n",
    "    std_dev = np.sqrt(variance) # sometimes this is considered dispersion\n",
    "    \n",
    "    # I'm a bit confused exactly how I'd compute a dataset-wide dispersion from this data\n",
    "    # the formula given is Variance = mean + dispersion*mean^2\n",
    "    # re-arranged, this gives dispersion = (variance - mean)/(mean*mean)\n",
    "    # I guess we can try it\n",
    "    dispersion = 0 # in case the mean is zero, or if variance = mean\n",
    "    if ((mean != 0) & (variance != mean)):\n",
    "        #dispersion = (variance - mean)/(mean**2)\n",
    "        dispersion = (mean**2)/(variance - mean) # did I have this backwards?\n",
    "        inverse_dispersion = dispersion**-1\n",
    "    \n",
    "    # and they define \"expected fraction zeros\" as exp(-mean) - Poisson distribution!\n",
    "    #prob_frac = math.exp(mean*-1)\n",
    "    \n",
    "    # lets do the NB formulation\n",
    "    prob_frac = 1 # if dispersion is zero, the fraction zero is 100%\n",
    "    if (dispersion >0):\n",
    "        prob_frac = ((inverse_dispersion)/(mean + inverse_dispersion))**(inverse_dispersion)\n",
    "    \n",
    "    # we will also want to know the fraction of the row that equals zero\n",
    "    zero_frac = (row == 0).sum()/len(row)\n",
    "    return pd.Series({'variance': variance, 'mean': mean, \"StDev\": std_dev, \"Dispersion\": dispersion, 'zero_fraction': zero_frac, 'prob_frac': prob_frac})\n",
    "\n",
    "# apply function along rows axis\n",
    "NORMAL_dispersion = count_NORMAL.apply(variance_mean, axis=1)\n",
    "NORMAL_dispersion_libadj = count_NORMAL_libsizeadjust.apply(variance_mean, axis=1)\n",
    "\n",
    "TUMOR_dispersion = count_TUMOR.apply(variance_mean, axis=1)\n",
    "TUMOR_dispersion_libadj = count_TUMOR_libsizeadjust.apply(variance_mean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc81339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the normals\n",
    "prob_over_zero = NORMAL_dispersion['prob_frac'] < 1\n",
    "probe_over_zero_filt = NORMAL_dispersion[prob_over_zero]\n",
    "print(probe_over_zero_filt.nsmallest(100, 'Dispersion'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db1ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 'variance' and 'zero_count' columns\n",
    "ydata = NORMAL_dispersion['zero_fraction']\n",
    "xdata = NORMAL_dispersion['mean'] \n",
    "\n",
    "mean = NORMAL_dispersion['mean']\n",
    "prob = NORMAL_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Log[mean]')\n",
    "plt.title(\"GSE146889 Normal - Zero Frac. vs Log(Mean) [Blue]; Expected Mean [Orange]\", fontdict=None, loc='center', pad=None)\n",
    "plt.show()\n",
    "\n",
    "# and again for tumours\n",
    "ydata = TUMOR_dispersion['zero_fraction']\n",
    "xdata = TUMOR_dispersion['mean'] \n",
    "\n",
    "mean = TUMOR_dispersion['mean']\n",
    "prob = TUMOR_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Log[mean]')\n",
    "plt.title(\"GSE146889 Tumor - Zero Frac. vs Log(Mean) [Blue]; Expected Mean [Orange]\", fontdict=None, loc='center', pad=None)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we plot the probability computed from mean, but plot variance?\n",
    "\n",
    "# extract 'variance' and 'zero_count' columns\n",
    "ydata = NORMAL_dispersion['zero_fraction']\n",
    "xdata = NORMAL_dispersion['Dispersion'] # standard deviation of the variance\n",
    "\n",
    "prob = NORMAL_dispersion['prob_frac'] # probability of fraction zeros with \n",
    "mean = NORMAL_dispersion['Dispersion'] # StDev \n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "#plt.scatter(mean, prob, alpha=0.02)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Dispersion - Normal')\n",
    "plt.title(\"GSE146889 Normal - Zero Frac. vs Log(Dispersion); Expected Disp. [Orange]\", fontdict=None, loc='center', pad=None)\n",
    "plt.xlim([0, 50])\n",
    "plt.show()\n",
    "\n",
    "# DCIS\n",
    "ydata = TUMOR_dispersion['zero_fraction']\n",
    "xdata = TUMOR_dispersion['Dispersion'] # standard deviation of the variance\n",
    "\n",
    "prob = TUMOR_dispersion['prob_frac'] # probability of fraction zeros with \n",
    "mean = TUMOR_dispersion['Dispersion'] # StDev \n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.02)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Dispersion - Tumor')\n",
    "plt.title(\"GSE146889 Tumor - Zero Frac. vs Log(Dispersion); Expected Disp. [Orange]\", fontdict=None, loc='center', pad=None)\n",
    "plt.xlim([0, 50])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we plot mean vs dispersion\n",
    "\n",
    "# extract 'variance' and 'zero_count' columns\n",
    "ydata = NORMAL_dispersion['mean']\n",
    "xdata = NORMAL_dispersion['Dispersion'] # standard deviation of the variance\n",
    "\n",
    "prob = NORMAL_dispersion['prob_frac'] # probability of fraction zeros with \n",
    "mean = NORMAL_dispersion['Dispersion'] # StDev \n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "#plt.scatter(mean, prob, alpha=0.02)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Mean')\n",
    "plt.xlabel('Dispersion - Normal')\n",
    "plt.title(\"GSE146889 Normal - Zero Frac. vs Log(Dispersion)\", fontdict=None, loc='center', pad=None)\n",
    "plt.xlim([0, 50])\n",
    "plt.show()\n",
    "\n",
    "# DCIS\n",
    "ydata = TUMOR_dispersion['mean']\n",
    "xdata = TUMOR_dispersion['Dispersion'] # standard deviation of the variance\n",
    "\n",
    "prob = TUMOR_dispersion['prob_frac'] # probability of fraction zeros with \n",
    "mean = TUMOR_dispersion['Dispersion'] # StDev \n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "#plt.scatter(mean, prob, alpha=0.02)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Mean')\n",
    "plt.xlabel('Dispersion - Tumor')\n",
    "plt.title(\"GSE146889 Tumor - Mean vs Log(Dispersion)\", fontdict=None, loc='center', pad=None)\n",
    "plt.xlim([0, 50])\n",
    "plt.ylim(0, 200000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of counts for a patient\n",
    "patient2 = count_NORMAL['MSI_MLH1G_normal_10_count']\n",
    "\n",
    "plt.hist(patient2, range=(0, 2000), bins=2000)\n",
    "plt.yscale('log')\n",
    "# add labels and title\n",
    "plt.xlabel('#Counts')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.title('Histogram of Counts from MSI_MLH1G_normal_10_count')\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839ff8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Third Party Dataset - GSE209998 ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c335bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## here, we will repeat our plots but for a different data set\n",
    "all_counts = pyreadr.read_r('/path/to/Third_Party_FFPE/GSE209998_GeneCount.rds')\n",
    "\n",
    "\n",
    "sample_information = pyreadr.read_r('/path/to/Third_Party_FFPE/GSE209998_Sample_Data.rds')\n",
    "\n",
    "# now we want to isolate just the expression from a particular type of tissue\n",
    "\n",
    "df_counts = all_counts[None] # load all_counts into a pandas data frame\n",
    "df_sample = sample_information[None] # load all_counts into a pandas data frame\n",
    "\n",
    "# here, we need to match if a sample is normal or tumour by !Sample_source_name_ch1 row\n",
    "\n",
    "# so I need to: 1) match columns between sample_information and all_counts \n",
    "# are they in the same order\n",
    "columns_df1 = df_counts.columns\n",
    "columns_df2 = df_sample.columns\n",
    "\n",
    "#if columns_df1.equals(columns_df2):\n",
    "#    print(\"The columns are in the same order.\")\n",
    "# this code shows the columns are indeed in the same order\n",
    "\n",
    "# Now we find what samples were tumours and what were normal\n",
    "samples_row = df_sample.loc[\"!Sample_source_name_ch1\"]\n",
    "\n",
    "split_dfs = {}\n",
    "for sample_type in samples_row.unique():\n",
    "    matching_columns = [col for col in df_counts.columns if col in df_sample.columns and samples_row[col] == sample_type]\n",
    "    split_dfs[sample_type] = df_counts[matching_columns]\n",
    "\n",
    "# Access the split DataFrames using the sample type\n",
    "count_NORMAL = split_dfs[\"Normal tissue\"]\n",
    "count_TUMOR = split_dfs[\"Primary tumor\"]\n",
    "count_META = split_dfs[\"Metastatic tumor\"]\n",
    "\n",
    "print(\"NORMAL\", count_NORMAL.shape[1])\n",
    "print(\"PRIMARY\", count_TUMOR.shape[1])\n",
    "print(\"METASTAT.\", count_META.shape[1])\n",
    "# there are only 6 normal samples so they might not be good for further analysis\n",
    "# there are 44 primary tumour and 79 metastatic\n",
    "\n",
    "sample_source = df_sample.loc[\"!Sample_source\"]\n",
    "\n",
    "split_source = {}\n",
    "for sample_type in sample_source.unique():\n",
    "    matching_columns = [col for col in df_counts.columns if col in df_sample.columns and sample_source[col] == sample_type]\n",
    "    split_source[sample_type] = df_counts[matching_columns]\n",
    "\n",
    "\n",
    "count_FRESH = split_source[\"Fresh frozen\"]\n",
    "count_FFPE = split_source[\"FFPE\"]\n",
    "\n",
    "print(\"FRESH\", count_FRESH.shape[1])\n",
    "print(\"FFPE\", count_FFPE.shape[1])\n",
    "# note that this would be a mix of primary, metastatic and normals\n",
    "\n",
    "# how many normals are in fresh/frozen?\n",
    "\n",
    "split_dfs = {}\n",
    "for sample_type in samples_row.unique():\n",
    "    matching_columns = [col for col in count_FRESH.columns if col in df_sample.columns and samples_row[col] == sample_type]\n",
    "    split_dfs[sample_type] = count_FRESH[matching_columns]\n",
    "\n",
    "# Access the split DataFrames using the sample type\n",
    "count_NORMAL = split_dfs[\"Normal tissue\"]\n",
    "count_TUMOR = split_dfs[\"Primary tumor\"]\n",
    "count_META = split_dfs[\"Metastatic tumor\"]\n",
    "\n",
    "print(\"NORMAL\", count_NORMAL.shape[1])\n",
    "print(\"PRIMARY\", count_TUMOR.shape[1])\n",
    "print(\"METASTAT.\", count_META.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e451e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to add a new count table, averaged by the number of reads in the entire sample\n",
    "column_sums = np.sum(count_FRESH, axis=0)\n",
    "\n",
    "# Divide each element by the column sum\n",
    "count_FRESH_libsizeadjust = count_FRESH / column_sums\n",
    "\n",
    "column_sums = np.sum(count_FFPE, axis=0)\n",
    "count_FFPE_libsizeadjust = count_FFPE / column_sums\n",
    "\n",
    "#print(count_FFPE_libsizeadjust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642bd175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_mean(row):\n",
    "    variance = np.var(row, ddof=1)\n",
    "    mean = np.mean(row)\n",
    "    std_dev = np.sqrt(variance) # sometimes this is considered dispersion\n",
    "    \n",
    "    # I'm a bit confused exactly how I'd compute a dataset-wide dispersion from this data\n",
    "    # the formula given is Variance = mean + dispersion*mean^2\n",
    "    # re-arranged, this gives dispersion = (variance - mean)/(mean*mean)\n",
    "    # I guess we can try it\n",
    "    dispersion = 0 # in case the mean is zero, or if variance = mean\n",
    "    if ((mean != 0) & (variance != mean)):\n",
    "        #dispersion = (variance - mean)/(mean**2)\n",
    "        dispersion = (mean**2)/(variance - mean) # did I have this backwards?\n",
    "        inverse_dispersion = dispersion**-1\n",
    "    \n",
    "    # and they define \"expected fraction zeros\" as exp(-mean) - Poisson distribution!\n",
    "    #prob_frac = math.exp(mean*-1)\n",
    "    \n",
    "    # lets do the NB formulation\n",
    "    prob_frac = 1 # if dispersion is zero, the fraction zero is 100%\n",
    "    if (dispersion >0):\n",
    "        prob_frac = ((inverse_dispersion)/(mean + inverse_dispersion))**(inverse_dispersion)\n",
    "    \n",
    "    # we will also want to know the fraction of the row that equals zero\n",
    "    zero_frac = (row == 0).sum()/len(row)\n",
    "    return pd.Series({'variance': variance, 'mean': mean, \"StDev\": std_dev, \"Dispersion\": dispersion, 'zero_fraction': zero_frac, 'prob_frac': prob_frac})\n",
    "\n",
    "# apply function along rows axis\n",
    "FRESH_dispersion = count_FRESH.apply(variance_mean, axis=1)\n",
    "FRESH_dispersion_libadj = count_FRESH_libsizeadjust.apply(variance_mean, axis=1)\n",
    "\n",
    "FFPE_dispersion = count_FFPE.apply(variance_mean, axis=1)\n",
    "FFPE_dispersion_libadj = count_FFPE_libsizeadjust.apply(variance_mean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761175e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 'variance' and 'zero_count' columns\n",
    "ydata = FRESH_dispersion['zero_fraction']\n",
    "xdata = FRESH_dispersion['mean'] \n",
    "\n",
    "mean = FRESH_dispersion['mean']\n",
    "prob = FRESH_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Log[mean]')\n",
    "plt.xlim(0.001, 1000000)\n",
    "plt.title(\"GSE209998 FreshFrozen - ZeroFrac vs Log(Mean) [Blue]; Exp. Mean [Orange]\", fontdict=None, loc='center', pad=None)\n",
    "plt.show()\n",
    "\n",
    "# and again for tumours\n",
    "ydata = FFPE_dispersion['zero_fraction']\n",
    "xdata = FFPE_dispersion['mean'] \n",
    "\n",
    "mean = FFPE_dispersion['mean']\n",
    "prob = FFPE_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.xlim(0.001, 1000000)\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Log[mean]')\n",
    "plt.title(\"GSE209998 FFPE - ZeroFrac vs Log(Mean) [Blue]; Exp. Mean [Orange]\", fontdict=None, loc='center', pad=None)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b1b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fourth Party Dataset - GSE47462 ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194bb31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time instead of starting from RDS files, I want to pre-process the data here\n",
    "# we start with GSE47462\n",
    "# sample names have normals, IDC and EN (early neoplasia)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv('/path/to/Third_Party_FFPE/Additional_Sets/GSE47462_Raw_counts_Refseq_genes.txt',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "# Split the DataFrame into subsets based on column names indicating sample type\n",
    "normal_data = data.filter(like='_normal')\n",
    "EN_data = data.filter(like='_EN')\n",
    "DCIS_data = data.filter(like='_DCIS')\n",
    "IDC_data = data.filter(like='_IDC')\n",
    "\n",
    "# since there isn't a ton of data, I also want to group tumors\n",
    "tumours_data = data.loc[:, ~data.columns.str.contains('_normal')]\n",
    "tumours_data = tumours_data.iloc[:, 1:]\n",
    "\n",
    "# convert to normal numpy matrices of counts\n",
    "normal_counts = normal_data.to_numpy()\n",
    "en_counts = EN_data.to_numpy()\n",
    "dcis_counts = DCIS_data.to_numpy()\n",
    "idc_counts = IDC_data.to_numpy()\n",
    "tumours_counts = tumours_data.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6adfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NORMAL\", normal_counts.shape[1])\n",
    "print(\"IDC\", idc_counts.shape[1])\n",
    "print(\"DCIS\", dcis_counts.shape[1])\n",
    "print(\"Early Neoplastia\", en_counts.shape[1])\n",
    "print(\"All Tumours\", tumours_counts.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcf201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispersion of tumours\n",
    "tumours_counts = pd.DataFrame(tumours_counts)\n",
    "\n",
    "column_sums = np.sum(tumours_counts, axis=0)\n",
    "count_TUMOR_libsizeadjust = tumours_counts / column_sums\n",
    "\n",
    "TUMOR_dispersion = tumours_counts.apply(variance_mean, axis=1)\n",
    "TUMOR_dispersion_libadj = count_TUMOR_libsizeadjust.apply(variance_mean, axis=1)\n",
    "\n",
    "# and normals\n",
    "normal_counts = pd.DataFrame(normal_counts)\n",
    "\n",
    "column_sums = np.sum(normal_counts, axis=0)\n",
    "count_NORMAL_libsizeadjust = normal_counts / column_sums\n",
    "\n",
    "NORMAL_dispersion = normal_counts.apply(variance_mean, axis=1)\n",
    "NORMAL_dispersion_libadj = count_NORMAL_libsizeadjust.apply(variance_mean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets draw the dispersion\n",
    "# extract 'variance' and 'zero_count' columns\n",
    "ydata = NORMAL_dispersion['zero_fraction']\n",
    "xdata = NORMAL_dispersion['mean'] \n",
    "\n",
    "mean = NORMAL_dispersion['mean']\n",
    "prob = NORMAL_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Log[mean]')\n",
    "plt.xlim(0.001, 1000000)\n",
    "plt.title(\"GSE47462 Normal - ZeroFrac vs Log(Mean) [Blue]; Exp. Mean [Orange]\", fontdict=None, loc='center', pad=None)\n",
    "plt.show()\n",
    "\n",
    "# and again for tumours\n",
    "ydata = TUMOR_dispersion['zero_fraction']\n",
    "xdata = TUMOR_dispersion['mean'] \n",
    "\n",
    "mean = TUMOR_dispersion['mean']\n",
    "prob = TUMOR_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.xlim(0.001, 1000000)\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Log[mean]')\n",
    "plt.title(\"GSE47462 Tumours - ZeroFrac vs Log(Mean) [Blue]; Exp. Mean [Orange]\", fontdict=None, loc='center', pad=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8dcbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e12254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Dataset - GSE120795_total_norms_raw_counts.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a492eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are all from normal patients\n",
    "# not all the data is FFPE, some is fresh, so I'll need to separate them\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv('/path/to/Third_Party_FFPE/Additional_Sets/GSE120795_total_norms_raw_counts.tsv',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "# in the series matrix\"disease: healthy\", \n",
    "patient_info = pd.read_csv('/path/to/Third_Party_FFPE/Additional_Sets/GSE120795_cell_info.txt',\n",
    "                  delimiter='\\t')\n",
    "# note that the column order of these two files are NOT the same\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e5473",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = patient_info.iloc[0] == \"healthy\"\n",
    "\n",
    "filtered_data = patient_info.loc[:, mask]\n",
    "patient_names = filtered_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a1ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use patient info to filter data\n",
    "# remember that patient names from \"filtered_data\" don't have \".fastq.gz\" at the end of them\n",
    "column_names_with_extension = [name + \".fastq.gz\" for name in patient_names]\n",
    "column_names_with_extension = column_names_with_extension[1:]\n",
    "\n",
    "# Assuming 'second_list' is the list where you want to filter based on column names\n",
    "filtered_data = data[column_names_with_extension]\n",
    "\n",
    "print(data.shape)\n",
    "print(filtered_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f634afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispersion of tumours\n",
    "ffpe_counts = pd.DataFrame(filtered_data)\n",
    "\n",
    "column_sums = np.sum(ffpe_counts, axis=0)\n",
    "count_FFPE_libsizeadjust = ffpe_counts / column_sums\n",
    "\n",
    "FFPE_dispersion = ffpe_counts.apply(variance_mean, axis=1)\n",
    "FFPE_dispersion_libadj = count_TUMOR_libsizeadjust.apply(variance_mean, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87191165",
   "metadata": {},
   "outputs": [],
   "source": [
    "ydata = FFPE_dispersion['zero_fraction']\n",
    "xdata = FFPE_dispersion['mean'] \n",
    "\n",
    "mean = FFPE_dispersion['mean']\n",
    "prob = FFPE_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.xlim(0.001, 1000000)\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Log[mean]')\n",
    "plt.title(\"GSE120795 FFPE - ZeroFrac vs Log(Mean) [Blue]; Exp. Mean [Orange]\", fontdict=None, loc='center', pad=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c599e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE MORE Dataset - GSE193103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f7ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all FFPE breast tumours, different treatment (not split up)\n",
    "\n",
    "data = pd.read_csv('/path/to/Third_Party_FFPE/Additional_Sets/GSE193103_salmon_gene.matrix_RAP101_plus_Normals24.txt',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "# this data set has fresh and FFPE, so we'll need to separate them\n",
    "# it also has breast tumour vs metastatic breast, so there are differences there too\n",
    "# not 100% if the metastasis is from the tissue it is found in, or from the breast\n",
    "patient_info = pd.read_csv('/path/to/Third_Party_FFPE/Additional_Sets/GSE193103_Patient_Data.txt',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0484e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row [0] is metastasis location, [1] is cancer type (breast or metastasis) and [2] is fresh/FFPE\n",
    "# \"Fresh frozen\" or \"Formalin-Fixed Paraffin-Embedded\"\n",
    "mask = patient_info.iloc[2] == \"Formalin-Fixed Paraffin-Embedded\"\n",
    "FFPE_data = patient_info.loc[:, mask]\n",
    "FFPE_patient_names = FFPE_data.columns\n",
    "\n",
    "mask = patient_info.iloc[2] == \"Fresh frozen\"\n",
    "Fresh_data = patient_info.loc[:, mask]\n",
    "Fresh_patient_names = Fresh_data.columns\n",
    "\n",
    "# now we filter the data\n",
    "filtered_FFPE_data = data[FFPE_patient_names]\n",
    "filtered_Fresh_data = data[Fresh_patient_names]\n",
    "\n",
    "print(data.shape)\n",
    "print(filtered_FFPE_data.shape) # 20\n",
    "print(filtered_Fresh_data.shape) # 105\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispersion of tumours - All Data\n",
    "tumours_counts = pd.DataFrame(data)\n",
    "# removing gene column\n",
    "tumours_counts = tumours_counts.drop(tumours_counts.columns[0], axis=1)\n",
    "column_sums = np.sum(tumours_counts, axis=0)\n",
    "TUMOR_dispersion = tumours_counts.apply(variance_mean, axis=1)\n",
    "\n",
    "# dispersion of tumours - FFPE Only\n",
    "FFPE_counts = pd.DataFrame(filtered_FFPE_data)\n",
    "# removing gene column\n",
    "FFPE_counts = FFPE_counts.drop(FFPE_counts.columns[0], axis=1)\n",
    "column_sums = np.sum(FFPE_counts, axis=0)\n",
    "FFPE_dispersion = FFPE_counts.apply(variance_mean, axis=1)\n",
    "\n",
    "# dispersion of tumours - Fresh Only\n",
    "Fresh_counts = pd.DataFrame(filtered_Fresh_data)\n",
    "# removing gene column\n",
    "Fresh_counts = Fresh_counts.drop(Fresh_counts.columns[0], axis=1)\n",
    "column_sums = np.sum(Fresh_counts, axis=0)\n",
    "Fresh_dispersion = Fresh_counts.apply(variance_mean, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d239665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all samples (fresh and FFPE)\n",
    "ydata = TUMOR_dispersion['zero_fraction']\n",
    "xdata = TUMOR_dispersion['mean'] \n",
    "\n",
    "mean = TUMOR_dispersion['mean']\n",
    "prob = TUMOR_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.xlim(0.001, 1000000)\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Log[mean]')\n",
    "plt.title(\"GSE193103 All - ZeroFrac vs Log(Mean) [Blue]; Exp. Mean [Orange]\", \n",
    "          fontdict=None, loc='center', pad=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11180e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by FFPE and Fresh/Frozen\n",
    "print(FFPE_dispersion)\n",
    "\n",
    "ydata = FFPE_dispersion['zero_fraction']\n",
    "xdata = FFPE_dispersion['mean'] \n",
    "\n",
    "mean = FFPE_dispersion['mean']\n",
    "prob = FFPE_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.xlim(0.001, 1000000)\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Log[mean]')\n",
    "plt.title(\"GSE193103 FFPE - ZeroFrac vs Log(Mean) [Blue]; Exp. Mean [Orange]\", \n",
    "          fontdict=None, loc='center', pad=None)\n",
    "plt.show()\n",
    "\n",
    "## Fresh/Frozen\n",
    "# split by FFPE and Fresh/Frozen\n",
    "ydata = Fresh_dispersion['zero_fraction']\n",
    "xdata = Fresh_dispersion['mean'] \n",
    "\n",
    "mean = Fresh_dispersion['mean']\n",
    "prob = Fresh_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.xlim(0.001, 1000000)\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Log[mean]')\n",
    "plt.title(\"GSE193103 Fresh/Froz. - ZeroFrac vs Log(Mean) [Blue]; Exp. Mean [Orange]\", \n",
    "          fontdict=None, loc='center', pad=None)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c60dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c694d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dataset - GSE181466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0055df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all FFPE breast tumours, different treatment (not split up)\n",
    "data = pd.read_csv('/path/to/Third_Party_FFPE/Additional_Sets/GSE181466_rsem_genes_matrix-97.txt',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "# patient information splitting is unnecessary, this appears to all be both FFPE and from tumours\n",
    "# there is subtype and age information in the series matrix file, if we're interested\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispersion of tumours - All Data\n",
    "tumours_counts = pd.DataFrame(data)\n",
    "# removing gene column at position 0\n",
    "tumours_counts = tumours_counts.drop(tumours_counts.columns[0], axis=1)\n",
    "column_sums = np.sum(tumours_counts, axis=0)\n",
    "TUMOR_dispersion = tumours_counts.apply(variance_mean, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cef35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "\n",
    "ydata = TUMOR_dispersion['zero_fraction']\n",
    "xdata = TUMOR_dispersion['mean'] \n",
    "\n",
    "mean = TUMOR_dispersion['mean']\n",
    "prob = TUMOR_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.xlim(0.001, 1000000)\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Log[mean]')\n",
    "plt.title(\"GSE181466 FFPE - ZeroFrac vs Log(Mean) [Blue]; Exp. Mean [Orange]\", \n",
    "          fontdict=None, loc='center', pad=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7693b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data/lab_vm/raw/preffect/7_datasets/third_party/CountMeIn_BConly_third_party_ffpe/MBC_CMI_Compiled_Counts.tsv',\n",
    "                  delimiter=' ')\n",
    "\n",
    "# \"5\" \"ENSG00000000003.15\" \"TSPAN6\" \"protein_coding\" 350 247 ...\n",
    "\n",
    "\n",
    "# dispersion of tumours - All Data\n",
    "tumours_counts = pd.DataFrame(data)\n",
    "# first four columns are gene descriptors\n",
    "tumours_counts = tumours_counts.iloc[:, 4:]\n",
    "\n",
    "column_sums = np.sum(tumours_counts, axis=0)\n",
    "TUMOR_dispersion = tumours_counts.apply(variance_mean, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976f85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "\n",
    "ydata = TUMOR_dispersion['zero_fraction']\n",
    "xdata = TUMOR_dispersion['mean'] \n",
    "\n",
    "mean = TUMOR_dispersion['mean']\n",
    "prob = TUMOR_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.xlim(0.001, 1000000)\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Log[mean]')\n",
    "plt.title(\"TMBC FFPE - ZeroFrac vs Log(Mean) [Blue]; Exp. Mean [Orange]\", \n",
    "          fontdict=None, loc='center', pad=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefeef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dataset - GSE167977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all FFPE breast tumours, different treatment (not split up)\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/path/to/Third_Party_FFPE/Additional_Sets/GSE167977_Raw_Counts.txt',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "# no reason to load up the series matrix, as samples only really differ by treatment (and there's no outcome so ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe45f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispersion of tumours - All Data\n",
    "tumours_counts = pd.DataFrame(data)\n",
    "# removing gene column at position 0\n",
    "\n",
    "# I also need to remove the last 5 columns, as they contained data of the genes\n",
    "tumours_counts = tumours_counts.drop(tumours_counts.columns[0], axis=1) # column 1\n",
    "tumours_counts = tumours_counts.drop(tumours_counts.columns[-5:], axis=1) # last 5 columns\n",
    "\n",
    "column_sums = np.sum(tumours_counts, axis=0)\n",
    "TUMOR_dispersion = tumours_counts.apply(variance_mean, axis=1)\n",
    "\n",
    "print(tumours_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f55885",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "\n",
    "ydata = TUMOR_dispersion['zero_fraction']\n",
    "xdata = TUMOR_dispersion['mean'] \n",
    "\n",
    "mean = TUMOR_dispersion['mean']\n",
    "prob = TUMOR_dispersion['prob_frac']\n",
    "\n",
    "# plot data points and fitted curve\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(mean, prob, alpha=0.01)\n",
    "plt.xscale('log')\n",
    "plt.xlim(0.001, 1000000)\n",
    "plt.ylabel('ZeroFraction')\n",
    "plt.xlabel('Log[mean]')\n",
    "plt.title(\"GSE167977 FFPE - ZeroFrac vs Log(Mean) [Blue]; Exp. Mean [Orange]\", \n",
    "          fontdict=None, loc='center', pad=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece33e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make QQ Plots, comparing gene expression with an NB\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Simulated or real observed data\n",
    "# use tumours_counts, as it cut out non-count data\n",
    "observed_random_gene = tumours_counts.iloc[15, :]\n",
    "\n",
    "# calculate r and p from this gene\n",
    "# Estimate the parameters r and p using method of moments\n",
    "mean_gene_expression = np.mean(observed_random_gene)\n",
    "var_gene_expression = np.var(observed_random_gene)\n",
    "p = mean_gene_expression / var_gene_expression\n",
    "r = mean_gene_expression**2 / (var_gene_expression - mean_gene_expression)\n",
    "\n",
    "# Sort the observed data\n",
    "sorted_data = np.sort(observed_random_gene)\n",
    "\n",
    "# Calculate observed quantiles\n",
    "observed_quantiles = np.array([(i - 0.5) / len(sorted_data) for i in range(1, len(sorted_data) + 1)])\n",
    "\n",
    "# Calculate theoretical quantiles\n",
    "theoretical_quantiles = stats.nbinom.ppf(observed_quantiles, r, p)\n",
    "\n",
    "# Create the Q-Q plot\n",
    "plt.scatter(theoretical_quantiles, sorted_data)\n",
    "plt.plot([min(theoretical_quantiles), max(theoretical_quantiles)], [min(sorted_data), max(sorted_data)], 'r--')\n",
    "plt.xlabel('Theoretical Quantiles')\n",
    "plt.ylabel('Observed Quantiles')\n",
    "plt.title('Q-Q Plot for NB Data')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9760b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now again, using a ZINB\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Simulated or real observed data\n",
    "# use tumours_counts, as it cut out non-count data\n",
    "observed_random_gene = tumours_counts.iloc[15, :]\n",
    "\n",
    "# lets compute the ZINB\n",
    "pi = sum(observed_random_gene == 0) / len(observed_random_gene)\n",
    "non_zero_data = observed_random_gene[observed_random_gene > 0]\n",
    "mean_gene_expression = np.mean(non_zero_data)\n",
    "var_gene_expression = np.var(non_zero_data)\n",
    "p = mean_gene_expression / var_gene_expression\n",
    "r = mean_gene_expression**2 / (var_gene_expression - mean_gene_expression)\n",
    "\n",
    "# Sort the observed data, removing zeros\n",
    "sorted_data = np.sort(non_zero_data)\n",
    "\n",
    "# Calculate observed quantiles\n",
    "observed_quantiles = np.array([(i - 0.5) / len(sorted_data) for i in range(1, len(sorted_data) + 1)])\n",
    "\n",
    "# Generate theoretical ZINB quantiles using a large simulated dataset\n",
    "n_samples = 10000\n",
    "nb_samples = stats.nbinom.rvs(r, p, size=n_samples)\n",
    "zero_inflated = np.random.rand(n_samples) < pi\n",
    "zinb_samples = np.where(zero_inflated, 0, nb_samples)\n",
    "zinb_samples_no_zero = zinb_samples[zinb_samples > 0]\n",
    "zinb_samples_no_zero.sort()\n",
    "\n",
    "theoretical_quantiles = np.percentile(zinb_samples_no_zero, observed_quantiles*100)\n",
    "\n",
    "# Create QQ plot\n",
    "plt.scatter(theoretical_quantiles, sorted_data)\n",
    "plt.plot([min(theoretical_quantiles), max(theoretical_quantiles)], [min(sorted_data), max(sorted_data)], 'r--')\n",
    "plt.xlabel('Theoretical Quantiles')\n",
    "plt.ylabel('Observed Quantiles')\n",
    "plt.title('QQ-Plot for ZINB Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f591886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Maximum Likelihood Estimation (MLE) to compute ZINB\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def nll_zinb(params, data):\n",
    "    r, p, pi = params\n",
    "    nb_term = stats.nbinom.logpmf(data[data > 0], r, p)\n",
    "    zero_term = np.log((1 - pi) + pi * stats.nbinom.pmf(0, r, p))\n",
    "    nll = -np.sum(nb_term) - np.sum(zero_term)\n",
    "    return nll\n",
    "\n",
    "# Your observed gene expression data\n",
    "observed_random_gene = tumours_counts.iloc[15, :]\n",
    "\n",
    "# Initial guesses for r, p, and pi\n",
    "initial_guess = [1, 0.5, 0.1]\n",
    "\n",
    "# Bounds for r, p, and pi\n",
    "bounds = [(0.01, 20), (0.01, 0.99), (0.01, 0.99)]\n",
    "\n",
    "result = minimize(nll_zinb, initial_guess, args=(observed_random_gene,), bounds=bounds)\n",
    "r_mle, p_mle, pi_mle = result.x\n",
    "\n",
    "sorted_data = np.sort(observed_random_gene)\n",
    "\n",
    "# Calculate observed quantiles\n",
    "observed_quantiles = np.array([(i - 0.5) / len(sorted_data) for i in range(1, len(sorted_data) + 1)])\n",
    "\n",
    "# Calculate theoretical quantiles with ZINB parameters\n",
    "# Zero-inflation will affect the lower quantiles; we need to adjust for this.\n",
    "adjusted_quantiles = (1 - pi_mle) + pi_mle * observed_quantiles\n",
    "theoretical_quantiles = stats.nbinom.ppf(adjusted_quantiles, r_mle, p_mle)\n",
    "\n",
    "# Create QQ plot\n",
    "plt.scatter(theoretical_quantiles, sorted_data)\n",
    "plt.plot([min(theoretical_quantiles), max(theoretical_quantiles)], [min(theoretical_quantiles), max(theoretical_quantiles)], 'r--')\n",
    "plt.xlabel('Theoretical Quantiles')\n",
    "plt.ylabel('Observed Quantiles')\n",
    "plt.title('QQ plot using Maximum Likelihood Estimation (ZINB)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df545a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "\n",
    "image_path = \"/path/to/1_estimating_common_dispersion/mean_vs_zerofract_plots/\"\n",
    "\n",
    "# List of image file paths in the directory\n",
    "image_files = sorted([os.path.join(image_path, file) for file in os.listdir(image_path) if file.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "# Check if there are exactly 13 images\n",
    "if len(image_files) != 13:\n",
    "    print(len(image_files))\n",
    "    raise ValueError(\"There must be exactly 13 image files in the directory\")\n",
    "\n",
    "# Load images and crop black text borders\n",
    "def crop_image(image):\n",
    "    # Convert image to grayscale\n",
    "    gray_image = image.convert('L')\n",
    "    # Invert the image\n",
    "    inverted_image = ImageOps.invert(gray_image)\n",
    "    # Get bounding box of non-zero regions in the inverted image\n",
    "    bbox = inverted_image.getbbox()\n",
    "    # Crop the original image to the bounding box\n",
    "    cropped_image = image.crop(bbox)\n",
    "    return cropped_image\n",
    "\n",
    "images = [crop_image(Image.open(img)) for img in image_files]\n",
    "\n",
    "# Assuming all images are the same size after cropping\n",
    "img_width, img_height = images[0].size\n",
    "\n",
    "# Define grid size (4x4)\n",
    "grid_width = 5\n",
    "grid_height = 3\n",
    "\n",
    "# Create a blank image with the appropriate size\n",
    "combined_image = Image.new('RGB', (grid_width * img_width, grid_height * img_height))\n",
    "\n",
    "# Paste images into the combined image\n",
    "for idx, image in enumerate(images):\n",
    "    x = (idx % grid_width) * img_width\n",
    "    y = (idx // grid_width) * img_height\n",
    "    combined_image.paste(image, (x, y))\n",
    "\n",
    "\n",
    "\n",
    "# Save the combined image\n",
    "final_impage = image_path + \"combined_plot.png\"\n",
    "\n",
    "combined_image.save(final_impage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
