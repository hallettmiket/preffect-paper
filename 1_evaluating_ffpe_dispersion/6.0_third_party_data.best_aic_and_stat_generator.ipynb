{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0debac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T20:58:43.707271Z",
     "iopub.status.busy": "2024-03-26T20:58:43.707092Z",
     "iopub.status.idle": "2024-03-26T20:58:46.089095Z",
     "shell.execute_reply": "2024-03-26T20:58:46.088318Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families import NegativeBinomial, Gamma\n",
    "from statsmodels.discrete.count_model import ZeroInflatedNegativeBinomialP\n",
    "\n",
    "from scipy.stats import expon, nbinom, norm, poisson\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# now the DCIS count data is found in an RDA file, which we apparently read using 'pyreadr'\n",
    "import pyreadr\n",
    "\n",
    "\n",
    "# to convert Ensemble to Refseq gene names\n",
    "gene_convert = pyreadr.read_r('/path/to/7_datasets/our_dcis/gene_info/ensemble_to_refseq_gene_name_table.rds')\n",
    "gene_convert = gene_convert[None]\n",
    "id_to_name = {gene_id: gene_name for gene_id, gene_name in zip(gene_convert[\"gene_id\"], gene_convert[\"gene_name\"])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e5697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T20:58:46.092668Z",
     "iopub.status.busy": "2024-03-26T20:58:46.091997Z",
     "iopub.status.idle": "2024-03-26T20:58:46.095791Z",
     "shell.execute_reply": "2024-03-26T20:58:46.095426Z"
    }
   },
   "outputs": [],
   "source": [
    "### Parameters ###\n",
    "\n",
    "# whether or not we're doing outlier removal using trimmed means\n",
    "trim_means_flag = True\n",
    "trim_percent = 10 # 1% usually gets rid of most extreme outliers\n",
    "\n",
    "# genes must be expressed in this % of patients (between 0-1)\n",
    "express_percent_limit = 0.2 # set to 0 if you want patient stats (all genes with at least 1 read), set to 0.2 if we want AIC stats of genes with >20% expression\n",
    "\n",
    "# library adjust (using fractional method)\n",
    "adjust_for_lib = False\n",
    "\n",
    "# calculate AIC distance\n",
    "calc_AIC_dist = False # False saves time when running the full program\n",
    "\n",
    "# a flag if we want to just do \"no ZI\" or \"NB vs ZINB only\"\n",
    "NB_ZINB_only = False # Only comparing NB to ZINB [trim_percent should be low, maybe even zero]\n",
    "\n",
    "# trim will remove zeroes, so I don't think we should activate trim when doing NB/ZINB comparison\n",
    "if (NB_ZINB_only == True):\n",
    "    trim_percent = 0\n",
    "\n",
    "no_ZI_AICs = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea7391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T20:58:46.097340Z",
     "iopub.status.busy": "2024-03-26T20:58:46.097145Z",
     "iopub.status.idle": "2024-03-26T20:58:46.104279Z",
     "shell.execute_reply": "2024-03-26T20:58:46.103914Z"
    }
   },
   "outputs": [],
   "source": [
    "# non-AIC related functions used in this program    \n",
    "\n",
    "# computation of gene average, fraction of zeroes, and library size\n",
    "def dataset_stats_generator(df, draw_zero_distribution = True):\n",
    "    num_genes = df.shape[0]\n",
    "    num_samples = df.shape[1]\n",
    "    # Compute the metrics for each row\n",
    "    row_sums = df.sum(axis = 0)\n",
    "    fraction_zero_samples = (df == 0).sum(axis=0) / num_genes\n",
    "    fraction_zero_genes = (df == 0).sum(axis=1) / num_samples\n",
    "    row_means = df.mean(axis=1)\n",
    "\n",
    "    if (draw_zero_distribution):\n",
    "        plt.hist(fraction_zero_genes, bins=100, color='blue', alpha=0.7)\n",
    "        plt.xlabel('Fraction of Zeroes (Genes)')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title(\"Fraction of Zeroes per Gene\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.hist(fraction_zero_samples, bins=100, color='blue', alpha=0.7)\n",
    "        plt.xlabel('Fraction of Zeroes (Samples)')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title(\"Fraction of Zeroes per Sample\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.hist(row_means, bins=100, color='blue', alpha=0.7)\n",
    "        plt.xlabel('Means of Gene Expression')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title(\"Distribution of Means of Genes in Dataset\")\n",
    "        plt.show()\n",
    "      \n",
    "    # get the average of these \n",
    "    avg_library_size = np.round(np.sum(row_sums) / num_samples, decimals = 0)\n",
    "    avg_zeroes = np.round(np.sum(fraction_zero_samples) / num_samples, decimals = 3)\n",
    "    avg_mean_expression = np.round(np.mean(row_means), decimals = 3)\n",
    "    \n",
    "    # print(\"Avg Library Size\", \"Avg Fraction Zeroes\", \"Avg Mean Expression\")\n",
    "    return avg_library_size, avg_zeroes, avg_mean_expression\n",
    "\n",
    "# Simulating some data for illustration\n",
    "#data = np.random.negative_binomial(10, 0.5, 1000)\n",
    "\n",
    "def fit_to_nb_plot(data, plotrange = 30):\n",
    "\n",
    "    # Estimating parameters directly from data\n",
    "    mean = np.mean(data)\n",
    "    var = np.var(data)\n",
    "    p = 1 - (mean / var)\n",
    "    n = mean * (1 - p) / p\n",
    "\n",
    "    # Plotting\n",
    "    plt.hist(data, bins=range(plotrange), align='left', density=True, alpha=0.6, color='g')\n",
    "    plt.plot(bins[:-1], nbinom.pmf(bins[:-1], n, p), 'ro-', lw=2)\n",
    "    plt.title(\"Negative Binomial Fit\")\n",
    "    plt.show()\n",
    "\n",
    "# adjust for library sizes\n",
    "def library_adjust(data):\n",
    "    if (adjust_for_lib):\n",
    "        library_size = data.sum(axis=0)\n",
    "        \n",
    "        cleaned_matrix = np.round((data /library_size)*10000000)\n",
    "        return cleaned_matrix\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea31f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T20:58:46.105749Z",
     "iopub.status.busy": "2024-03-26T20:58:46.105605Z",
     "iopub.status.idle": "2024-03-26T20:58:46.110002Z",
     "shell.execute_reply": "2024-03-26T20:58:46.109645Z"
    }
   },
   "outputs": [],
   "source": [
    "# functions to compute ZINB\n",
    "\n",
    "def zinb_loglike(params, counts):\n",
    "    mu, theta, pi = params\n",
    "    p = 1 / (1 + mu/theta)\n",
    "    n = mu * p / (1 - p)\n",
    "    loglik_pois = nbinom.logpmf(counts, n, p)\n",
    "    loglik_zero = np.log(pi + (1 - pi) * np.exp(nbinom.logpmf(0, n, p)))\n",
    "    loglik = np.where(counts == 0, loglik_zero, np.log(1 - pi) + loglik_pois)\n",
    "    return -np.sum(loglik)\n",
    "\n",
    "def calculate_aic(loglik, k):\n",
    "    return 2*k - 2*loglik\n",
    "\n",
    "def fit_zinb_and_calculate_aic(counts):\n",
    "    \n",
    "    initial_params = np.array([np.mean(counts), np.var(counts), 0.5])\n",
    "    bounds = [(0, None), (0, None), (0, 1)]\n",
    "    result = minimize(zinb_loglike, initial_params, args=(counts), bounds=bounds)\n",
    "    mu, theta, pi = result.x\n",
    "    loglik = -result.fun\n",
    "    \n",
    "    k = 3  # Number of parameters\n",
    "    aic = calculate_aic(loglik, k)\n",
    "    return mu, theta, pi, aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee79dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute ZIP\n",
    "def zip_loglike(params, counts):\n",
    "    mu, pi = params\n",
    "    loglik_pois = poisson.logpmf(counts, mu)\n",
    "    loglik_zero = np.log(pi + (1 - pi) * np.exp(poisson.logpmf(0, mu)))\n",
    "    loglik = np.where(counts == 0, loglik_zero, np.log(1 - pi) + loglik_pois)\n",
    "    return -np.sum(loglik)\n",
    "\n",
    "def calculate_aic(loglik, k):\n",
    "    return 2*k - 2*loglik\n",
    "\n",
    "def fit_zip_and_calculate_aic(counts):\n",
    "    \n",
    "    initial_params = np.array([np.mean(counts), 0.5])\n",
    "    bounds = [(0, None), (0, 1)]\n",
    "    result = minimize(zip_loglike, initial_params, args=(counts), bounds=bounds)\n",
    "    mu, pi = result.x\n",
    "    loglik = -result.fun\n",
    "    k = 2  # Number of parameters for ZIP model\n",
    "    aic = calculate_aic(loglik, k)\n",
    "    return mu, pi, aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cf92b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T20:58:46.111466Z",
     "iopub.status.busy": "2024-03-26T20:58:46.111323Z",
     "iopub.status.idle": "2024-03-26T20:58:46.122710Z",
     "shell.execute_reply": "2024-03-26T20:58:46.122342Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is the function that computes AIC for all distributions (Gaussian, Exponential, Negative Binomial, ZIP, ZINB)\n",
    "# and reports which distribution is lowest\n",
    "# row - a vector of expressions\n",
    "def manual_aic(row):\n",
    "    \n",
    "    row = np.round(row) # it must be count data\n",
    "\n",
    "    # trimmed mean to remove outliers\n",
    "    n = len(row)\n",
    "    \n",
    "    if (trim_means_flag):\n",
    "        elements_to_trim = int(np.floor(trim_percent / 100.0 * n))  \n",
    "        sorted_data = np.sort(row)\n",
    "        \n",
    "        if (elements_to_trim > 0):\n",
    "            row = sorted_data[elements_to_trim:-elements_to_trim]\n",
    "        else: \n",
    "            row = sorted_data\n",
    "\n",
    "    if (sum(row) <= 0):\n",
    "        return \"ZEROES\"\n",
    "\n",
    "    X = sm.add_constant(np.ones(len(row)))\n",
    "\n",
    "    # Exponential parameters\n",
    "    lambda_exp = 1 / np.mean(row)\n",
    "    log_likelihood_exp = np.sum(expon.logpdf(row, scale=1/lambda_exp))\n",
    "    aic_exp = 2*1 - 2*log_likelihood_exp  # 1 parameter for exponential\n",
    "\n",
    "    # log -> linear -> delog\n",
    "    # using StatsModels to fit to a Gamma (it doesn't have exponential)\n",
    "    #model_exponential_approx = sm.GLM(row, X, family=Gamma()).fit()\n",
    "    #print('AIC for Gamma:', model_exponential_approx.aic)\n",
    "    #aic_exp = model_exponential_approx.aic\n",
    "\n",
    "    # Compute AIC to NB manually \n",
    "    mu_sample = np.mean(row)\n",
    "    var_sample = np.var(row)\n",
    "    if (mu_sample == var_sample):\n",
    "        var_sample = var_sample + 0.0000000000001\n",
    "    r_estimated = mu_sample**2 / (var_sample - mu_sample)\n",
    "    \n",
    "    if (mu_sample + r_estimated) == 0:\n",
    "        r_estimated = r_estimated + 0.0000000000001\n",
    "    p_estimated = r_estimated / (mu_sample + r_estimated)\n",
    "    log_likelihood_nb = np.sum(nbinom.logpmf(row, r_estimated, p_estimated))\n",
    "    aic_nb = 2*2 - 2*log_likelihood_nb  # 2 parameters for NB\n",
    "    aic_nb_orig = aic_nb\n",
    "\n",
    "    # StatsModels method to compute fit to NB\n",
    "    X = sm.add_constant(np.ones(len(row)))\n",
    "    model_nb = sm.GLM(row, X, family=NegativeBinomial()).fit()\n",
    "    aic_nb = model_nb.aic\n",
    "    #print(model_nb.summary())\n",
    "    #print(\"aic GLM\", aic_nb)\n",
    "\n",
    "    res = sm.NegativeBinomial(row, X).fit(start_params=[1,1])\n",
    "    #print(res.summary())\n",
    "    #print(\"aic MLE\", res.aic)\n",
    "    \n",
    "    aic_nb_orig = res.aic\n",
    "\n",
    "    # ZINB parameters\n",
    "    #pi_zinb = np.mean(row == 0)\n",
    "    #log_likelihood_zeros = np.sum(np.log(pi_zinb) * (row == 0))\n",
    "    #log_likelihood_non_zeros = np.sum(np.log(1 - pi_zinb) + nbinom.logpmf(row[row != 0], r_estimated, p_estimated))\n",
    "    #log_likelihood_zinb = log_likelihood_zeros + log_likelihood_non_zeros\n",
    "    #aic_zinb = 2*3 - 2*log_likelihood_zinb  # 3 parameters for ZINB: pi, r, and p\n",
    "\n",
    "    #print(\"Old\", aic_zinb)\n",
    "\n",
    "    mu, theta, pi, aic = fit_zinb_and_calculate_aic(row)\n",
    "    aic_zinb = aic\n",
    "    \n",
    "    #print(\"New\", mu, theta, pi, aic_zinb)\n",
    "    #print(\"AIC ZINB\", aic_zinb)\n",
    "    #model_zinb = ZeroInflatedNegativeBinomialP(endog=row, exog=X, exog_infl=X, inflation='logit')\n",
    "    #results_zinb = model_zinb.fit()\n",
    "\n",
    "    # print(\"StatsModels ZINB\", results_zinb.aic)\n",
    "\n",
    "\n",
    "    # Gaussian parameters\n",
    "    mu_gauss = np.mean(row)\n",
    "    sigma_gauss = np.std(row)\n",
    "    log_likelihood_gauss = np.sum(norm.logpdf(row, mu_gauss, sigma_gauss))\n",
    "    aic_gauss = 2*2 - 2*log_likelihood_gauss  # 2 parameters for Gaussian: mu and sigma\n",
    "    #print(\"Manual Gaussian\", aic_gauss)\n",
    "\n",
    "    model_gaussian = sm.GLM(row, X).fit()  # Default is Gaussian\n",
    "    #print('AIC for Gaussian model:', model_gaussian.aic)\n",
    "    aic_gauss = model_gaussian.aic\n",
    "\n",
    "    # alternative method to compute AIC for Gaussian; end result seems ~1% of GLM\n",
    "    #x = np.random.normal(size=len(row))\n",
    "    #X = sm.add_constant(x)  # Adds a constant term to the independent variables\n",
    "    # model = sm.OLS(row, X).fit()\n",
    "\n",
    "\n",
    "    # Poisson parameters (all methods give the same AIC)\n",
    "    lambda_pois = np.mean(row)\n",
    "    log_likelihood_pois = np.sum(poisson.logpmf(row, lambda_pois))\n",
    "    aic_pois = 2*1 - 2*log_likelihood_pois  # 1 parameter for Poisson: lambda\n",
    "\n",
    "    #print(\"Manual Poisson AIC\", aic_pois)\n",
    "\n",
    "    model_poisson = sm.GLM(row, X, family=sm.families.Poisson()).fit()\n",
    "    aic_pois = model_poisson.aic\n",
    "    #print(\"GLM Poisson\", aic_pois)\n",
    "\n",
    "    model_poisson = sm.Poisson(row, X).fit()\n",
    "    #print(\"GLM Poisson\", model_poisson.aic)\n",
    "\n",
    "\n",
    "    # ZIP parameters\n",
    "    #pi_zip = np.mean(row == 0)\n",
    "    #lambda_zip = np.mean(row[row != 0])\n",
    "    #log_likelihood_zeros_zip = np.sum(np.log(pi_zip) * (row == 0))\n",
    "    #log_likelihood_non_zeros_zip = np.sum(np.log(1 - pi_zip) + poisson.logpmf(row[row != 0], lambda_zip))\n",
    "    #log_likelihood_zip = log_likelihood_zeros_zip + log_likelihood_non_zeros_zip\n",
    "    #aic_zip = 2*2 - 2*log_likelihood_zip  # 2 parameters for ZIP: pi and lambda\n",
    "\n",
    "    #print(\"Old\", aic_zip)\n",
    "    # Usage\n",
    "    mu, pi, aic = fit_zip_and_calculate_aic(row)\n",
    "    aic_zip = aic\n",
    "    #print(f\"mu: {mu}, pi: {pi}, AIC: {aic}\")\n",
    "\n",
    "\n",
    "    # sometimes ZIP and ZINB can be NaN if there are no zeroes\n",
    "    # NB can also become NaN if Mean > Variance (I think)\n",
    "    # just in case, lets add this check for all of them\n",
    "    aic_scores = {'aic_zip': aic_zip, 'aic_zinb': aic_zinb, 'aic_nb': aic_nb, 'aic_pois': aic_pois, 'aic_gauss': aic_gauss, 'aic_exp': aic_exp}\n",
    "\n",
    "    for key in aic_scores:\n",
    "        if np.isnan(aic_scores[key]) | np.isinf(aic_scores[key]):\n",
    "            aic_scores[key] = 100000000\n",
    "\n",
    "    aic_zip, aic_zinb, aic_nb, aic_pois, aic_gauss, aic_exp = aic_scores.values()\n",
    "        \n",
    "    # in certain analyses, we might only want to look at certain distributions\n",
    "    # so we will make the AIC score high for those we don't care about\n",
    "    if (NB_ZINB_only == True):\n",
    "        aic_zip, aic_pois, aic_gauss, aic_exp = 10000000, 10000000, 10000000, 10000000\n",
    "    if (no_ZI_AICs == True):\n",
    "        aic_zip, aic_zinb = 10000000, 10000000\n",
    "    \n",
    "    print(aic_nb_orig, aic_nb, aic_gauss, aic_exp)\n",
    "\n",
    "    # Compare AICs and determine best fit\n",
    "    if (aic_nb < aic_pois ) & (aic_nb < aic_gauss) & (aic_nb < aic_exp) & (aic_nb < aic_zip) & (aic_nb < aic_zinb):\n",
    "        return \"NB\"\n",
    "    elif (aic_gauss < aic_nb) & (aic_gauss < aic_pois) & (aic_gauss < aic_exp) & (aic_gauss < aic_zip) & (aic_gauss < aic_zinb):\n",
    "        return \"Gaussian\"\n",
    "    elif (aic_exp < aic_nb) & (aic_exp < aic_pois) & (aic_exp < aic_gauss) & (aic_exp < aic_zip) & (aic_exp < aic_zinb):\n",
    "        return \"Exponential\"\n",
    "    elif (aic_zinb < aic_nb) & (aic_zinb < aic_pois) & (aic_zinb < aic_gauss) & (aic_zinb < aic_zip) & (aic_zinb < aic_exp):\n",
    "        return \"ZINB\"\n",
    "    elif (aic_zip < aic_nb) & (aic_zip < aic_pois) & (aic_zip < aic_gauss) & (aic_zip < aic_zinb) & (aic_zip < aic_exp):\n",
    "        return \"ZIP\"\n",
    "    else:\n",
    "        return \"Poisson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81954ab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T20:58:46.124162Z",
     "iopub.status.busy": "2024-03-26T20:58:46.124018Z",
     "iopub.status.idle": "2024-03-26T20:58:46.133651Z",
     "shell.execute_reply": "2024-03-26T20:58:46.133313Z"
    }
   },
   "outputs": [],
   "source": [
    "# this version of the function computes the same values but instead returns the \n",
    "# differential between the NB AIC and other distributions\n",
    "\n",
    "# row - a vector of expressions\n",
    "def manual_aic_distfromNB(row):\n",
    "    \n",
    "    row = np.round(row) # make it count data\n",
    "    # New Way - Trimmed Means\n",
    "    # trimmed mean to remove outliers\n",
    "    n = len(row)\n",
    "    \n",
    "    if (trim_means_flag):\n",
    "        elements_to_trim = int(np.floor(trim_percent / 100.0 * n))  \n",
    "        sorted_data = np.sort(row)\n",
    "        \n",
    "        if (elements_to_trim > 0):\n",
    "            row = sorted_data[elements_to_trim:-elements_to_trim]\n",
    "        else: \n",
    "            row = sorted_data\n",
    "\n",
    "    \n",
    "    if (sum(row) <= 0):\n",
    "        return -9999\n",
    "\n",
    "    # Exponential parameters\n",
    "    lambda_exp = 1 / np.mean(row)\n",
    "    log_likelihood_exp = np.sum(expon.logpdf(row, scale=1/lambda_exp))\n",
    "    aic_exp = 2*1 - 2*log_likelihood_exp  # 1 parameter for exponential\n",
    "   \n",
    "\n",
    "    # NB parameters\n",
    "    mu_sample = np.mean(row)\n",
    "    var_sample = np.var(row)\n",
    "    if (mu_sample == var_sample):\n",
    "        var_sample = var_sample + 0.0000000000001\n",
    "    r_estimated = mu_sample**2 / (var_sample - mu_sample)\n",
    "    \n",
    "    if (mu_sample + r_estimated) == 0:\n",
    "        r_estimated = r_estimated + 0.0000000000001\n",
    "    p_estimated = r_estimated / (mu_sample + r_estimated)\n",
    "    log_likelihood_nb = np.sum(nbinom.logpmf(row, r_estimated, p_estimated))\n",
    "    aic_nb = 2*2 - 2*log_likelihood_nb  # 2 parameters for NB\n",
    "\n",
    "    # ZINB parameters\n",
    "    pi_zinb = np.mean(row == 0)\n",
    "    log_likelihood_zeros = np.sum(np.log(pi_zinb) * (row == 0))\n",
    "    log_likelihood_non_zeros = np.sum(np.log(1 - pi_zinb) + nbinom.logpmf(row[row != 0], r_estimated, p_estimated))\n",
    "    log_likelihood_zinb = log_likelihood_zeros + log_likelihood_non_zeros\n",
    "    aic_zinb = 2*3 - 2*log_likelihood_zinb  # 3 parameters for ZINB: pi, r, and p\n",
    "\n",
    "    # Gaussian parameters\n",
    "    mu_gauss = np.mean(row)\n",
    "    sigma_gauss = np.std(row)\n",
    "    log_likelihood_gauss = np.sum(norm.logpdf(row, mu_gauss, sigma_gauss))\n",
    "    aic_gauss = 2*2 - 2*log_likelihood_gauss  # 2 parameters for Gaussian: mu and sigma\n",
    "\n",
    "   \n",
    "\n",
    "    # Poisson parameters\n",
    "    lambda_pois = np.mean(row)\n",
    "    log_likelihood_pois = np.sum(poisson.logpmf(row, lambda_pois))\n",
    "    aic_pois = 2*1 - 2*log_likelihood_pois  # 1 parameter for Poisson: lambda\n",
    "\n",
    "    # ZIP parameters\n",
    "    pi_zip = np.mean(row == 0)\n",
    "    lambda_zip = np.mean(row[row != 0])\n",
    "    log_likelihood_zeros_zip = np.sum(np.log(pi_zip) * (row == 0))\n",
    "    log_likelihood_non_zeros_zip = np.sum(np.log(1 - pi_zip) + poisson.logpmf(row[row != 0], lambda_zip))\n",
    "    log_likelihood_zip = log_likelihood_zeros_zip + log_likelihood_non_zeros_zip\n",
    "    aic_zip = 2*2 - 2*log_likelihood_zip  # 2 parameters for ZIP: pi and lambda\n",
    "    \n",
    "    # ZIP and ZINB can be NaN if there are no zeroes; similarly, NB is NaN if Mean > Variance\n",
    "    # to account for this, lets set them to a very high AIC if this occurs\n",
    "    aic_scores = {'aic_zip': aic_zip, 'aic_zinb': aic_zinb, 'aic_nb': aic_nb, 'aic_pois': aic_pois, 'aic_gauss': aic_gauss, 'aic_exp': aic_exp}\n",
    "\n",
    "    for key in aic_scores:\n",
    "        if np.isnan(aic_scores[key]):\n",
    "            aic_scores[key] = 1000000000\n",
    "\n",
    "    aic_zip, aic_zinb, aic_nb, aic_pois, aic_gauss, aic_exp = aic_scores.values()\n",
    "\n",
    "    if (NB_ZINB_only == True):\n",
    "        aic_zip, aic_pois, aic_gauss, aic_exp = 10000000, 10000000, 10000000, 10000000\n",
    "    if (no_ZI_AICs == True):\n",
    "        aic_zip, aic_zinb = 10000000, 10000000\n",
    "\n",
    "    # Compare AICs and determine best fit\n",
    "    if (aic_nb < aic_pois ) & (aic_nb < aic_gauss) & (aic_nb < aic_exp) & (aic_nb < aic_zip) & (aic_nb < aic_zinb):\n",
    "        return 0\n",
    "    elif (aic_gauss < aic_nb) & (aic_gauss < aic_pois) & (aic_gauss < aic_exp) & (aic_gauss < aic_zip) & (aic_gauss < aic_zinb):\n",
    "        return (aic_nb - aic_gauss)/aic_gauss\n",
    "    elif (aic_exp < aic_nb) & (aic_exp < aic_pois) & (aic_exp < aic_gauss) & (aic_exp < aic_zip) & (aic_exp < aic_zinb):\n",
    "        return (aic_nb - aic_exp)/aic_exp\n",
    "    elif (aic_zinb < aic_nb) & (aic_zinb < aic_pois) & (aic_zinb < aic_gauss) & (aic_zinb < aic_zip) & (aic_zinb < aic_exp):\n",
    "        return (aic_nb - aic_zinb)/aic_zinb\n",
    "    elif (aic_zip < aic_nb) & (aic_zip < aic_pois) & (aic_zip < aic_gauss) & (aic_zip < aic_zinb) & (aic_zip < aic_exp):\n",
    "        return (aic_nb - aic_zip)/aic_zip\n",
    "    else:\n",
    "        return (aic_nb - aic_pois)/aic_pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bcc1d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T20:58:46.135051Z",
     "iopub.status.busy": "2024-03-26T20:58:46.134913Z",
     "iopub.status.idle": "2024-03-26T20:58:49.969015Z",
     "shell.execute_reply": "2024-03-26T20:58:49.966174Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is a dataset with 528 FFPE breast cancer samples, sequenced from a HiSeq\n",
    "\n",
    "data = pd.read_csv('/path/to/7_datasets/third_party/GSE167977_third_party_ffpe/GSE167977_Raw_Counts.txt',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "# filter and compute dispersion\n",
    "# dispersion of tumours - All Data\n",
    "tumours_counts = pd.DataFrame(data)\n",
    "tumours_counts = tumours_counts.drop(tumours_counts.columns[0], axis=1) # column 1\n",
    "tumours_counts = tumours_counts.drop(tumours_counts.columns[-5:], axis=1) # last 5 columns\n",
    "\n",
    "# adjust for library size (fraction method)\n",
    "# should come before the gene filter\n",
    "tumours_counts_lib_adjust = library_adjust(tumours_counts)\n",
    "\n",
    "fraction_of_zeroes = (tumours_counts_lib_adjust == 0).mean(axis=1)\n",
    "filtered_df = tumours_counts_lib_adjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "print(filtered_df.shape)\n",
    "\n",
    "dataset_stats = dataset_stats_generator(filtered_df, draw_zero_distribution=True)\n",
    "print(\"Average Library Size: \", dataset_stats[0])\n",
    "print(\"Fraction of Zeroes: \", dataset_stats[1])\n",
    "print(\"Average Mean Expression: \", dataset_stats[2])\n",
    "\n",
    "# print(dataset_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd273d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T20:58:49.972451Z",
     "iopub.status.busy": "2024-03-26T20:58:49.971601Z",
     "iopub.status.idle": "2024-03-26T20:58:49.976611Z",
     "shell.execute_reply": "2024-03-26T20:58:49.976176Z"
    }
   },
   "outputs": [],
   "source": [
    "if(calc_AIC_dist):\n",
    "\n",
    "    print(\"GSE167977 - How off NB is to the winning distribution\")\n",
    "    aic_off = filtered_df.apply(manual_aic_distfromNB, axis=1)\n",
    "    print(aic_off)\n",
    "\n",
    "    # I want the average, and I want to eliminate -9999 (that's if all genes are zeroes)\n",
    "    mask = (aic_off != 0) & (aic_off > -9999)\n",
    "\n",
    "    median_off = np.median(aic_off[mask])\n",
    "    print(\"NB AIC is usually: \", median_off)\n",
    "    count_less_than_10 = np.sum(aic_off[mask] < 0.01)\n",
    "    count_greater_equal_10 = np.sum(aic_off[mask] >= 0.01)\n",
    "\n",
    "    print(f\"Count of values < 1%: {count_less_than_10}\")\n",
    "    print(f\"Count of values >= 1%: {count_greater_equal_10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91bc27d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T20:58:49.978532Z",
     "iopub.status.busy": "2024-03-26T20:58:49.978306Z",
     "iopub.status.idle": "2024-03-26T21:45:45.075994Z",
     "shell.execute_reply": "2024-03-26T21:45:45.075382Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function to compute by row\n",
    "print(\"GSE167977 - Lowest AIC across all genes\")\n",
    "\n",
    "aic_values = filtered_df.apply(manual_aic, axis=1)\n",
    "# print(aic_values)    \n",
    "AIC_top_rank_GSE167977 = aic_values.value_counts()\n",
    "print(AIC_top_rank_GSE167977)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31373a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2903f74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T21:45:45.080868Z",
     "iopub.status.busy": "2024-03-26T21:45:45.080624Z",
     "iopub.status.idle": "2024-03-26T21:45:45.855248Z",
     "shell.execute_reply": "2024-03-26T21:45:45.854701Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/path/to/7_datasets/third_party/GSE181466_third_party_ffpe/GSE181466_rsem_genes_matrix-97.txt',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "# patient information splitting is unnecessary, this appears to all be both FFPE and from tumours\n",
    "# there is subtype and age information in the series matrix file, if we're interested\n",
    "\n",
    "# dispersion of tumours - All Data\n",
    "tumours_counts = pd.DataFrame(data)\n",
    "# removing gene column at position 0\n",
    "tumours_counts = tumours_counts.drop(tumours_counts.columns[0], axis=1)\n",
    "# skip genes that are all zeroes, or just one spurrious read somewhere\n",
    "\n",
    "# adjust for library size (fraction method)\n",
    "tumours_counts_libadjust = library_adjust(tumours_counts)\n",
    "\n",
    "fraction_of_zeroes = (tumours_counts_libadjust == 0).mean(axis=1)\n",
    "filtered_df = tumours_counts_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "print(filtered_df.shape)\n",
    "\n",
    "dataset_stats = dataset_stats_generator(filtered_df)\n",
    "print(\"Average Library Size: \", dataset_stats[0])\n",
    "print(\"Fraction of Zeroes: \", dataset_stats[1])\n",
    "print(\"Average Mean Expression: \", dataset_stats[2])\n",
    "print(dataset_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933efedc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T21:45:45.857085Z",
     "iopub.status.busy": "2024-03-26T21:45:45.856932Z",
     "iopub.status.idle": "2024-03-26T21:45:45.860554Z",
     "shell.execute_reply": "2024-03-26T21:45:45.860118Z"
    }
   },
   "outputs": [],
   "source": [
    "if (calc_AIC_dist):\n",
    "    print(\"GSE181466 - How off NB is to the winning distribution\")\n",
    "    aic_off = filtered_df.apply(manual_aic_distfromNB, axis=1)\n",
    "    print(aic_off)\n",
    "\n",
    "    # I want the average, and I want to eliminate -9999 (that's if all genes are zeroes)\n",
    "    mask = (aic_off != 0) & (aic_off > -9999)\n",
    "\n",
    "    median_off = np.median(aic_off[mask])\n",
    "    print(\"NB AIC is usually: \", median_off)\n",
    "    count_less_than_10 = np.sum(aic_off[mask] < 0.01)\n",
    "    count_greater_equal_10 = np.sum(aic_off[mask] >= 0.01)\n",
    "\n",
    "    print(f\"Count of values < 1%: {count_less_than_10}\")\n",
    "    print(f\"Count of values >= 1: {count_greater_equal_10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477de0d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T21:45:45.862588Z",
     "iopub.status.busy": "2024-03-26T21:45:45.862269Z",
     "iopub.status.idle": "2024-03-26T21:52:54.957006Z",
     "shell.execute_reply": "2024-03-26T21:52:54.955715Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"GSE181466\")\n",
    "\n",
    "aic_values = filtered_df.apply(manual_aic, axis=1)\n",
    "print(aic_values)    \n",
    "AIC_top_rank_GSE181466 = aic_values.value_counts()\n",
    "print(AIC_top_rank_GSE181466)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e85296a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9cd8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T21:52:54.965954Z",
     "iopub.status.busy": "2024-03-26T21:52:54.965721Z",
     "iopub.status.idle": "2024-03-26T21:52:57.607664Z",
     "shell.execute_reply": "2024-03-26T21:52:57.607211Z"
    }
   },
   "outputs": [],
   "source": [
    "## here, we will repeat our plots but for a different data set\n",
    "all_counts = pyreadr.read_r('/path/to/7_datasets/third_party/GSE146889_third_party_ffpe/GSE146889_GeneCount.rds')\n",
    "df = all_counts[None] # load all_counts into a pandas data frame\n",
    "\n",
    "# we need to split the tumors and normals by name\n",
    "count_TUMOR = df.filter(like='tumor')\n",
    "count_NORMAL = df.filter(like='normal')\n",
    "\n",
    "#filtered_tumour = count_TUMOR[count_TUMOR.sum(axis=1) > 1]\n",
    "#filtered_normal = count_NORMAL[count_NORMAL.sum(axis=1) > 1]\n",
    "\n",
    "# adjust for library size (fraction method)\n",
    "count_TUMOR_libadjust = library_adjust(count_TUMOR)\n",
    "\n",
    "fraction_of_zeroes = (count_TUMOR_libadjust == 0).mean(axis=1)\n",
    "filtered_tumour = count_TUMOR_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "print(\"Tumours (GSE146889)\")\n",
    "dataset_stats = dataset_stats_generator(filtered_tumour)\n",
    "print(\"Average Library Size: \", dataset_stats[0])\n",
    "print(\"Fraction of Zeroes: \", dataset_stats[1])\n",
    "print(\"Average Mean Expression: \", dataset_stats[2])\n",
    "print(count_TUMOR_libadjust.shape)\n",
    "print(filtered_tumour.shape)\n",
    "\n",
    "#print(dataset_stats)\n",
    "# adjust for library size (fraction method)\n",
    "count_NORMAL_libadjust = library_adjust(count_NORMAL)\n",
    "\n",
    "fraction_of_zeroes = (count_NORMAL_libadjust == 0).mean(axis=1)\n",
    "filtered_normal = count_NORMAL_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "print(\"Normals\")\n",
    "dataset_stats = dataset_stats_generator(filtered_normal)\n",
    "print(\"Average Library Size: \", dataset_stats[0])\n",
    "print(\"Fraction of Zeroes: \", dataset_stats[1])\n",
    "print(\"Average Mean Expression: \", dataset_stats[2])\n",
    "#print(dataset_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad1075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T21:52:57.612425Z",
     "iopub.status.busy": "2024-03-26T21:52:57.611949Z",
     "iopub.status.idle": "2024-03-26T22:05:44.638291Z",
     "shell.execute_reply": "2024-03-26T22:05:44.627641Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"GSE146889 - Tumours\")\n",
    "\n",
    "aic_values = filtered_tumour.apply(manual_aic, axis=1)\n",
    "print(aic_values)    \n",
    "AIC_top_rank_GSE146889_tumours = aic_values.value_counts()\n",
    "print(AIC_top_rank_GSE146889_tumours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d578082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T22:05:44.645260Z",
     "iopub.status.busy": "2024-03-26T22:05:44.645017Z",
     "iopub.status.idle": "2024-03-26T22:17:56.716179Z",
     "shell.execute_reply": "2024-03-26T22:17:56.713528Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"GSE146889 - Normal\")\n",
    "\n",
    "aic_values = filtered_normal.apply(manual_aic, axis=1)\n",
    "print(aic_values)    \n",
    "AIC_top_rank_GSE146889_normals = aic_values.value_counts()\n",
    "print(AIC_top_rank_GSE146889_normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe899f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98a72f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T22:17:56.724762Z",
     "iopub.status.busy": "2024-03-26T22:17:56.724380Z",
     "iopub.status.idle": "2024-03-26T22:17:59.929221Z",
     "shell.execute_reply": "2024-03-26T22:17:59.928462Z"
    }
   },
   "outputs": [],
   "source": [
    "all_counts = pyreadr.read_r('/path/to/7_datasets/third_party/GSE209998_third_party_ffpe/GSE209998_GeneCount.rds')\n",
    "sample_information = pyreadr.read_r('/path/to/7_datasets/third_party/GSE209998_third_party_ffpe/GSE209998_Sample_Data.rds')\n",
    "\n",
    "# now we want to isolate just the expression from a particular type of tissue\n",
    "df_counts = all_counts[None] # load all_counts into a pandas data frame\n",
    "df_sample = sample_information[None] # load all_counts into a pandas data frame\n",
    "\n",
    "# here, we need to match if a sample is normal or tumour by !Sample_source_name_ch1 row\n",
    "\n",
    "# so I need to: 1) match columns between sample_information and all_counts \n",
    "# are they in the same order\n",
    "columns_df1 = df_counts.columns\n",
    "columns_df2 = df_sample.columns\n",
    "\n",
    "# Now we find what samples were tumours and what were normal\n",
    "samples_row = df_sample.loc[\"!Sample_source_name_ch1\"]\n",
    "\n",
    "split_dfs = {}\n",
    "for sample_type in samples_row.unique():\n",
    "    matching_columns = [col for col in df_counts.columns if col in df_sample.columns and samples_row[col] == sample_type]\n",
    "    split_dfs[sample_type] = df_counts[matching_columns]\n",
    "\n",
    "sample_source = df_sample.loc[\"!Sample_source\"]\n",
    "\n",
    "split_source = {}\n",
    "for sample_type in sample_source.unique():\n",
    "    matching_columns = [col for col in df_counts.columns if col in df_sample.columns and sample_source[col] == sample_type]\n",
    "    split_source[sample_type] = df_counts[matching_columns]\n",
    "\n",
    "\n",
    "count_FRESH = split_source[\"Fresh frozen\"]\n",
    "count_FFPE = split_source[\"FFPE\"]\n",
    "\n",
    "#filtered_ffpe = count_FFPE[count_FFPE.sum(axis=1) > 1]\n",
    "# adjust for library size (fraction method)\n",
    "count_FFPE_libadjust = library_adjust(count_FFPE)\n",
    "fraction_of_zeroes = (count_FFPE_libadjust == 0).mean(axis=1)\n",
    "filtered_ffpe = np.round(count_FFPE_libadjust[fraction_of_zeroes < (1 - express_percent_limit)]) # must be expressed to this percentage of patients\n",
    "\n",
    "print(\"FFPE\")\n",
    "dataset_stats = dataset_stats_generator(filtered_ffpe)\n",
    "print(\"Average Library Size: \", dataset_stats[0])\n",
    "print(\"Fraction of Zeroes: \", dataset_stats[1])\n",
    "print(\"Average Mean Expression: \", dataset_stats[2])\n",
    "# print(dataset_stats)\n",
    "\n",
    "print(\"FFPE\", filtered_ffpe.shape)\n",
    "\n",
    "\n",
    "# adjust for library size (fraction method)\n",
    "count_FRESH_libadjust = library_adjust(count_FRESH)\n",
    "fraction_of_zeroes = (count_FRESH_libadjust == 0).mean(axis=1)\n",
    "filtered_fresh = np.round(count_FRESH_libadjust[fraction_of_zeroes < (1 - express_percent_limit)]) # must be expressed to this percentage of patients\n",
    "print(\"Fresh\", filtered_fresh.shape[1])\n",
    "\n",
    "dataset_stats = dataset_stats_generator(filtered_fresh)\n",
    "print(\"Average Library Size: \", dataset_stats[0])\n",
    "print(\"Fraction of Zeroes: \", dataset_stats[1])\n",
    "print(\"Average Mean Expression: \", dataset_stats[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c73f758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T22:17:59.931473Z",
     "iopub.status.busy": "2024-03-26T22:17:59.931253Z",
     "iopub.status.idle": "2024-03-26T22:35:31.665747Z",
     "shell.execute_reply": "2024-03-26T22:35:31.664703Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"GSE209998 - FFPE Tumours\")\n",
    "\n",
    "aic_values = filtered_ffpe.apply(manual_aic, axis=1)\n",
    "print(aic_values)    \n",
    "AIC_top_rank_GSE209998_ffpe = aic_values.value_counts()\n",
    "print(AIC_top_rank_GSE209998_ffpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579cb9e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T22:35:31.668265Z",
     "iopub.status.busy": "2024-03-26T22:35:31.668037Z",
     "iopub.status.idle": "2024-03-26T22:52:16.425550Z",
     "shell.execute_reply": "2024-03-26T22:52:16.424851Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"GSE209998 - Fresh/Frozen Tumours\")\n",
    "\n",
    "aic_values = filtered_fresh.apply(manual_aic, axis=1)\n",
    "print(aic_values)    \n",
    "AIC_top_rank_GSE209998_fresh = aic_values.value_counts()\n",
    "print(AIC_top_rank_GSE209998_fresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06eee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a7770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb4399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T22:52:16.441866Z",
     "iopub.status.busy": "2024-03-26T22:52:16.441644Z",
     "iopub.status.idle": "2024-03-26T22:52:18.048131Z",
     "shell.execute_reply": "2024-03-26T22:52:18.047595Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/path/to/7_datasets/third_party/GSE47462_third_party_ffpe/GSE47462_Raw_counts_Refseq_genes.txt',\n",
    "                  delimiter='\\t')\n",
    "# Split the DataFrame into subsets based on column names indicating sample type\n",
    "normal_data = data.filter(like='_normal')\n",
    "EN_data = data.filter(like='_EN')\n",
    "DCIS_data = data.filter(like='_DCIS')\n",
    "IDC_data = data.filter(like='_IDC')\n",
    "\n",
    "# since there isn't a ton of data, I also want to group tumors\n",
    "tumours_data = data.loc[:, ~data.columns.str.contains('_normal')]\n",
    "tumours_data = tumours_data.iloc[:, 1:]\n",
    "\n",
    "#filtered_tumour = tumours_counts[tumours_counts.sum(axis=1) > 1]\n",
    "#filtered_normal = normal_counts[normal_counts.sum(axis=1) > 1]\n",
    "\n",
    "# adjust for library size (fraction method)\n",
    "tumours_data_libadjust = library_adjust(tumours_data)\n",
    "fraction_of_zeroes = (tumours_data_libadjust == 0).mean(axis=1)\n",
    "filtered_tumour = tumours_data_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "normal_data_libadjust = library_adjust(normal_data)\n",
    "fraction_of_zeroes = (normal_data_libadjust == 0).mean(axis=1)\n",
    "filtered_normal = normal_data_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "print(filtered_tumour.shape)\n",
    "print(filtered_normal.shape)\n",
    "\n",
    "print(\"Tumour\")\n",
    "dataset_stats = dataset_stats_generator(filtered_tumour)\n",
    "print(\"Average Library Size: \", dataset_stats[0])\n",
    "print(\"Fraction of Zeroes: \", dataset_stats[1])\n",
    "print(\"Average Mean Expression: \", dataset_stats[2])\n",
    "# print(dataset_stats)\n",
    "\n",
    "print(\"Normal\")\n",
    "dataset_stats = dataset_stats_generator(filtered_normal)\n",
    "print(\"Average Library Size: \", dataset_stats[0])\n",
    "print(\"Fraction of Zeroes: \", dataset_stats[1])\n",
    "print(\"Average Mean Expression: \", dataset_stats[2])\n",
    "# print(dataset_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e141e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T22:52:18.055985Z",
     "iopub.status.busy": "2024-03-26T22:52:18.055664Z",
     "iopub.status.idle": "2024-03-26T23:00:16.754682Z",
     "shell.execute_reply": "2024-03-26T23:00:16.753594Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"GSE47462 - Tumours\")\n",
    "\n",
    "aic_values = filtered_tumour.apply(manual_aic, axis=1)\n",
    "print(aic_values)    \n",
    "AIC_top_rank_GSE47462_tumours = aic_values.value_counts()\n",
    "print(AIC_top_rank_GSE47462_tumours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb29ed55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T23:00:16.757880Z",
     "iopub.status.busy": "2024-03-26T23:00:16.757635Z",
     "iopub.status.idle": "2024-03-26T23:07:50.044187Z",
     "shell.execute_reply": "2024-03-26T23:07:50.043025Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"GSE47462 - Normal\")\n",
    "# aic_values = filtered_normal.apply(best_fit, axis=1)\n",
    "aic_values = filtered_normal.apply(manual_aic, axis=1)\n",
    "print(aic_values)    \n",
    "AIC_top_rank_GSE47462_normals = aic_values.value_counts()\n",
    "print(AIC_top_rank_GSE47462_normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737f7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673e2662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T23:07:50.047808Z",
     "iopub.status.busy": "2024-03-26T23:07:50.047546Z",
     "iopub.status.idle": "2024-03-26T23:07:51.106022Z",
     "shell.execute_reply": "2024-03-26T23:07:51.105534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv('/path/to/7_datasets/third_party/GSE120795_third_party_ffpe/GSE120795_total_norms_raw_counts.tsv',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "# in the series matrix\"disease: healthy\", \n",
    "patient_info = pd.read_csv('/path/to/7_datasets/third_party/GSE120795_third_party_ffpe/GSE120795_cell_info.txt',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "# this filter is present because those filtered out were not FFPE (blood and bone marrow)\n",
    "mask = patient_info.iloc[0] == \"healthy\"\n",
    "\n",
    "filtered_data = patient_info.loc[:, mask]\n",
    "patient_names = filtered_data.columns\n",
    "column_names_with_extension = [name + \".fastq.gz\" for name in patient_names]\n",
    "column_names_with_extension = column_names_with_extension[1:]\n",
    "\n",
    "# Assuming 'second_list' is the list where you want to filter based on column names\n",
    "filtered_data = data[column_names_with_extension]\n",
    "ffpe_counts = pd.DataFrame(filtered_data)\n",
    "#filtered_data = ffpe_counts[ffpe_counts.sum(axis=1) > 1]\n",
    "print(ffpe_counts.shape)\n",
    "\n",
    "ffpe_counts_libadjust = library_adjust(ffpe_counts)\n",
    "fraction_of_zeroes = (ffpe_counts_libadjust == 0).mean(axis=1)\n",
    "filtered_data = ffpe_counts_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "print(filtered_data.shape)\n",
    "\n",
    "dataset_stats = dataset_stats_generator(filtered_data)\n",
    "print(\"Average Library Size: \", dataset_stats[0])\n",
    "print(\"Fraction of Zeroes: \", dataset_stats[1])\n",
    "print(\"Average Mean Expression: \", dataset_stats[2])\n",
    "print(dataset_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b47a99a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T23:07:51.108597Z",
     "iopub.status.busy": "2024-03-26T23:07:51.108051Z",
     "iopub.status.idle": "2024-03-26T23:18:15.588933Z",
     "shell.execute_reply": "2024-03-26T23:18:15.579473Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"GSE120795 - Normal\")\n",
    "\n",
    "aic_values = filtered_data.apply(manual_aic, axis=1)\n",
    "print(aic_values)    \n",
    "AIC_top_rank_GSE120795_normals = aic_values.value_counts()\n",
    "print(AIC_top_rank_GSE120795_normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af532ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a213ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T23:18:15.595822Z",
     "iopub.status.busy": "2024-03-26T23:18:15.595529Z",
     "iopub.status.idle": "2024-03-26T23:18:16.829803Z",
     "shell.execute_reply": "2024-03-26T23:18:16.824639Z"
    }
   },
   "outputs": [],
   "source": [
    "# the GDC Count-Me-In Data\n",
    "data = pd.read_csv('/path/to/7_datasets/third_party/CountMeIn_BConly_third_party_ffpe/MBC_CMI_Compiled_Counts.tsv',\n",
    "                  delimiter=' ') # space delimited\n",
    "\n",
    "tumours_counts = pd.DataFrame(data)\n",
    "tumours_counts = tumours_counts.drop(tumours_counts.columns[:3], axis=1) # columns 1-3 should be ignored\n",
    "\n",
    "# library adjust; remove genes expressed < express_percent_limit\n",
    "tumours_counts_libadjust = library_adjust(tumours_counts)\n",
    "fraction_of_zeroes = (tumours_counts_libadjust == 0).mean(axis=1)\n",
    "filtered_df = tumours_counts_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "print(filtered_df.shape)\n",
    "\n",
    "dataset_stats = dataset_stats_generator(filtered_df)\n",
    "print(\"Average Library Size: \", dataset_stats[0])\n",
    "print(\"Fraction of Zeroes: \", dataset_stats[1])\n",
    "print(\"Average Mean Expression: \", dataset_stats[2])\n",
    "print(dataset_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb41814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T23:18:16.833605Z",
     "iopub.status.busy": "2024-03-26T23:18:16.833323Z",
     "iopub.status.idle": "2024-03-26T23:30:26.317336Z",
     "shell.execute_reply": "2024-03-26T23:30:26.315469Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Count Me In - Breast Cancer Only\")\n",
    "\n",
    "aic_values = filtered_df.apply(manual_aic, axis=1)\n",
    "print(aic_values)    \n",
    "AIC_top_rank_CMI = aic_values.value_counts()\n",
    "print(AIC_top_rank_CMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8d0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3de063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b0bb39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T23:30:26.320458Z",
     "iopub.status.busy": "2024-03-26T23:30:26.320283Z",
     "iopub.status.idle": "2024-03-26T23:30:32.706586Z",
     "shell.execute_reply": "2024-03-26T23:30:32.705947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Our dataset!\n",
    "all_counts = pyreadr.read_r('/path/to/7_datasets/dcis/expression_counts.Jan2023_1_2_and_2_2.rds')\n",
    "vst_norm = pyreadr.read_r('/path/to/7_datasets/dcis/expression_VST_Normalized.Jan2023_1_2_and_2_2.rds')\n",
    "\n",
    "# this data is loading without issue\n",
    "ship_data = pyreadr.read_r('/path/to/7_datasets/dcis/ship1_2_full_tbl.Jan2023.With_Stroma_Assignment.rds')\n",
    "\n",
    "# now we want to isolate just the expression from a particular type of tissue\n",
    "df = all_counts[None] # load all_counts into a pandas data frame\n",
    "\n",
    "# Eliminate any samples in the blacklist\n",
    "ship_df = ship_data[None]\n",
    "#print(ship_df['blacklist'].value_counts()) # they're all false\n",
    "\n",
    "# since ship_data already has patients filtered out, lets filter out any patient who isn't on the list\n",
    "# match by 'sample_name'\n",
    "df_blacklist_filtered = df[ship_df['sample_name']]\n",
    "\n",
    "# split the patients by tissue\n",
    "count_DCIS = df_blacklist_filtered.filter(like='_D')\n",
    "count_STROMA = df_blacklist_filtered.filter(like='_S')\n",
    "count_NORMAL = df_blacklist_filtered.filter(like='_N')\n",
    "\n",
    "# if we want consistency between the 3 sample types\n",
    "vst_table = vst_norm[None] # we don't apply this anymore because it blocks any gene with >80% frac_zero\n",
    "filtered_norm_count = count_NORMAL[count_NORMAL.index.isin(vst_table.index)]\n",
    "filtered_tumour_count = count_DCIS[count_DCIS.index.isin(vst_table.index)]\n",
    "filtered_stroma_count = count_STROMA[count_STROMA.index.isin(vst_table.index)]\n",
    "\n",
    "filtered_norm_count_libadjust = library_adjust(filtered_norm_count)\n",
    "fraction_of_zeroes = (filtered_norm_count_libadjust == 0).mean(axis=1)\n",
    "filtered_norm_count = filtered_norm_count_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "filtered_tumour_count_libadjust = library_adjust(filtered_tumour_count)\n",
    "fraction_of_zeroes = (filtered_tumour_count_libadjust == 0).mean(axis=1)\n",
    "filtered_tumour_count = filtered_tumour_count_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "filtered_stroma_count_libadjust = library_adjust(filtered_stroma_count)\n",
    "fraction_of_zeroes = (filtered_stroma_count_libadjust == 0).mean(axis=1)\n",
    "filtered_stroma_count = filtered_stroma_count_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "\n",
    "\n",
    "print(\"DCIS\")\n",
    "print(filtered_tumour_count.shape)\n",
    "dataset_stats = dataset_stats_generator(filtered_tumour_count)\n",
    "print(\"Average Library Size: \", dataset_stats[0])\n",
    "print(\"Fraction of Zeroes: \", dataset_stats[1])\n",
    "print(\"Average Mean Expression: \", dataset_stats[2])\n",
    "\n",
    "print(\"Stroma\")\n",
    "print(filtered_stroma_count.shape)\n",
    "dataset_stats = dataset_stats_generator(filtered_stroma_count)\n",
    "print(\"Average Library Size: \", dataset_stats[0])\n",
    "print(\"Fraction of Zeroes: \", dataset_stats[1])\n",
    "print(\"Average Mean Expression: \", dataset_stats[2])\n",
    "\n",
    "print(\"Normal\")\n",
    "print(filtered_norm_count.shape)\n",
    "dataset_stats = dataset_stats_generator(filtered_norm_count)\n",
    "print(\"Average Library Size: \", dataset_stats[0])\n",
    "print(\"Fraction of Zeroes: \", dataset_stats[1])\n",
    "print(\"Average Mean Expression: \", dataset_stats[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24cf0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T23:30:32.708784Z",
     "iopub.status.busy": "2024-03-26T23:30:32.708614Z",
     "iopub.status.idle": "2024-03-26T23:38:35.381494Z",
     "shell.execute_reply": "2024-03-26T23:38:35.380861Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Our Data: Tumours\")\n",
    "#print(filtered_tumour_count.head(10))\n",
    "\n",
    "aic_values = filtered_tumour_count.apply(manual_aic, axis=1)\n",
    "print(aic_values)    \n",
    "AIC_top_rank_DCIS = aic_values.value_counts()\n",
    "print(AIC_top_rank_DCIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4dbf5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T23:38:35.395479Z",
     "iopub.status.busy": "2024-03-26T23:38:35.395168Z",
     "iopub.status.idle": "2024-03-26T23:45:48.888441Z",
     "shell.execute_reply": "2024-03-26T23:45:48.887549Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Our Data: Normal\")\n",
    "\n",
    "aic_values = filtered_norm_count.apply(manual_aic, axis=1)\n",
    "print(aic_values)    \n",
    "AIC_top_rank_DCISNorm = aic_values.value_counts()\n",
    "print(AIC_top_rank_DCISNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5014be0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T23:45:48.893672Z",
     "iopub.status.busy": "2024-03-26T23:45:48.893464Z",
     "iopub.status.idle": "2024-03-26T23:53:23.054724Z",
     "shell.execute_reply": "2024-03-26T23:53:23.053633Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Our Data: Stroma\")\n",
    "\n",
    "aic_values = filtered_stroma_count.apply(manual_aic, axis=1)\n",
    "print(aic_values)    \n",
    "AIC_top_rank_DCISStrom = aic_values.value_counts()\n",
    "print(AIC_top_rank_DCISStrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057fbf5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T23:53:23.057417Z",
     "iopub.status.busy": "2024-03-26T23:53:23.057073Z",
     "iopub.status.idle": "2024-03-26T23:53:23.092068Z",
     "shell.execute_reply": "2024-03-26T23:53:23.091473Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a heatmap\n",
    "AIC_top_rank_GSE167977.name = \"GSE167977 (BC)\"\n",
    "AIC_top_rank_GSE181466.name = \"GSE181466 (TNBC)\"\n",
    "AIC_top_rank_GSE146889_tumours.name = \"GSE146889 (Colo./Endo.)\"\n",
    "AIC_top_rank_GSE146889_normals.name = \"GSE146889 (Normal)\"\n",
    "AIC_top_rank_GSE209998_ffpe.name = \"GSE209998 (BC|FFPE)\"\n",
    "AIC_top_rank_GSE209998_fresh.name = \"GSE209998 (BC|FRESH)\"\n",
    "AIC_top_rank_GSE47462_tumours.name = \"GSE47462 (BC)\"\n",
    "AIC_top_rank_GSE47462_normals.name = \"GSE47462 (Normal)\"\n",
    "AIC_top_rank_GSE120795_normals.name = \"GSE120795 (Normal)\"\n",
    "AIC_top_rank_CMI.name = \"TMBC Project\"\n",
    "AIC_top_rank_DCIS.name = \"DCIS (Tumour)\"\n",
    "AIC_top_rank_DCISNorm.name = \"DCIS (Normal)\"\n",
    "AIC_top_rank_DCISStrom.name = \"DCIS (Stroma)\"\n",
    "\n",
    "\n",
    "# lets combine the results in one large table\n",
    "# must adjust for events where one table is missing entries for a particular dist\n",
    "combined_table = pd.concat([\n",
    "    AIC_top_rank_GSE47462_tumours, AIC_top_rank_GSE47462_normals,\n",
    "    AIC_top_rank_GSE120795_normals, \n",
    "    AIC_top_rank_GSE146889_tumours, AIC_top_rank_GSE146889_normals,\n",
    "    AIC_top_rank_GSE167977, AIC_top_rank_GSE181466,\n",
    "    AIC_top_rank_GSE209998_ffpe, AIC_top_rank_GSE209998_fresh,\n",
    "    AIC_top_rank_CMI, AIC_top_rank_DCIS, AIC_top_rank_DCISNorm, AIC_top_rank_DCISStrom\n",
    "    ], axis=1)\n",
    "# print(combined_table)\n",
    "\n",
    "# change table to be based on percentages\n",
    "df_filled = combined_table.fillna(0)\n",
    "df_percent = df_filled.div(df_filled.sum(axis=0), axis=1) \n",
    "df_transposed = df_percent.T\n",
    "\n",
    "if 'ZEROES' in df_transposed.columns:\n",
    "    df_transposed = df_transposed.drop('ZEROES', axis=1)\n",
    "\n",
    "extra = \"All\"\n",
    "\n",
    "if (NB_ZINB_only == True):\n",
    "    new_order = ['NB', 'ZINB']\n",
    "    extra = \"NB_ZINB\"\n",
    "elif (no_ZI_AICs == True):\n",
    "    new_order = ['NB', 'Exponential', 'Gaussian', 'Poisson']\n",
    "    extra = \"No_ZI\"\n",
    "else:\n",
    "    new_order = ['NB', 'Exponential', 'Gaussian', 'Poisson', 'ZINB', 'ZIP']\n",
    "\n",
    "df_transposed = df_transposed[new_order]\n",
    "\n",
    "df_transposed.rename(columns={'Exponential': 'Gamma'}, inplace=True)\n",
    "\n",
    "print(df_transposed.round(3))\n",
    "\n",
    "lib_adj = \"No\"\n",
    "if (adjust_for_lib):\n",
    "    lib_adj = \"Yes\"\n",
    "\n",
    "df_transposed.to_csv('/data/lab_vm/refined/preffect/6_dispersion/6.0_Third_Party_Data_Distribution_Evaluation/Percent_Best_AIC_Table.ZeroFract_' + \n",
    "                     str(express_percent_limit) + \".Trim_\" + str(trim_percent) + \".Lib_Adj_\" + str(lib_adj) + \".\" + str(extra) + \".csv\" , index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c68a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T23:53:23.094462Z",
     "iopub.status.busy": "2024-03-26T23:53:23.094176Z",
     "iopub.status.idle": "2024-03-26T23:53:23.913860Z",
     "shell.execute_reply": "2024-03-26T23:53:23.913435Z"
    }
   },
   "outputs": [],
   "source": [
    "# lets use the table to create a heatmap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create the heatmap from percentage values above\n",
    "if (NB_ZINB_only == True):\n",
    "        # the NB/ZINB plot has just two rows so we should make it narrower\n",
    "        plt.figure(figsize=(3, 3.7))\n",
    "elif (no_ZI_AICs == True):\n",
    "        plt.figure(figsize=(4, 4))\n",
    "else: \n",
    "        plt.figure(figsize=(6, 4))\n",
    "\n",
    "\n",
    "\n",
    "heatmap = sns.heatmap(df_transposed, annot=True, fmt=\".2f\", cmap='crest_r', linewidths=.5,\n",
    "                      annot_kws={\"size\": 8, \"color\": 'w'},  # Set annotation text color to black\n",
    "                      cbar_kws={'shrink': 0.5, 'ticks': [0, 0.5, 1], 'format': '%.2f'})\n",
    "\n",
    "\n",
    "\n",
    "# make X/Y labels smaller\n",
    "plt.yticks(fontsize=7)\n",
    "plt.xticks(fontsize=7, rotation=60)\n",
    "\n",
    "# draw a horizontal line between certain rows\n",
    "gap_size = 3\n",
    "plt.axhline(y=2, color='honeydew', linewidth=gap_size)\n",
    "plt.axhline(y=3, color='honeydew', linewidth=gap_size)\n",
    "plt.axhline(y=5, color='honeydew', linewidth=gap_size)\n",
    "plt.axhline(y=6, color='honeydew', linewidth=gap_size)\n",
    "plt.axhline(y=7, color='honeydew', linewidth=gap_size)\n",
    "plt.axhline(y=9, color='honeydew', linewidth=gap_size)\n",
    "plt.axhline(y=10, color='honeydew', linewidth=gap_size)\n",
    "\n",
    "# wanted the color bar to display less digits\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=8)  \n",
    "cbar.set_ticks([cbar.vmin, 0, cbar.vmax])\n",
    "cbar.set_ticklabels([f'{cbar.vmin:.1f}', '0.0', f'{cbar.vmax:.1f}'])\n",
    "\n",
    "# Save and display the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('/path/to/6.0_Third_Party_Data_Distribution_Evaluation/Percent_Best_AIC_Table.ZeroFract_' + \n",
    "                     str(express_percent_limit) + \".Trim_\" + str(trim_percent) + \".Lib_Adj_\" + str(lib_adj) + \".\" + str(extra) +  \".pdf\",\n",
    "             dpi=300, bbox_inches='tight')  # dpi is dots per inch, for resolution\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Optional: Clear the figure after saving, so that future plt calls don't reuse the same figure\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
