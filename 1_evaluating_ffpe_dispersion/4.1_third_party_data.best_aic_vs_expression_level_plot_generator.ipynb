{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5640a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T21:49:18.571223Z",
     "iopub.status.busy": "2024-04-02T21:49:18.571030Z",
     "iopub.status.idle": "2024-04-02T21:49:18.575458Z",
     "shell.execute_reply": "2024-04-02T21:49:18.574652Z"
    }
   },
   "outputs": [],
   "source": [
    "# This program computes AIC of gene expression across various distributions\n",
    "# it then creates line plots that show how these AIC \"winners\" (those withl lowest AICs)\n",
    "# in genes segmented by: total read counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0debac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T21:49:18.580555Z",
     "iopub.status.busy": "2024-04-02T21:49:18.580032Z",
     "iopub.status.idle": "2024-04-02T21:49:19.648882Z",
     "shell.execute_reply": "2024-04-02T21:49:19.648080Z"
    }
   },
   "outputs": [],
   "source": [
    "# first lets read in scipy, as I'll need the \"curve_fit\" function in optimize\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "from scipy.special import psi\n",
    "from scipy.special import factorial\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import comb\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families import NegativeBinomial, Gamma\n",
    "from statsmodels.discrete.count_model import ZeroInflatedNegativeBinomialP\n",
    "\n",
    "from scipy.stats import expon, nbinom, norm, poisson\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# now the DCIS count data is found in an RDA file, which we apparently read using 'pyreadr'\n",
    "import pyreadr\n",
    "\n",
    "# thread issues\n",
    "os.environ['OMP_NUM_THREADS'] = '10'  # Limit to 1 thread\n",
    "os.environ['MKL_NUM_THREADS'] = '10'  # Limit to 1 thread for MKL (if used)\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '10'  # Limit to 1 thread for NumExpr (if used)\n",
    "\n",
    "\n",
    "# to convert Ensemble to Refseq gene names\n",
    "gene_convert = pyreadr.read_r('/path/to/dcis/gene_info/ensemble_to_refseq_gene_name_table.rds')\n",
    "gene_convert = gene_convert[None]\n",
    "id_to_name = {gene_id: gene_name for gene_id, gene_name in zip(gene_convert[\"gene_id\"], gene_convert[\"gene_name\"])}\n",
    "\n",
    "\n",
    "def qqplot_nb_vs_exp(data, path, gene_name):\n",
    "    \n",
    "    # Sample data for the Negative Binomial plot (replace this with your data)\n",
    "    \n",
    "    sorted_data = np.sort(data)\n",
    "    sorted_data = sorted_data[:-1] # remove top sample as it is often an outlier\n",
    "    # Estimate the parameters r and p using method of moments\n",
    "    mean_gene_expression = np.mean(sorted_data)\n",
    "    var_gene_expression = np.var(sorted_data)\n",
    "    p = mean_gene_expression / var_gene_expression\n",
    "    r = mean_gene_expression**2 / (var_gene_expression - mean_gene_expression)\n",
    "\n",
    "    # Calculate observed and theoretical quantiles for NB\n",
    "    observed_quantiles_nb = np.array([(i - 0.5) / len(sorted_data) for i in range(1, len(sorted_data) + 1)])\n",
    "    theoretical_quantiles_nb = stats.nbinom.ppf(observed_quantiles_nb, r, p)\n",
    "\n",
    "    # Estimate the rate parameter Î» (lambda) for the exponential distribution\n",
    "    lambda_est = 1 / np.mean(sorted_data)\n",
    "\n",
    "    # Calculate observed and theoretical quantiles for Exponential\n",
    "    observed_quantiles_exponential = np.array([(i - 0.5) / len(sorted_data) for i in range(1, len(sorted_data) + 1)])\n",
    "    theoretical_quantiles_exponential = stats.expon.ppf(observed_quantiles_exponential, scale=1/lambda_est)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n",
    "\n",
    "    # Plot the Negative Binomial QQ plot on the left\n",
    "    ax1.scatter(theoretical_quantiles_nb, sorted_data, label='NB QQ Plot')\n",
    "    ax1.plot([min(theoretical_quantiles_nb), max(theoretical_quantiles_nb)], [min(sorted_data), max(sorted_data)], 'r--')\n",
    "    ax1.set_title(f'Negative Binomial QQ Plot: {gene_name}', fontsize = 10)\n",
    "    ax1.set_xlabel('Theoretical Quantiles', fontsize = \"small\")\n",
    "    ax1.set_ylabel('Sample Quantiles', fontsize = \"small\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Plot the Exponential QQ plot on the right\n",
    "    ax2.scatter(theoretical_quantiles_exponential, sorted_data, label='Exponential QQ Plot')\n",
    "    ax2.plot([min(theoretical_quantiles_exponential), max(theoretical_quantiles_exponential)], [min(sorted_data), max(sorted_data)], 'r--')\n",
    "    ax2.set_title(f'Exponential QQ Plot: {gene_name}', fontsize = 10)\n",
    "    ax2.set_xlabel('Theoretical Quantiles', fontsize = \"small\")\n",
    "    ax2.set_ylabel('Sample Quantiles', fontsize = \"small\")\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Adjust layout and display\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    image_name = f'{gene_name}.png'\n",
    "    full_path = os.path.join(path, image_name)\n",
    "    plt.savefig(full_path, dpi=100)\n",
    "    #plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae620d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T21:49:19.653198Z",
     "iopub.status.busy": "2024-04-02T21:49:19.652883Z",
     "iopub.status.idle": "2024-04-02T21:49:19.656971Z",
     "shell.execute_reply": "2024-04-02T21:49:19.656403Z"
    }
   },
   "outputs": [],
   "source": [
    "### Parameters ###\n",
    "\n",
    "# whether or not we're doing outlier removal using trimmed means\n",
    "trim_means_flag = True\n",
    "trim_percent = 10 # 1% usually gets rid of most extreme outliers\n",
    "\n",
    "# genes must be expressed in this % of patients (between 0-1)\n",
    "express_percent_limit = 0.2 # set to 0 if you want patient stats (all genes with at least 1 read), set to 0.2 if we want AIC stats of genes with >20% expression\n",
    "\n",
    "# library adjust (using fractional method)\n",
    "adjust_for_lib = False\n",
    "\n",
    "# calculate AIC distance\n",
    "calc_AIC_dist = False # False saves time when running the full program\n",
    "\n",
    "# a flag if we want to just do \"no ZI\" or \"NB vs ZINB only\"\n",
    "NB_ZINB_only = False # Only comparing NB to ZINB [trim_percent should be low, maybe even zero]\n",
    "\n",
    "# trim will remove zeroes, so I don't think we should activate trim when doing NB/ZINB comparison\n",
    "if (NB_ZINB_only == True):\n",
    "    trim_percent = 0\n",
    "\n",
    "no_ZI_AICs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18ec20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T21:49:19.659933Z",
     "iopub.status.busy": "2024-04-02T21:49:19.659780Z",
     "iopub.status.idle": "2024-04-02T21:49:19.667270Z",
     "shell.execute_reply": "2024-04-02T21:49:19.666712Z"
    }
   },
   "outputs": [],
   "source": [
    "# non-AIC related functions used in this program    \n",
    "\n",
    "# computation of gene average, fraction of zeroes, and library size\n",
    "def dataset_stats_generator(df, draw_zero_distribution = True):\n",
    "    num_genes = df.shape[0]\n",
    "    num_samples = df.shape[1]\n",
    "    # Compute the metrics for each row\n",
    "    row_sums = df.sum(axis = 0)\n",
    "    fraction_zero_samples = (df == 0).sum(axis=0) / num_genes\n",
    "    fraction_zero_genes = (df == 0).sum(axis=1) / num_samples\n",
    "    row_means = df.mean(axis=1)\n",
    "\n",
    "    if (draw_zero_distribution):\n",
    "        plt.hist(fraction_zero_genes, bins=100, color='blue', alpha=0.7)\n",
    "        plt.xlabel('Fraction of Zeroes (Genes)')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title(\"Fraction of Zeroes per Gene\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.hist(fraction_zero_samples, bins=100, color='blue', alpha=0.7)\n",
    "        plt.xlabel('Fraction of Zeroes (Samples)')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title(\"Fraction of Zeroes per Sample\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.hist(row_means, bins=100, color='blue', alpha=0.7)\n",
    "        plt.xlabel('Means of Gene Expression')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title(\"Distribution of Means of Genes in Dataset\")\n",
    "        plt.show()\n",
    "      \n",
    "    # get the average of these \n",
    "    avg_library_size = np.round(np.sum(row_sums) / num_samples, decimals = 0)\n",
    "    avg_zeroes = np.round(np.sum(fraction_zero_samples) / num_samples, decimals = 3)\n",
    "    avg_mean_expression = np.round(np.mean(row_means), decimals = 3)\n",
    "    \n",
    "    # print(\"Avg Library Size\", \"Avg Fraction Zeroes\", \"Avg Mean Expression\")\n",
    "    return avg_library_size, avg_zeroes, avg_mean_expression\n",
    "\n",
    "# Simulating some data for illustration\n",
    "#data = np.random.negative_binomial(10, 0.5, 1000)\n",
    "\n",
    "def fit_to_nb_plot(data, plotrange = 30):\n",
    "\n",
    "    # Estimating parameters directly from data\n",
    "    mean = np.mean(data)\n",
    "    var = np.var(data)\n",
    "    p = 1 - (mean / var)\n",
    "    n = mean * (1 - p) / p\n",
    "\n",
    "    # Plotting\n",
    "    plt.hist(data, bins=range(plotrange), align='left', density=True, alpha=0.6, color='g')\n",
    "    plt.plot(bins[:-1], nbinom.pmf(bins[:-1], n, p), 'ro-', lw=2)\n",
    "    plt.title(\"Negative Binomial Fit\")\n",
    "    plt.show()\n",
    "\n",
    "# adjust for library sizes\n",
    "def library_adjust(data):\n",
    "    if (adjust_for_lib):\n",
    "        library_size = data.sum(axis=0)\n",
    "        \n",
    "        cleaned_matrix = np.round((data /library_size)*10000000)\n",
    "        return cleaned_matrix\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c579e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T21:49:19.670120Z",
     "iopub.status.busy": "2024-04-02T21:49:19.669973Z",
     "iopub.status.idle": "2024-04-02T21:49:19.674866Z",
     "shell.execute_reply": "2024-04-02T21:49:19.674327Z"
    }
   },
   "outputs": [],
   "source": [
    "# functions to compute ZINB\n",
    "\n",
    "def zinb_loglike(params, counts):\n",
    "    mu, theta, pi = params\n",
    "    p = 1 / (1 + mu/theta)\n",
    "    n = mu * p / (1 - p)\n",
    "    loglik_pois = nbinom.logpmf(counts, n, p)\n",
    "    loglik_zero = np.log(pi + (1 - pi) * np.exp(nbinom.logpmf(0, n, p)))\n",
    "    loglik = np.where(counts == 0, loglik_zero, np.log(1 - pi) + loglik_pois)\n",
    "    return -np.sum(loglik)\n",
    "\n",
    "def calculate_aic(loglik, k):\n",
    "    return 2*k - 2*loglik\n",
    "\n",
    "def fit_zinb_and_calculate_aic(counts):\n",
    "    \n",
    "    initial_params = np.array([np.mean(counts), np.var(counts), 0.5])\n",
    "    bounds = [(0, None), (0, None), (0, 1)]\n",
    "    result = minimize(zinb_loglike, initial_params, args=(counts), bounds=bounds)\n",
    "    mu, theta, pi = result.x\n",
    "    loglik = -result.fun\n",
    "    \n",
    "    k = 3  # Number of parameters\n",
    "    aic = calculate_aic(loglik, k)\n",
    "    return mu, theta, pi, aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0971883d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T21:49:19.677502Z",
     "iopub.status.busy": "2024-04-02T21:49:19.677358Z",
     "iopub.status.idle": "2024-04-02T21:49:19.681813Z",
     "shell.execute_reply": "2024-04-02T21:49:19.681285Z"
    }
   },
   "outputs": [],
   "source": [
    "# functions to compute ZIP\n",
    "def zip_loglike(params, counts):\n",
    "    mu, pi = params\n",
    "    loglik_pois = poisson.logpmf(counts, mu)\n",
    "    loglik_zero = np.log(pi + (1 - pi) * np.exp(poisson.logpmf(0, mu)))\n",
    "    loglik = np.where(counts == 0, loglik_zero, np.log(1 - pi) + loglik_pois)\n",
    "    return -np.sum(loglik)\n",
    "\n",
    "def calculate_aic(loglik, k):\n",
    "    return 2*k - 2*loglik\n",
    "\n",
    "def fit_zip_and_calculate_aic(counts):\n",
    "    \n",
    "    initial_params = np.array([np.mean(counts), 0.5])\n",
    "    bounds = [(0, None), (0, 1)]\n",
    "    result = minimize(zip_loglike, initial_params, args=(counts), bounds=bounds)\n",
    "    mu, pi = result.x\n",
    "    loglik = -result.fun\n",
    "    k = 2  # Number of parameters for ZIP model\n",
    "    aic = calculate_aic(loglik, k)\n",
    "    return mu, pi, aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82385f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T21:49:19.684375Z",
     "iopub.status.busy": "2024-04-02T21:49:19.684238Z",
     "iopub.status.idle": "2024-04-02T21:49:19.694307Z",
     "shell.execute_reply": "2024-04-02T21:49:19.693751Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_distributions(aic_values):\n",
    "    distribution_types = {\n",
    "        \"NB\": aic_values[\"NB\"],\n",
    "        \"Gaussian\": aic_values[\"Gaussian\"],\n",
    "        \"Poisson\": aic_values[\"Poisson\"],\n",
    "        \"Exponential\": aic_values[\"Exponential\"],\n",
    "        \"ZIP\": aic_values[\"Zero-Inflated Poisson\"],\n",
    "        \"ZINB\": aic_values[\"Zero-Inflated Negative Binomial\"]\n",
    "    }\n",
    "\n",
    "    min_aic_type = min(distribution_types, key=distribution_types.get)\n",
    "    min_aic_value = distribution_types[min_aic_type]\n",
    "\n",
    "    return min_aic_type, min_aic_value\n",
    "\n",
    "\n",
    "\n",
    "# this is the function that computes AIC for all distributions (Gaussian, Exponential, Negative Binomial, ZIP, ZINB)\n",
    "# and reports which distribution is lowest\n",
    "# row - a vector of expressions\n",
    "def manual_aic(row, path):\n",
    "    gene_name = row.name\n",
    "\n",
    "    row = np.round(row) # it must be count data\n",
    "\n",
    "    # trimmed mean to remove outliers\n",
    "    n = len(row)\n",
    "\n",
    "    if (trim_means_flag):\n",
    "        elements_to_trim = int(np.floor(trim_percent / 100.0 * n))  \n",
    "        sorted_data = np.sort(row)\n",
    "        \n",
    "        if (elements_to_trim > 0):\n",
    "            row = sorted_data[elements_to_trim:-elements_to_trim]\n",
    "        else: \n",
    "            row = sorted_data\n",
    "\n",
    "    if (sum(row) <= 0):\n",
    "        return \"ZEROES\"\n",
    "\n",
    "    X = sm.add_constant(np.ones(len(row)))\n",
    "\n",
    "    # Exponential parameters\n",
    "    lambda_exp = 1 / np.mean(row)\n",
    "    log_likelihood_exp = np.sum(expon.logpdf(row, scale=1/lambda_exp))\n",
    "    aic_exp = 2*1 - 2*log_likelihood_exp  # 1 parameter for exponential\n",
    "\n",
    "    # log -> linear -> delog\n",
    "    # using StatsModels to fit to a Gamma (it doesn't have exponential)\n",
    "    #model_exponential_approx = sm.GLM(row, X, family=Gamma()).fit()\n",
    "    #print('AIC for Gamma:', model_exponential_approx.aic)\n",
    "    #aic_exp = model_exponential_approx.aic\n",
    "\n",
    "    # Compute AIC to NB manually \n",
    "    mu_sample = np.mean(row)\n",
    "    var_sample = np.var(row)\n",
    "    if (mu_sample == var_sample):\n",
    "        var_sample = var_sample + 0.0000000000001\n",
    "    r_estimated = mu_sample**2 / (var_sample - mu_sample)\n",
    "    \n",
    "    if (mu_sample + r_estimated) == 0:\n",
    "        r_estimated = r_estimated + 0.0000000000001\n",
    "    p_estimated = r_estimated / (mu_sample + r_estimated)\n",
    "    #log_likelihood_nb = np.sum(nbinom.logpmf(row, r_estimated, p_estimated))\n",
    "    #aic_nb = 2*2 - 2*log_likelihood_nb  # 2 parameters for NB\n",
    "    \n",
    "    #print(\"NB AIC SciPy\", aic_nb_orig)\n",
    "\n",
    "    # StatsModels method to compute fit to NB\n",
    "    #X = sm.add_constant(np.ones(len(row)))\n",
    "    #model_nb = sm.GLM(row, X, family=NegativeBinomial()).fit(disp=0)\n",
    "    #aic_nb = model_nb.aic\n",
    "    #print(model_nb.summary())\n",
    "    #print(\"NB AIC GLM\", aic_nb)\n",
    "\n",
    "    res = sm.NegativeBinomial(row, X).fit(start_params=[1,1], disp=0)\n",
    "    \n",
    "    const = res.params[0]\n",
    "    alpha = res.params[1]\n",
    "\n",
    "    mu = np.exp(const)\n",
    "    p = 1/(1+np.exp(const)*alpha)\n",
    "    n = np.exp(const)*p/(1-p)\n",
    "\n",
    "    nb_theta = mu * (1 - p) / p\n",
    "\n",
    "    aic_nb = res.aic\n",
    "\n",
    "    # ZINB parameters\n",
    "    mu, zinb_theta, zinb_pi, aic = fit_zinb_and_calculate_aic(row)\n",
    "    aic_zinb = aic\n",
    "    \n",
    "\n",
    "\n",
    "    # AIC of Gaussian following IRLS (IRLS)\n",
    "    model_gaussian = sm.GLM(row, X, family=sm.families.Gaussian()).fit(disp=0)\n",
    "    aic_gauss = model_gaussian.aic\n",
    "\n",
    "\n",
    "    # Poisson parameters (all methods give the same AIC)\n",
    "    model_poisson = sm.Poisson(row, X).fit(disp=0)\n",
    "    aic_pois = model_poisson.aic\n",
    "\n",
    "    # ZIP parameters\n",
    "    #pi_zip = np.mean(row == 0)\n",
    "    #lambda_zip = np.mean(row[row != 0])\n",
    "    #log_likelihood_zeros_zip = np.sum(np.log(pi_zip) * (row == 0))\n",
    "    #log_likelihood_non_zeros_zip = np.sum(np.log(1 - pi_zip) + poisson.logpmf(row[row != 0], lambda_zip))\n",
    "    #log_likelihood_zip = log_likelihood_zeros_zip + log_likelihood_non_zeros_zip\n",
    "    #aic_zip = 2*2 - 2*log_likelihood_zip  # 2 parameters for ZIP: pi and lambda\n",
    "\n",
    "    #print(\"Old\", aic_zip)\n",
    "    # Usage\n",
    "    mu, pi, aic = fit_zip_and_calculate_aic(row)\n",
    "    aic_zip = aic\n",
    "    #print(f\"mu: {mu}, pi: {pi}, AIC: {aic}\")\n",
    "\n",
    "\n",
    "    # sometimes ZIP and ZINB can be NaN if there are no zeroes\n",
    "    # NB can also become NaN if Mean > Variance (I think)\n",
    "    # just in case, lets add this check for all of them\n",
    "    aic_scores = {'aic_zip': aic_zip, 'aic_zinb': aic_zinb, 'aic_nb': aic_nb, 'aic_pois': aic_pois, 'aic_gauss': aic_gauss, 'aic_exp': aic_exp}\n",
    "\n",
    "    for key in aic_scores:\n",
    "        if np.isnan(aic_scores[key]) | np.isinf(aic_scores[key]):\n",
    "            aic_scores[key] = 100000000\n",
    "\n",
    "    aic_zip, aic_zinb, aic_nb, aic_pois, aic_gauss, aic_exp = aic_scores.values()\n",
    "        \n",
    "    # in certain analyses, we might only want to look at certain distributions\n",
    "    # so we will make the AIC score high for those we don't care about\n",
    "    if (NB_ZINB_only == True):\n",
    "        aic_zip, aic_pois, aic_gauss, aic_exp = 10000000, 10000000, 10000000, 10000000\n",
    "    if (no_ZI_AICs == True):\n",
    "        aic_zip, aic_zinb = 10000000, 10000000\n",
    "    \n",
    "    # \n",
    "    qqplot_nb_vs_exp(row, path, gene_name)  \n",
    "\n",
    "\n",
    "    # print(aic_nb, aic_gauss, aic_pois, aic_exp)\n",
    "    best_distribution, best_aic = compare_distributions({\n",
    "        \"NB\": aic_nb,\n",
    "        \"Gaussian\": aic_gauss,\n",
    "        \"Poisson\": aic_pois,\n",
    "        \"Exponential\": aic_exp,\n",
    "        \"Zero-Inflated Poisson\": aic_zip,\n",
    "        \"Zero-Inflated Negative Binomial\": aic_zinb\n",
    "    })\n",
    "\n",
    "    return best_distribution #, nb_theta, zinb_theta, zinb_pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af669e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cf92b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T21:49:19.696635Z",
     "iopub.status.busy": "2024-04-02T21:49:19.696495Z",
     "iopub.status.idle": "2024-04-02T21:49:19.705156Z",
     "shell.execute_reply": "2024-04-02T21:49:19.704602Z"
    }
   },
   "outputs": [],
   "source": [
    "# NEW AIC CALCULATION PROGRAM\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy.stats import expon, nbinom, norm, poisson\n",
    "\n",
    "# lets turn this into a function\n",
    "def manual_aic(row, path):\n",
    "    row = np.round(row) # make it count data\n",
    "    \n",
    "    # what if we adjust the row with elimination of outliers\n",
    "    # IQR is distribution agnostic which is why I chose it\n",
    "    Q1 = np.percentile(row, 25)\n",
    "    Q3 = np.percentile(row, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 2 * IQR\n",
    "    upper_bound = Q3 + 2 * IQR\n",
    "   \n",
    "    # row = row[(row >= lower_bound) & (row <= upper_bound)]\n",
    "    #row = row[row <= upper_bound]\n",
    "    \n",
    "    \n",
    "    if (sum(row) <= 0):\n",
    "        return \"ZEROES\"\n",
    "    \n",
    "    # Exponential parameters\n",
    "    lambda_exp = 1 / np.mean(row)\n",
    "    log_likelihood_exp = np.sum(expon.logpdf(row, scale=1/lambda_exp))\n",
    "    aic_exp = 2*1 - 2*log_likelihood_exp  # 1 parameter for exponential\n",
    "\n",
    "    # NB parameters\n",
    "    mu_sample = np.mean(row)\n",
    "    var_sample = np.var(row)\n",
    "    if (mu_sample == var_sample):\n",
    "        var_sample = var_sample + 0.0000000000001\n",
    "    r_estimated = mu_sample**2 / (var_sample - mu_sample)\n",
    "    \n",
    "    if (mu_sample + r_estimated) == 0:\n",
    "        r_estimated = r_estimated + 0.0000000000001\n",
    "    p_estimated = r_estimated / (mu_sample + r_estimated)\n",
    "    log_likelihood_nb = np.sum(nbinom.logpmf(row, r_estimated, p_estimated))\n",
    "    aic_nb = 2*2 - 2*log_likelihood_nb  # 2 parameters for NB\n",
    "\n",
    "    # ZINB parameters\n",
    "    pi_zinb = np.mean(row == 0)\n",
    "    log_likelihood_zeros = np.sum(np.log(pi_zinb) * (row == 0))\n",
    "    log_likelihood_non_zeros = np.sum(np.log(1 - pi_zinb) + nbinom.logpmf(row[row != 0], r_estimated, p_estimated))\n",
    "    log_likelihood_zinb = log_likelihood_zeros + log_likelihood_non_zeros\n",
    "    aic_zinb = 2*3 - 2*log_likelihood_zinb  # 3 parameters for ZINB: pi, r, and p\n",
    "\n",
    "    # Gaussian parameters\n",
    "    mu_gauss = np.mean(row)\n",
    "    sigma_gauss = np.std(row)\n",
    "    log_likelihood_gauss = np.sum(norm.logpdf(row, mu_gauss, sigma_gauss))\n",
    "    aic_gauss = 2*2 - 2*log_likelihood_gauss  # 2 parameters for Gaussian: mu and sigma\n",
    "\n",
    "    # Poisson parameters\n",
    "    lambda_pois = np.mean(row)\n",
    "    log_likelihood_pois = np.sum(poisson.logpmf(row, lambda_pois))\n",
    "    aic_pois = 2*1 - 2*log_likelihood_pois  # 1 parameter for Poisson: lambda\n",
    "\n",
    "    # ZIP parameters\n",
    "    pi_zip = np.mean(row == 0)\n",
    "    lambda_zip = np.mean(row[row != 0])\n",
    "    log_likelihood_zeros_zip = np.sum(np.log(pi_zip) * (row == 0))\n",
    "    log_likelihood_non_zeros_zip = np.sum(np.log(1 - pi_zip) + poisson.logpmf(row[row != 0], lambda_zip))\n",
    "    log_likelihood_zip = log_likelihood_zeros_zip + log_likelihood_non_zeros_zip\n",
    "    aic_zip = 2*2 - 2*log_likelihood_zip  # 2 parameters for ZIP: pi and lambda\n",
    "\n",
    "    # sometimes ZIP and ZINB can be NaN if there are no zeroes\n",
    "    # NB can also become NaN if Mean > Variance (I think)\n",
    "    # just in case, lets add this check for all of them\n",
    "    if np.isnan(aic_zip):\n",
    "        aic_zip = 1000000000000\n",
    "    if np.isnan(aic_zinb):\n",
    "        aic_zinb = 1000000000000\n",
    "    if np.isnan(aic_nb):\n",
    "        aic_nb = 1000000000000\n",
    "    if np.isnan(aic_pois):\n",
    "        aic_pois = 1000000000000\n",
    "    if np.isnan(aic_gauss):\n",
    "        aic_gauss = 1000000000000\n",
    "    if np.isnan(aic_exp):\n",
    "        aic_exp = 1000000000000\n",
    "        \n",
    "   \n",
    "    # Compare AICs and determine best fit\n",
    "    if (aic_nb < aic_pois ) & (aic_nb < aic_gauss) & (aic_nb < aic_exp) & (aic_nb < aic_zip) & (aic_nb < aic_zinb): \n",
    "        #qqplot_nb_vs_exp(row, path)  \n",
    "        return \"NB\"\n",
    "    elif (aic_gauss < aic_nb) & (aic_gauss < aic_pois) & (aic_gauss < aic_exp) & (aic_gauss < aic_zip) & (aic_gauss < aic_zinb):\n",
    "        return \"Gaussian\"\n",
    "    elif (aic_exp < aic_nb) & (aic_exp < aic_pois) & (aic_exp < aic_gauss) & (aic_exp < aic_zip) & (aic_exp < aic_zinb):\n",
    "        #qqplot_nb_vs_exp(row, path)  \n",
    "        return \"Exponential\"\n",
    "    elif (aic_zinb < aic_nb) & (aic_zinb < aic_pois) & (aic_zinb < aic_gauss) & (aic_zinb < aic_zip) & (aic_zinb < aic_exp):\n",
    "        return \"ZINB\"\n",
    "    elif (aic_zip < aic_nb) & (aic_zip < aic_pois) & (aic_zip < aic_gauss) & (aic_zip < aic_zinb) & (aic_zip < aic_exp):\n",
    "        return \"ZIP\"\n",
    "    else:\n",
    "        return \"Poisson\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bcc1d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T21:49:19.709163Z",
     "iopub.status.busy": "2024-04-02T21:49:19.709015Z",
     "iopub.status.idle": "2024-04-02T21:49:19.718944Z",
     "shell.execute_reply": "2024-04-02T21:49:19.718382Z"
    }
   },
   "outputs": [],
   "source": [
    "def segmental_aic_find(counts, path=\"\"):\n",
    "    add_vector_nb, add_vector_exp, add_vector_zinb, sample_total = [], [], [], []\n",
    "    add_vector_zip, add_vector_gaussian, add_vector_poisson = [], [], []\n",
    "    wf_nb, wf_zinb, wf_gau, wf_poi, wf_zip, wf_exp = 1,1,1,1,1,1\n",
    "\n",
    "    for i in range(1,5):\n",
    "        \n",
    "        # instead of by zero fraction, we split genes by mean expression\n",
    "        counts.loc[:, 'RowSum'] = counts.sum(axis=1)\n",
    "\n",
    "        # Sort the DataFrame by the RowSum column\n",
    "        counts = counts.sort_values(by='RowSum', ascending=False)\n",
    "\n",
    "        # ditch any row with no reads\n",
    "        counts = counts[counts['RowSum'] != 0]\n",
    "        \n",
    "        # Calculate quartile values\n",
    "        total_rows = len(counts)\n",
    "        top_25 = int(total_rows * 0.25)\n",
    "        middle_50 = int(total_rows * 0.5)\n",
    "        bottom_25 = int(total_rows * 0.75)\n",
    "        \n",
    "        # remove rowsum\n",
    "        counts = counts.drop(columns=['RowSum'])\n",
    "        \n",
    "        top25_percent = counts.iloc[:top_25]\n",
    "        top50_to25_percent = counts.iloc[top_25:middle_50]\n",
    "        top75_to50_percent = counts.iloc[middle_50:bottom_25]\n",
    "        bottom25_percent = counts.iloc[bottom_25:]\n",
    "        \n",
    "        # Set the quartiles\n",
    "        if (i == 1):\n",
    "            filtered_df = top25_percent\n",
    "        if (i == 2):\n",
    "            filtered_df = top50_to25_percent        \n",
    "        if (i == 3): \n",
    "            filtered_df = top75_to50_percent\n",
    "        if (i == 4): \n",
    "            filtered_df = bottom25_percent \n",
    "        \n",
    "        sample_total.append(filtered_df.shape[0])\n",
    "    \n",
    "        #aic_values = filtered_df.apply(manual_aic, axis=1)\n",
    "        aic_values = filtered_df.apply(lambda row: manual_aic(row, path), axis=1)\n",
    "        ratio_NB_to_Gaussian = aic_values.value_counts()\n",
    "    \n",
    "        # to add zero if the distribution didn't occur\n",
    "        if(wf_nb == 0):\n",
    "           add_vector_nb.append(0)\n",
    "        if(wf_zinb == 0):\n",
    "            add_vector_zinb.append(0)\n",
    "        if(wf_zip == 0):\n",
    "            add_vector_zip.append(0)        \n",
    "        if(wf_poi == 0):\n",
    "            add_vector_poisson.append(0)\n",
    "        if(wf_gau == 0):\n",
    "            add_vector_gaussian.append(0)\n",
    "        if(wf_exp == 0):\n",
    "            add_vector_exp.append(0)\n",
    "    \n",
    "        wf_nb, wf_zinb, wf_gau, wf_poi, wf_zip, wf_exp = 0,0,0,0,0,0\n",
    "    \n",
    "        names = ratio_NB_to_Gaussian.index\n",
    "        values = ratio_NB_to_Gaussian.values\n",
    "    \n",
    "        # add to individual vectors\n",
    "        for i in range(len(names)):\n",
    "            if(names[i] == 'NB'):\n",
    "                add_vector_nb.append(values[i])\n",
    "                wf_nb = 1\n",
    "            if(names[i] == 'ZINB'):\n",
    "                add_vector_zinb.append(values[i])\n",
    "                wf_zinb = 1\n",
    "            if(names[i] == 'ZIP'):\n",
    "                add_vector_zip.append(values[i])\n",
    "                wf_zip = 1\n",
    "            if(names[i] == 'Poisson'):\n",
    "                add_vector_poisson.append(values[i])\n",
    "                wf_poi = 1\n",
    "            if(names[i] == 'Gaussian'):\n",
    "                add_vector_gaussian.append(values[i])\n",
    "                wf_gau = 1\n",
    "            if(names[i] == 'Exponential'):\n",
    "                add_vector_exp.append(values[i])\n",
    "                wf_exp = 1\n",
    "        \n",
    "    # need to do it once again for the last value\n",
    "    if(wf_nb == 0):\n",
    "        add_vector_nb.append(0)\n",
    "    if(wf_zinb == 0):\n",
    "        add_vector_zinb.append(0)\n",
    "    if(wf_zip == 0):\n",
    "        add_vector_zip.append(0)        \n",
    "    if(wf_poi == 0):\n",
    "        add_vector_poisson.append(0)\n",
    "    if(wf_gau == 0):\n",
    "        add_vector_gaussian.append(0)\n",
    "    if(wf_exp == 0):\n",
    "        add_vector_exp.append(0)\n",
    "    \n",
    "    return add_vector_nb, add_vector_zinb, add_vector_zip, add_vector_poisson, add_vector_gaussian, add_vector_exp, sample_total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470bef7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T21:49:19.721224Z",
     "iopub.status.busy": "2024-04-02T21:49:19.721076Z",
     "iopub.status.idle": "2024-04-02T21:49:19.727541Z",
     "shell.execute_reply": "2024-04-02T21:49:19.727004Z"
    }
   },
   "outputs": [],
   "source": [
    "# don't forget we want to take the average value\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a vector of x-values (input values)\n",
    "def gradual_aic_plot(data, title_add=\"\"):\n",
    "    x_values = [\"Top 25%\", \"25-50%\", \"50-75%\", \"75-100%\"]\n",
    "    # order is: add_vector_nb, add_vector_zinb, add_vector_zip, add_vector_poisson,\n",
    "    # add_vector_gaussian, add_vector_exp, sample_total\n",
    "    add_vector_nb = data[0]\n",
    "    add_vector_zinb = data[1]\n",
    "    add_vector_zip = data[2]\n",
    "    add_vector_poisson = data[3]\n",
    "    add_vector_gaussian = data[4]\n",
    "    add_vector_exp = data[5]\n",
    "    sample_total = data[6]\n",
    "    \n",
    "    fraction_nb = [x / y for x, y in zip(add_vector_nb, sample_total)]\n",
    "    fraction_zinb = [x / y for x, y in zip(add_vector_zinb, sample_total)]\n",
    "    fraction_exp = [x / y for x, y in zip(add_vector_exp, sample_total)]\n",
    "    fraction_zip = [x / y for x, y in zip(add_vector_zip, sample_total)]\n",
    "    fraction_gau = [x / y for x, y in zip(add_vector_gaussian, sample_total)]\n",
    "    fraction_poi = [x / y for x, y in zip(add_vector_poisson, sample_total)]\n",
    "\n",
    "    # Create a line plot\n",
    "    fig = plt.figure(figsize=(2.8, 2.2))\n",
    "    plt.plot(x_values, fraction_nb, marker='o', linestyle='-', label='NB')\n",
    "    plt.plot(x_values, fraction_zinb, marker='o', linestyle='-', label='ZINB')\n",
    "    plt.plot(x_values, fraction_exp, marker='o', linestyle='-', label='Exponential')\n",
    "    plt.plot(x_values, fraction_poi, marker='o', linestyle='-', label='Poisson')\n",
    "    plt.plot(x_values, fraction_zip, marker='o', linestyle='-', label='ZIP')\n",
    "    plt.plot(x_values, fraction_gau, marker='o', linestyle='-', label='Gaussian')\n",
    "\n",
    "    # Add labels and a title\n",
    "    #plt.xlabel('Genes Grouped by Overall Counts')\n",
    "    #plt.ylabel('% of Genes Best Fitting Distribution')\n",
    "    \n",
    "    #title_text = f\"Gene Fraction with Lowest AIC [{title_add}]\"\n",
    "    title_text = f\"{title_add}\"\n",
    "    \n",
    "    plt.title(title_text, fontsize=10)\n",
    "    \n",
    "    # saving plot\n",
    "    plt.savefig('/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/By_Expression_AIC_Plot.' +\n",
    "        str(title_add) + \".ZeroFract_\" + str(express_percent_limit) + \".Trim_\" + str(trim_percent) + \".pdf\",\n",
    "        dpi=300, bbox_inches='tight')  # dpi is dots per inch, for resolution\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dfed58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T21:49:19.729698Z",
     "iopub.status.busy": "2024-04-02T21:49:19.729560Z",
     "iopub.status.idle": "2024-04-02T22:03:29.942059Z",
     "shell.execute_reply": "2024-04-02T22:03:29.941043Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is a dataset with 528 FFPE breast cancer samples, sequenced from a HiSeq\n",
    "\n",
    "data = pd.read_csv('/path/to/GSE167977_third_party_ffpe/GSE167977_Raw_Counts.txt',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "# filter and compute dispersion\n",
    "# dispersion of tumours - All Data\n",
    "GSE167977_tumours_counts = pd.DataFrame(data)\n",
    "GSE167977_tumours_counts = GSE167977_tumours_counts.set_index('ensembl_gene_id')\n",
    "GSE167977_tumours_counts = GSE167977_tumours_counts.rename(index=dict(zip(gene_convert[\"gene_id\"], gene_convert[\"gene_name\"])))\n",
    "#GSE167977_tumours_counts = GSE167977_tumours_counts.drop(GSE167977_tumours_counts.columns[0], axis=1) # column 1\n",
    "GSE167977_tumours_counts = GSE167977_tumours_counts.drop(GSE167977_tumours_counts.columns[-5:], axis=1) # last 5 columns\n",
    "\n",
    "# adjust for library size (fraction method)\n",
    "# should come before the gene filter\n",
    "tumours_counts_lib_adjust = library_adjust(GSE167977_tumours_counts)\n",
    "\n",
    "fraction_of_zeroes = (tumours_counts_lib_adjust == 0).mean(axis=1)\n",
    "filtered_df = tumours_counts_lib_adjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "\n",
    "print(\"GSE167977 - Lowest AIC across all genes\")\n",
    "\n",
    "GSE167977_tumours_data = segmental_aic_find(GSE167977_tumours_counts, \"/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/qq_plots/GSE167977/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c8783b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:03:29.947910Z",
     "iopub.status.busy": "2024-04-02T22:03:29.947711Z",
     "iopub.status.idle": "2024-04-02T22:03:30.282108Z",
     "shell.execute_reply": "2024-04-02T22:03:30.281495Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gradual_aic_plot(GSE167977_tumours_data, \"GSE167977\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac2d3e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:03:30.288015Z",
     "iopub.status.busy": "2024-04-02T22:03:30.287861Z",
     "iopub.status.idle": "2024-04-02T22:03:30.588015Z",
     "shell.execute_reply": "2024-04-02T22:03:30.587406Z"
    }
   },
   "outputs": [],
   "source": [
    "def top50_bar_plot(data, title_add=\"\"):\n",
    "    x_values = [\"Top 25%\", \"25-50%\", \"50-75%\", \"75-100%\"]\n",
    "    # order is: add_vector_nb, add_vector_zinb, add_vector_zip, add_vector_poisson,\n",
    "    # add_vector_gaussian, add_vector_exp, sample_total\n",
    "    add_vector_nb = data[0]\n",
    "    add_vector_zinb = data[1]\n",
    "    add_vector_zip = data[2]\n",
    "    add_vector_poisson = data[3]\n",
    "    add_vector_gaussian = data[4]\n",
    "    add_vector_exp = data[5]\n",
    "    sample_total = data[6]\n",
    "    \n",
    "    sum_nb = add_vector_nb[0] #+ add_vector_nb[1]\n",
    "    sum_zinb = add_vector_zinb[0] #+ add_vector_zinb[1]\n",
    "    sum_exp = add_vector_exp[0] #+ add_vector_exp[1]\n",
    "    sum_zip = add_vector_zip[0] + add_vector_zip[1]\n",
    "    sum_gau = add_vector_gaussian[0] + add_vector_gaussian[1]\n",
    "    sum_poi = add_vector_poisson[0] + add_vector_poisson[1]\n",
    "\n",
    "    print(sum_nb, sum_zinb, sum_exp, sum_poi, sum_zip, sum_gau)\n",
    "    pos = 6\n",
    "    bar_width = 0.1\n",
    "    categories = ['NB', 'ZINB', 'Exponential', 'Poisson', 'ZIP', 'Gaussian']\n",
    "    \n",
    "    # Plotting the bars\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Create a bar for each set of values\n",
    "    plt.bar(pos, sum_nb, bar_width, label='NB')\n",
    "    plt.bar(pos + bar_width, sum_zinb, bar_width, label='ZINB')\n",
    "    plt.bar(pos + bar_width*2, sum_exp, bar_width, label='Exponential')\n",
    "    plt.bar(pos + bar_width*3, sum_poi, bar_width, label='Poisson')\n",
    "    plt.bar(pos + bar_width*4, sum_zip, bar_width, label='ZIP')\n",
    "    plt.bar(pos + bar_width*5, sum_gau, bar_width, label='Gaussian')\n",
    "\n",
    "    # Adding and formatting title and labels\n",
    "    plt.xlabel('Distribution Types')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(title_add)\n",
    "    #plt.xticks(pos + bar_width, categories)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig('/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/By_Expression_AIC_BarPlot.' +\n",
    "        str(title_add) + \".ZeroFract_\" + str(express_percent_limit) + \".Trim_\" + str(trim_percent) + \".pdf\",\n",
    "        dpi=300, bbox_inches='tight')  # dpi is dots per inch, for resolution\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "top50_bar_plot(GSE167977_tumours_data, \"GSE167977\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2903f74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:03:30.594159Z",
     "iopub.status.busy": "2024-04-02T22:03:30.593967Z",
     "iopub.status.idle": "2024-04-02T22:10:45.698398Z",
     "shell.execute_reply": "2024-04-02T22:10:45.697907Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/path/to/GSE181466_third_party_ffpe/GSE181466_rsem_genes_matrix-97.txt',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "# patient information splitting is unnecessary, this appears to all be both FFPE and from tumours\n",
    "# there is subtype and age information in the series matrix file, if we're interested\n",
    "\n",
    "# dispersion of tumours - All Data\n",
    "tumours_counts = pd.DataFrame(data)\n",
    "# removing gene column at position 0\n",
    "tumours_counts = tumours_counts.drop(tumours_counts.columns[0], axis=1)\n",
    "# skip genes that are all zeroes, or just one spurrious read somewhere\n",
    "\n",
    "# adjust for library size (fraction method)\n",
    "tumours_counts_libadjust = library_adjust(tumours_counts)\n",
    "\n",
    "fraction_of_zeroes = (tumours_counts_libadjust == 0).mean(axis=1)\n",
    "filtered_df = tumours_counts_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "print(\"GSE181466\")\n",
    "GSE181466_data = segmental_aic_find(filtered_df, \"/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/qq_plots/GSE181466/\")\n",
    "gradual_aic_plot(GSE181466_data, \"GSE181466\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e85296a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9cd8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:10:45.704130Z",
     "iopub.status.busy": "2024-04-02T22:10:45.703961Z",
     "iopub.status.idle": "2024-04-02T22:33:50.348833Z",
     "shell.execute_reply": "2024-04-02T22:33:50.348119Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## here, we will repeat our plots but for a different data set\n",
    "all_counts = pyreadr.read_r('/path/to/GSE146889_third_party_ffpe/GSE146889_GeneCount.rds')\n",
    "df = all_counts[None] \n",
    "\n",
    "# we need to split the tumors and normals by name\n",
    "GSE146889_count_TUMOR = df.filter(like='tumor')\n",
    "GSE146889_count_NORMAL = df.filter(like='normal')\n",
    "\n",
    "count_TUMOR_libadjust = library_adjust(GSE146889_count_TUMOR)\n",
    "fraction_of_zeroes = (count_TUMOR_libadjust == 0).mean(axis=1)\n",
    "filtered_tumour = count_TUMOR_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "# adjust for library size (fraction method)\n",
    "count_NORMAL_libadjust = library_adjust(GSE146889_count_NORMAL)\n",
    "fraction_of_zeroes = (count_NORMAL_libadjust == 0).mean(axis=1)\n",
    "filtered_normal = count_NORMAL_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "\n",
    "print(\"GSE146889 - Tumours\")\n",
    "GSE146889_tum_data = segmental_aic_find(filtered_tumour, \"/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/qq_plots/GSE146889_tumour/\")\n",
    "gradual_aic_plot(GSE146889_tum_data, \"GSE146889_Tumours\") \n",
    "\n",
    "GSE146889_norm_data = segmental_aic_find(filtered_normal, \"/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/qq_plots/GSE146889_normal/\")\n",
    "gradual_aic_plot(GSE146889_norm_data, \"GSE146889_Normals\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe899f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98a72f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T22:33:50.352471Z",
     "iopub.status.busy": "2024-04-02T22:33:50.352310Z",
     "iopub.status.idle": "2024-04-02T23:07:16.218893Z",
     "shell.execute_reply": "2024-04-02T23:07:16.218255Z"
    }
   },
   "outputs": [],
   "source": [
    "all_counts = pyreadr.read_r('/path/to/GSE209998_third_party_ffpe/GSE209998_GeneCount.rds')\n",
    "sample_information = pyreadr.read_r('/path/to/GSE209998_third_party_ffpe/GSE209998_Sample_Data.rds')\n",
    "\n",
    "# now we want to isolate just the expression from a particular type of tissue\n",
    "df_counts = all_counts[None] # load all_counts into a pandas data frame\n",
    "df_sample = sample_information[None] # load all_counts into a pandas data frame\n",
    "\n",
    "# here, we need to match if a sample is normal or tumour by !Sample_source_name_ch1 row\n",
    "\n",
    "# so I need to: 1) match columns between sample_information and all_counts \n",
    "# are they in the same order\n",
    "columns_df1 = df_counts.columns\n",
    "columns_df2 = df_sample.columns\n",
    "\n",
    "# Now we find what samples were tumours and what were normal\n",
    "samples_row = df_sample.loc[\"!Sample_source_name_ch1\"]\n",
    "\n",
    "split_dfs = {}\n",
    "for sample_type in samples_row.unique():\n",
    "    matching_columns = [col for col in df_counts.columns if col in df_sample.columns and samples_row[col] == sample_type]\n",
    "    split_dfs[sample_type] = df_counts[matching_columns]\n",
    "\n",
    "sample_source = df_sample.loc[\"!Sample_source\"]\n",
    "\n",
    "split_source = {}\n",
    "for sample_type in sample_source.unique():\n",
    "    matching_columns = [col for col in df_counts.columns if col in df_sample.columns and sample_source[col] == sample_type]\n",
    "    split_source[sample_type] = df_counts[matching_columns]\n",
    "\n",
    "\n",
    "GSE209998_count_FRESH = split_source[\"Fresh frozen\"]\n",
    "GSE209998_count_FFPE = split_source[\"FFPE\"]\n",
    "\n",
    "count_FFPE_libadjust = library_adjust(GSE209998_count_FRESH)\n",
    "fraction_of_zeroes = (count_FFPE_libadjust == 0).mean(axis=1)\n",
    "filtered_ffpe = np.round(count_FFPE_libadjust[fraction_of_zeroes < (1 - express_percent_limit)]) # must be expressed to this percentage of patients\n",
    "\n",
    "count_FRESH_libadjust = library_adjust(GSE209998_count_FFPE)\n",
    "fraction_of_zeroes = (count_FRESH_libadjust == 0).mean(axis=1)\n",
    "filtered_fresh = np.round(count_FRESH_libadjust[fraction_of_zeroes < (1 - express_percent_limit)]) # must be expressed to this percentage of patients\n",
    "\n",
    "\n",
    "print(\"GSE209998\")\n",
    "\n",
    "GSE209998_ffpe_data = segmental_aic_find(filtered_ffpe, \"/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/qq_plots/GSE209998_FFPE/\")\n",
    "gradual_aic_plot(GSE209998_ffpe_data, \"GSE209998_FFPE\") \n",
    "\n",
    "GSE209998_fresh_data = segmental_aic_find(filtered_fresh, \"/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/qq_plots/GSE209998_FF/\")\n",
    "gradual_aic_plot(GSE209998_fresh_data, \"GSE209998_FreshFrozen\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06eee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a7770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb4399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T23:07:16.232876Z",
     "iopub.status.busy": "2024-04-02T23:07:16.232684Z",
     "iopub.status.idle": "2024-04-02T23:21:04.872795Z",
     "shell.execute_reply": "2024-04-02T23:21:04.872173Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/path/to/GSE47462_third_party_ffpe/GSE47462_Raw_counts_Refseq_genes.txt',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "# Split the DataFrame into subsets based on column names indicating sample type\n",
    "GSE47462_normal_data = data.filter(like='_normal')\n",
    "EN_data = data.filter(like='_EN')\n",
    "DCIS_data = data.filter(like='_DCIS')\n",
    "IDC_data = data.filter(like='_IDC')\n",
    "\n",
    "# since there isn't a ton of data, I also want to group tumors\n",
    "GSE47462_tumours_data = data.loc[:, ~data.columns.str.contains('_normal')]\n",
    "GSE47462_tumours_data = GSE47462_tumours_data.iloc[:, 1:]\n",
    "\n",
    "\n",
    "tumours_data_libadjust = library_adjust(GSE47462_tumours_data)\n",
    "fraction_of_zeroes = (tumours_data_libadjust == 0).mean(axis=1)\n",
    "filtered_tumour = tumours_data_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "normal_data_libadjust = library_adjust(GSE47462_normal_data)\n",
    "fraction_of_zeroes = (normal_data_libadjust == 0).mean(axis=1)\n",
    "filtered_normal = normal_data_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "\n",
    "print(\"GSE47462\")\n",
    "GSE47462_tum_data = segmental_aic_find(filtered_tumour, \"/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/qq_plots/GSE47462_tumour/\")\n",
    "\n",
    "gradual_aic_plot(GSE47462_tum_data, \"GSE47462_Tumours\")\n",
    "GSE47462_norm_data = segmental_aic_find(filtered_normal, \"/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/qq_plots/GSE47462_normal/\")\n",
    "gradual_aic_plot(GSE47462_norm_data, \"GSE47462_Normals\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737f7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673e2662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T23:21:04.875733Z",
     "iopub.status.busy": "2024-04-02T23:21:04.875565Z",
     "iopub.status.idle": "2024-04-02T23:32:02.165927Z",
     "shell.execute_reply": "2024-04-02T23:32:02.165315Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv('/path/to/GSE120795_third_party_ffpe/GSE120795_total_norms_raw_counts.tsv',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "# in the series matrix\"disease: healthy\", \n",
    "patient_info = pd.read_csv('/path/to/GSE120795_third_party_ffpe/GSE120795_cell_info.txt',\n",
    "                  delimiter='\\t')\n",
    "\n",
    "mask = patient_info.iloc[0] == \"healthy\"\n",
    "\n",
    "filtered_data = patient_info.loc[:, mask]\n",
    "patient_names = filtered_data.columns\n",
    "column_names_with_extension = [name + \".fastq.gz\" for name in patient_names]\n",
    "column_names_with_extension = column_names_with_extension[1:]\n",
    "\n",
    "# Assuming 'second_list' is the list where you want to filter based on column names\n",
    "GSE120795_filtered_data = data[column_names_with_extension]\n",
    "GSE120795_ffpe_counts = pd.DataFrame(GSE120795_filtered_data)\n",
    "\n",
    "ffpe_counts_libadjust = library_adjust(GSE120795_ffpe_counts)\n",
    "fraction_of_zeroes = (ffpe_counts_libadjust == 0).mean(axis=1)\n",
    "filtered_data = ffpe_counts_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "\n",
    "print(\"GSE120795\")\n",
    "GSE120795_tum_data = segmental_aic_find(filtered_data, \"/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/qq_plots/GSE120795/\")\n",
    "gradual_aic_plot(GSE120795_tum_data, \"GSE120795\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af532ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a213ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T23:32:02.173885Z",
     "iopub.status.busy": "2024-04-02T23:32:02.173640Z",
     "iopub.status.idle": "2024-04-02T23:43:47.211873Z",
     "shell.execute_reply": "2024-04-02T23:43:47.211235Z"
    }
   },
   "outputs": [],
   "source": [
    "# the GDC Count-Me-In Data\n",
    "data = pd.read_csv('/path/to/CountMeIn_BConly_third_party_ffpe/MBC_CMI_Compiled_Counts.tsv',\n",
    "                  delimiter=' ')\n",
    "\n",
    "TMBC_tumours_counts = pd.DataFrame(data)\n",
    "TMBC_tumours_counts = TMBC_tumours_counts.drop(TMBC_tumours_counts.columns[:3], axis=1) # columns 1-3 should be ignored\n",
    "\n",
    "tumours_counts_libadjust = library_adjust(TMBC_tumours_counts)\n",
    "fraction_of_zeroes = (tumours_counts_libadjust == 0).mean(axis=1)\n",
    "filtered_df = tumours_counts_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "\n",
    "print(\"Count Me In\")\n",
    "TMBC_tum_data = segmental_aic_find(filtered_df, \"/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/qq_plots/TMBC/\")\n",
    "gradual_aic_plot(TMBC_tum_data, \"TMBC_Project\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8d0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3de063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b0bb39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T23:43:47.214287Z",
     "iopub.status.busy": "2024-04-02T23:43:47.214041Z",
     "iopub.status.idle": "2024-04-02T23:43:49.807362Z",
     "shell.execute_reply": "2024-04-02T23:43:49.806656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Our dataset!\n",
    "all_counts = pyreadr.read_r('/path/to/dcis/expression_counts.Jan2023_1_2_and_2_2.rds')\n",
    "vst_norm = pyreadr.read_r('/path/to/dcis/expression_VST_Normalized.Jan2023_1_2_and_2_2.rds')\n",
    "\n",
    "# this data is loading without issue\n",
    "ship_data = pyreadr.read_r('/path/to/dcis/ship1_2_full_tbl.Jan2023.With_Stroma_Assignment.rds')\n",
    "# I wish that we could've simply used the RDA, but the counts-only RDS works and loads faster so what can you do\n",
    "# in the future, could try the package 'rpy2' instead, it's an alternative that requires R but that's okay for us\n",
    "\n",
    "# now we want to isolate just the expression from a particular type of tissue\n",
    "df = all_counts[None] # load all_counts into a pandas data frame\n",
    "\n",
    "# Eliminate any samples in the blacklist\n",
    "ship_df = ship_data[None]\n",
    "#print(ship_df['blacklist'].value_counts()) # they're all false\n",
    "\n",
    "# since ship_data already has patients filtered out, lets filter out any patient who isn't on the list\n",
    "# match by 'sample_name'\n",
    "df_blacklist_filtered = df[ship_df['sample_name']]\n",
    "\n",
    "# split the patients by tissue\n",
    "count_DCIS = df_blacklist_filtered.filter(like='_D')\n",
    "count_STROMA = df_blacklist_filtered.filter(like='_S')\n",
    "count_NORMAL = df_blacklist_filtered.filter(like='_N')\n",
    "\n",
    "vst_table = vst_norm[None] # we don't apply this anymore because it blocks any gene with >80% frac_zero\n",
    "DCIS_filtered_norm_count = count_NORMAL #[count_NORMAL.index.isin(vst_table.index)]\n",
    "DCIS_filtered_tumour_count = count_DCIS #[count_DCIS.index.isin(vst_table.index)]\n",
    "DCIS_filtered_stroma_count = count_STROMA #[count_STROMA.index.isin(vst_table.index)]\n",
    "\n",
    "count_DCIS = count_DCIS.rename(index=dict(zip(gene_convert[\"gene_id\"], gene_convert[\"gene_name\"])))\n",
    "count_STROMA = count_STROMA.rename(index=dict(zip(gene_convert[\"gene_id\"], gene_convert[\"gene_name\"])))\n",
    "count_NORMAL = count_NORMAL.rename(index=dict(zip(gene_convert[\"gene_id\"], gene_convert[\"gene_name\"])))\n",
    "\n",
    "\n",
    "filtered_norm_count_libadjust = library_adjust(DCIS_filtered_norm_count)\n",
    "fraction_of_zeroes = (filtered_norm_count_libadjust == 0).mean(axis=1)\n",
    "filtered_norm_count = filtered_norm_count_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "filtered_tumour_count_libadjust = library_adjust(DCIS_filtered_tumour_count)\n",
    "fraction_of_zeroes = (filtered_tumour_count_libadjust == 0).mean(axis=1)\n",
    "filtered_tumour_count = filtered_tumour_count_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n",
    "\n",
    "filtered_stroma_count_libadjust = library_adjust(DCIS_filtered_stroma_count)\n",
    "fraction_of_zeroes = (filtered_stroma_count_libadjust == 0).mean(axis=1)\n",
    "filtered_stroma_count = filtered_stroma_count_libadjust[fraction_of_zeroes < (1 - express_percent_limit)] # must be expressed to this percentage of patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24cf0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T23:43:49.812272Z",
     "iopub.status.busy": "2024-04-02T23:43:49.812039Z",
     "iopub.status.idle": "2024-04-02T23:58:59.275624Z",
     "shell.execute_reply": "2024-04-02T23:58:59.274913Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Our Data: Tumours\")\n",
    "DCIS_tum_data = segmental_aic_find(count_DCIS, \"/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/qq_plots/DCIS_tumour/\")\n",
    "gradual_aic_plot(DCIS_tum_data, \"DCIS_Precise_Tumours\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4dbf5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T23:58:59.280753Z",
     "iopub.status.busy": "2024-04-02T23:58:59.280519Z",
     "iopub.status.idle": "2024-04-03T00:13:35.401522Z",
     "shell.execute_reply": "2024-04-03T00:13:35.400831Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Our Data: Normal\")\n",
    "DCIS_norm_data = segmental_aic_find(count_NORMAL, \"/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/qq_plots/DCIS_normal/\")\n",
    "gradual_aic_plot(DCIS_norm_data, \"DCIS_Precise_Normal\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5014be0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T00:13:35.409489Z",
     "iopub.status.busy": "2024-04-03T00:13:35.409314Z",
     "iopub.status.idle": "2024-04-03T00:26:32.519764Z",
     "shell.execute_reply": "2024-04-03T00:26:32.519054Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Our Data: Stroma\")\n",
    "DCIS_stroma_data = segmental_aic_find(count_STROMA, , \"/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/qq_plots/DCIS_stroma/\")\n",
    "gradual_aic_plot(DCIS_stroma_data, \"DCIS_Precise_Stroma\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057fbf5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e29f38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T00:26:32.524969Z",
     "iopub.status.busy": "2024-04-03T00:26:32.524789Z",
     "iopub.status.idle": "2024-04-03T00:26:35.112651Z",
     "shell.execute_reply": "2024-04-03T00:26:35.112202Z"
    }
   },
   "outputs": [],
   "source": [
    "# lets plot all at the same time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a 5x2 grid of subplots\n",
    "fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(8, 12))  # Adjust figsize as needed\n",
    "x_values = [\"Top 25%\", \"25-50%\", \"50-75%\", \"75-100%\"]\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(2):\n",
    "        if (i == 0) & (j == 0):\n",
    "            data = DCIS_tum_data\n",
    "            title_text = \"DCIS-Precise: Tumour\"\n",
    "        elif (i == 0) & (j == 1):\n",
    "            data = DCIS_norm_data\n",
    "            title_text = \"DCIS-Precise: Normal\"\n",
    "        elif (i == 1) & (j == 0):\n",
    "            data = DCIS_stroma_data\n",
    "            title_text = \"DCIS-Precise: Stroma\"\n",
    "        elif (i == 1) & (j == 1):\n",
    "            data = GSE47462_tum_data\n",
    "            title_text = \"GSE47462: Tumour\"\n",
    "        elif (i == 2) & (j == 0):\n",
    "            data = GSE120795_tum_data\n",
    "            title_text = \"GSE120795: Normal\"\n",
    "        elif (i == 2) & (j == 1):\n",
    "            data = GSE146889_tum_data\n",
    "            title_text = \"GSE146889: Tumour\"\n",
    "        elif (i == 3) & (j == 0):\n",
    "            data = GSE167977_tumours_data\n",
    "            title_text = \"GSE167977: Tumour\"\n",
    "        elif (i == 3) & (j == 1):\n",
    "            data = GSE181466_data\n",
    "            title_text = \"GSE181466: Tumour\"\n",
    "        elif (i == 4) & (j == 0):\n",
    "            data = GSE209998_ffpe_data\n",
    "            title_text = \"GSE209998: Tumour\"\n",
    "        elif (i == 4) & (j == 1):\n",
    "            data = TMBC_tum_data\n",
    "            title_text = \"TMBC\"\n",
    "        \n",
    "        \n",
    "        # order is: add_vector_nb, add_vector_zinb, add_vector_zip, add_vector_poisson,\n",
    "        # add_vector_gaussian, add_vector_exp, sample_total\n",
    "        add_vector_nb = data[0]\n",
    "        add_vector_zinb = data[1]\n",
    "        add_vector_zip = data[2]\n",
    "        add_vector_poisson = data[3]\n",
    "        add_vector_gaussian = data[4]\n",
    "        add_vector_exp = data[5]\n",
    "        sample_total = data[6]\n",
    "    \n",
    "        fraction_nb = [x / y for x, y in zip(add_vector_nb, sample_total)]\n",
    "        fraction_zinb = [x / y for x, y in zip(add_vector_zinb, sample_total)]\n",
    "        fraction_exp = [x / y for x, y in zip(add_vector_exp, sample_total)]\n",
    "        fraction_zip = [x / y for x, y in zip(add_vector_zip, sample_total)]\n",
    "        fraction_gau = [x / y for x, y in zip(add_vector_gaussian, sample_total)]\n",
    "        fraction_poi = [x / y for x, y in zip(add_vector_poisson, sample_total)]\n",
    "\n",
    "        axs[i, j].plot(x_values, fraction_nb, marker='o', linestyle='-', label='NB')\n",
    "        axs[i, j].plot(x_values, fraction_zinb, marker='o', linestyle='-', label='ZINB')\n",
    "        axs[i, j].plot(x_values, fraction_exp, marker='o', linestyle='-', label='Exponential')\n",
    "        axs[i, j].plot(x_values, fraction_poi, marker='o', linestyle='-', label='Poisson')\n",
    "        axs[i, j].plot(x_values, fraction_zip, marker='o', linestyle='-', label='ZIP')\n",
    "        axs[i, j].plot(x_values, fraction_gau, marker='o', linestyle='-', label='Gaussian')\n",
    "        \n",
    "        axs[i, j].set_title(title_text, fontsize=10)\n",
    "        axs[i, j].legend(fontsize=6)\n",
    "        axs[i, j].set_xlabel('Genes Grouped by Overall Counts', fontsize=6)\n",
    "        axs[i, j].set_ylabel('% of Genes Best Fitting Distribution', fontsize=6)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/By_Expression_AIC_Plot.All.' +\n",
    "    \".ZeroFract_\" + str(express_percent_limit) + \".Trim_\" + str(trim_percent) + \".pdf\",\n",
    "        dpi=300, bbox_inches='tight')  # dpi is dots per inch, for resolution\n",
    "\n",
    "#plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4dbbde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T00:26:35.122014Z",
     "iopub.status.busy": "2024-04-03T00:26:35.121834Z",
     "iopub.status.idle": "2024-04-03T00:26:37.428071Z",
     "shell.execute_reply": "2024-04-03T00:26:37.427444Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(8, 12))  # Adjust figsize as needed\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(2):\n",
    "        if (i == 0) & (j == 0):\n",
    "            data = DCIS_tum_data\n",
    "            title_text = \"DCIS-Precise: Tumour\"\n",
    "        elif (i == 0) & (j == 1):\n",
    "            data = DCIS_norm_data\n",
    "            title_text = \"DCIS-Precise: Normal\"\n",
    "        elif (i == 1) & (j == 0):\n",
    "            data = DCIS_stroma_data\n",
    "            title_text = \"DCIS-Precise: Stroma\"\n",
    "        elif (i == 1) & (j == 1):\n",
    "            data = GSE47462_tum_data\n",
    "            title_text = \"GSE47462: Tumour\"\n",
    "        elif (i == 2) & (j == 0):\n",
    "            data = GSE120795_tum_data\n",
    "            title_text = \"GSE120795: Normal\"\n",
    "        elif (i == 2) & (j == 1):\n",
    "            data = GSE146889_tum_data\n",
    "            title_text = \"GSE146889: Tumour\"\n",
    "        elif (i == 3) & (j == 0):\n",
    "            data = GSE167977_tumours_data\n",
    "            title_text = \"GSE167977: Tumour\"\n",
    "        elif (i == 3) & (j == 1):\n",
    "            data = GSE181466_data\n",
    "            title_text = \"GSE181466: Tumour\"\n",
    "        elif (i == 4) & (j == 0):\n",
    "            data = GSE209998_ffpe_data\n",
    "            title_text = \"GSE209998: Tumour\"\n",
    "        elif (i == 4) & (j == 1):\n",
    "            data = TMBC_tum_data\n",
    "            title_text = \"The Metastatic Breast Cancer Project\"\n",
    "        \n",
    "        \n",
    "        # order is: add_vector_nb, add_vector_zinb, add_vector_zip, add_vector_poisson,\n",
    "        # add_vector_gaussian, add_vector_exp, sample_total\n",
    "        add_vector_nb = data[0]\n",
    "        add_vector_zinb = data[1]\n",
    "        add_vector_zip = data[2]\n",
    "        add_vector_poisson = data[3]\n",
    "        add_vector_gaussian = data[4]\n",
    "        add_vector_exp = data[5]\n",
    "        sample_total = data[6]\n",
    "        \n",
    "        sum_nb = add_vector_nb[0] + add_vector_nb[1]\n",
    "        sum_zinb = add_vector_zinb[0] + add_vector_zinb[1]\n",
    "        sum_exp = add_vector_exp[0] + add_vector_exp[1]\n",
    "        sum_zip = add_vector_zip[0] + add_vector_zip[1]\n",
    "        sum_gau = add_vector_gaussian[0] + add_vector_gaussian[1]\n",
    "        sum_poi = add_vector_poisson[0] + add_vector_poisson[1]\n",
    "    \n",
    "        print(title_text, sum_nb, sum_zinb, sum_exp, sum_poi, sum_zip, sum_gau)\n",
    "        pos = 6\n",
    "        bar_width = 0.1\n",
    "        categories = ('NB', 'ZINB', 'Exponential', 'Poisson', 'ZIP', 'Gaussian')\n",
    "        \n",
    "        # Create a bar for each set of values\n",
    "        axs[i, j].bar(pos, sum_nb, bar_width, label='NB')\n",
    "        axs[i, j].bar(pos + bar_width, sum_zinb, bar_width, label='ZINB')\n",
    "        axs[i, j].bar(pos + bar_width*2, sum_exp, bar_width, label='Exponential')\n",
    "        axs[i, j].bar(pos + bar_width*3, sum_poi, bar_width, label='Poisson')\n",
    "        axs[i, j].bar(pos + bar_width*4, sum_zip, bar_width, label='ZIP')\n",
    "        axs[i, j].bar(pos + bar_width*5, sum_gau, bar_width, label='Gaussian')\n",
    "\n",
    "        # Adding and formatting title and labels\n",
    "        axs[i, j].set_title(title_text, fontsize=10)\n",
    "        axs[i, j].legend(fontsize=6)\n",
    "        axs[i, j].set_xlabel('Distribution Types', fontsize=6)\n",
    "        axs[i, j].set_ylabel('No. Genes Best Fitting Distribution', fontsize=6)\n",
    "        tick_positions = [pos + bar_width * n for n in range(len(categories))]\n",
    "        axs[i, j].set_xticks(tick_positions)\n",
    "        axs[i, j].set_xticklabels(categories, fontsize=6)\n",
    "        \n",
    "plt.tight_layout()\n",
    "\n",
    "# saving plot\n",
    "\n",
    "plt.savefig('/path/to/6.2_Third_Party_Data.Best_AIC_vs_Expression_Level_Plot_Generator/By_Expression_AIC_BarPlot.All.' +\n",
    "    \".ZeroFract_\" + str(express_percent_limit) + \".Trim_\" + str(trim_percent) + \".pdf\",\n",
    "        dpi=300, bbox_inches='tight')  # dpi is dots per inch, for resolution\n",
    "\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d0953a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
