{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from matplotlib.patches import Rectangle, Patch\n",
    "\n",
    "\n",
    "sys.path.insert(0, '../4_preffect')\n",
    "from _config import configs\n",
    "from preffect_factory import factory\n",
    "import anndata as ad \n",
    "from _inference import( Inference )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "dataset_run = \"dataset_subtype_5\"\n",
    "\n",
    "def list_subfolders(directory):\n",
    "    subfolders = [entry.name for entry in os.scandir(directory) if entry.is_dir()]\n",
    "    return subfolders\n",
    "\n",
    "# created a sorting algorithm to ensure \"epoch_100\" is sorted after \"epoch_50\"\n",
    "def sort_key(s):\n",
    "    s = re.sub(r'\\s+', '', s)\n",
    "    # Extract the number from the folder name (assuming every folder name has the format 'test_<number>')\n",
    "    match = re.search(r'\\d+$', s)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return s\n",
    "\n",
    "folder_search = f'/path/to/{dataset_run}/testing_single/separate_latent'\n",
    "\n",
    "all_subfolders = sorted(list_subfolders(folder_search), reverse=False)\n",
    "\n",
    "#all_subfolders.sort(key=sort_key)\n",
    "\n",
    "#all_subfolders = all_subfolders[13:14]\n",
    "all_subfolders = all_subfolders[5:6]\n",
    "# 3 jumbled, 4 jumbled/nodrop, 5 nodrop, 6 Normal\n",
    "print(\"All sub-folders:\", all_subfolders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a specific run to this page. We are just interested in the first one, \n",
    "basic_M_1000_minibatch_200_epochs_1000_lr_0.001_lib_False_likelihood_NB_masking_MCAR_2_lambda_0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs['task'] = 'reinstate'\n",
    "\n",
    "pr_reinstate = {}\n",
    "pr_count = 0\n",
    "\n",
    "for dir_name in all_subfolders:\n",
    "\n",
    "    dir_name = re.sub(r'\\s+', '', dir_name)\n",
    "    full_path = folder_search + \"/\" + dir_name\n",
    "    configs['output_path'] = full_path\n",
    "    configs['cuda_device_num'] = 4\n",
    "    pr_reinstate[pr_count] = factory(task='reinstate', configs=configs, trigger_setup=True)\n",
    "    \n",
    "    #configs['input_inference_anndata_path'] = configs['input_anndata_path'] + 'test/' \n",
    "    #configs['task'] = 'impute_experiment'\n",
    "    #infy, error_masked, error_unmasked, df_subtype  = factory(task='impute_experiment', configs=configs, \n",
    "    #                                                preffect_obj=pr_reinstate, inference_key = 'endogenous',\n",
    "    #                                                error_type='mse')\n",
    "\n",
    "    configs['always_save'] = False\n",
    "\n",
    "\n",
    "    pr_count += 1\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_data = pr_reinstate[0]\n",
    "#print(pr_data.train_dataset.gene_names[965])\n",
    "\n",
    "# so position 965 is ERBB2 and 966 is ESR1\n",
    "configs_inf = pr_data.configs.copy()\n",
    "configs_inf['task'] = 'inference'\n",
    "inference_instance = Inference(pr_data, task='inference', inference_key = configs_inf['inference_key'], configs=configs_inf)\n",
    "inference_instance.run_inference()\n",
    "inference_instance.configs_inf['inference_key'] = 'endogenous'\n",
    "inference_instance.register_inference_run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((inference_instance.output['DAs'][0][0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pr_data.train_dataset.M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now cluster_counts works and only displays clustering on \\hat{mu}\n",
    "loop_count = 0\n",
    "for dir_name in all_subfolders:\n",
    "    print(dir_name)\n",
    "    factory(task='cluster_counts', preffect_obj=pr_reinstate[loop_count], inference_key='endogenous', trigger_setup=False, configs=configs)\n",
    "    loop_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_latent seems hardcoded for batch. Where does this happen?\n",
    "# fixed that, but now there's a problem with Leiden clustering\n",
    "\n",
    "configs['always_save'] = False\n",
    "loop_count = 0\n",
    "\n",
    "for dir_name in all_subfolders:\n",
    "    \n",
    "    print(dir_name)\n",
    "    factory(task='cluster_latent', preffect_obj=pr_reinstate[loop_count], inference_key='endogenous', trigger_setup=False, configs=configs)\n",
    "    loop_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets evaluate the Mu and Theta of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm having a weird rounding issue where it just randomly doesn't work\n",
    "def truncate_to_one_decimal(arr):\n",
    "    factor = 10  # 10^1 for one decimal place\n",
    "    return np.floor(arr * factor) / factor\n",
    "\n",
    "\n",
    "inf_reinstate = pr_reinstate[0].inference_dict['endogenous']\n",
    "var = inf_reinstate.parent.train_dataset.anndatas_orig[0].var\n",
    "#print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in P and R that generated\n",
    "# read PAM50 p and r file\n",
    "pam50_path = \"/path/to/9_Exploring_NB_In_PAM50/our_dcis.NB_PAM50.Median.Trim_5.Subtype.csv\"\n",
    "\n",
    "df = pd.read_csv(pam50_path)\n",
    "\n",
    "df_pivot = df.pivot_table(index='Gene', columns='Subtype', values=['p','r'], aggfunc='first')\n",
    "df_pivot.reset_index(inplace=True)\n",
    "df_pivot.columns = [' '.join(col).strip() for col in df_pivot.columns.values]\n",
    "\n",
    "#print(df_pivot)\n",
    "\n",
    "category_values_list, category_counts_list, category_omegas_list, category_true_omegas_list = [], [], [], []\n",
    "\n",
    "print(\"Gene Subtype GenMu MuHat(mean) MuHat(stdev)\")\n",
    "\n",
    "# Looping over each row\n",
    "for index, row in df_pivot.iterrows():\n",
    "    mus, thetas = {}, {}\n",
    "\n",
    "\n",
    "    p_basal = row['p Basal']\n",
    "    p_her2 = row['p Her2']\n",
    "    p_luma = row['p LumA']\n",
    "    p_lumb = row['p LumB']\n",
    "    p_normal = row['p Normal']\n",
    "\n",
    "    thetas['basal'] = row['r Basal']    \n",
    "    thetas['her2'] = row['r Her2']\n",
    "    thetas['luma'] = row['r LumA']\n",
    "    thetas['lumb'] = row['r LumB']\n",
    "    thetas['normal'] = row['r Normal']\n",
    "\n",
    "    # convert to p/r to mu (theta = r)\n",
    "    mus['basal'] = thetas['basal'] * (1 - p_basal) / p_basal\n",
    "    mus['her2'] = thetas['her2'] * (1 - p_her2) / p_her2\n",
    "    mus['luma'] = thetas['luma'] * (1 - p_luma) / p_luma\n",
    "    mus['lumb'] = thetas['lumb'] * (1 - p_lumb) / p_lumb\n",
    "    mus['normal'] = thetas['normal'] * (1 - p_normal) / p_normal\n",
    "\n",
    "    gene = row['Gene']\n",
    "\n",
    "    # the same information is in the AnnData input\n",
    "    model = 0\n",
    "    inf_reinstate = pr_reinstate[model].inference_dict['endogenous']\n",
    "    adata = inf_reinstate.return_counts_as_anndata()\n",
    "   \n",
    "    # continuing on, lets pull Mu/Theta for this gene\n",
    "    hat_mu = adata[0].X\n",
    "    hat_theta = adata[0].layers[\"X_hat_theta\"]\n",
    "    true_counts = adata[0].layers[\"original_counts\"]\n",
    "    \n",
    "    # lets convert true counts to omega\n",
    "    library_size = np.sum(true_counts, axis=1)\n",
    "\n",
    "    # Calculate omega (proportion of library size for each gene)\n",
    "    true_omega = true_counts / library_size[:, np.newaxis]\n",
    "        \n",
    "    omega = adata[0].layers[\"px_omega\"]\n",
    "    subtype = adata[0].obs['subtype']\n",
    "    gene_order = inf_reinstate.ds.gene_names\n",
    "\n",
    "    column_index = gene_order.index(gene)\n",
    "    gene_muhat = hat_mu[:, column_index]\n",
    "    gene_mutheta = hat_theta[:, column_index]\n",
    "\n",
    "    gene_truecounts = true_counts[:, column_index]\n",
    "\n",
    "    gene_omegas = omega[:, column_index]\n",
    "    gene_true_omegas = true_omega[:, column_index]\n",
    "\n",
    "    categories = subtype.cat.categories\n",
    "\n",
    "    # now I want to isolate the values based on the subtype in obs\n",
    "        \n",
    "    category_values = {category: gene_muhat[subtype == category] for category in categories}\n",
    "    category_counts = {category: gene_truecounts[subtype == category] for category in categories}\n",
    "    category_true_omega = {category: gene_true_omegas[subtype == category] for category in categories}\n",
    "    category_omegas = {category: gene_omegas[subtype == category] for category in categories}\n",
    "\n",
    "    category_values_list.append(category_values)\n",
    "    category_counts_list.append(category_counts)\n",
    "    category_omegas_list.append(category_omegas)\n",
    "    category_true_omegas_list.append(category_true_omega)\n",
    "\n",
    "\n",
    "    # Print the isolated values for each category\n",
    "    for category, values in category_values.items():\n",
    "\n",
    "        avg_mu_subtype = truncate_to_one_decimal(np.mean(values))\n",
    "        std_mu_subtype = truncate_to_one_decimal(np.std(values))\n",
    "\n",
    "        print(f\"{gene} {category} {np.round(mus[category], 1)} {avg_mu_subtype} {std_mu_subtype}\")\n",
    "        \n",
    "    # And again for true counts\n",
    "\n",
    "    for category, values in category_counts.items():\n",
    "\n",
    "        avg_mu_subtype = truncate_to_one_decimal(np.mean(values))\n",
    "        std_mu_subtype = truncate_to_one_decimal(np.std(values))\n",
    "\n",
    "        #print(f\"{gene} {category} {np.round(mus[category], 1)} {avg_mu_subtype} {std_mu_subtype}\")\n",
    "    #break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_mu, df_list_count, df_list_omega, df_list_true_omega = [], [], [], []\n",
    "\n",
    "# Loop over categories to create DataFrames\n",
    "for category in categories:\n",
    "    category_values = {gene: category_values_list[i][category] for i, gene in enumerate(df_pivot['Gene'])}\n",
    "    df = pd.DataFrame(category_values)\n",
    "    df['category'] = category\n",
    "    df_list_mu.append(df)\n",
    "\n",
    "    category_counts = {gene: category_counts_list[i][category] for i, gene in enumerate(df_pivot['Gene'])}\n",
    "    df = pd.DataFrame(category_counts)\n",
    "    df['category'] = category\n",
    "    df_list_count.append(df)\n",
    "\n",
    "    category_omegas = {gene: category_omegas_list[i][category] for i, gene in enumerate(df_pivot['Gene'])}\n",
    "    df = pd.DataFrame(category_omegas)\n",
    "    df['category'] = category\n",
    "    df_list_omega.append(df)\n",
    "\n",
    "    category_true_omegas = {gene: category_true_omegas_list[i][category] for i, gene in enumerate(df_pivot['Gene'])}\n",
    "    df = pd.DataFrame(category_true_omegas)\n",
    "    df['category'] = category\n",
    "    df_list_true_omega.append(df)\n",
    "\n",
    "all_category_values_df = pd.concat(df_list_mu)\n",
    "all_category_counts_df = pd.concat(df_list_count)\n",
    "all_category_omegas_df = pd.concat(df_list_omega)\n",
    "all_category_true_omegas_df = pd.concat(df_list_true_omega)\n",
    "\n",
    "# remove last column and normalize the data\n",
    "# originally using Z-Score, but that's for normal; switch to min-max scaling?\n",
    "\n",
    "category_order = all_category_values_df.pop(all_category_values_df.columns[-1])\n",
    "#normalized_data = all_category_values_df.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "normalized_data = (all_category_values_df - all_category_values_df.min()) / (all_category_values_df.max() - all_category_values_df.min())\n",
    "normalized_data = normalized_data.transpose()\n",
    "\n",
    "# the input counts\n",
    "category_order_counts = all_category_counts_df.pop(all_category_counts_df.columns[-1])\n",
    "#normalized_count_data = all_category_counts_df.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "normalized_count_data = (all_category_counts_df - all_category_counts_df.min()) / (all_category_counts_df.max() - all_category_counts_df.min())\n",
    "normalized_count_data = normalized_count_data.transpose()\n",
    "\n",
    "# true omegas\n",
    "# normalization for omegas: Min/Max scaling (best for continous data between 0,1)\n",
    "category_order = all_category_true_omegas_df.pop(all_category_true_omegas_df.columns[-1])\n",
    "#normalized_true_omega_data = all_category_true_omegas_df.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "normalized_true_omega_data = (all_category_true_omegas_df - all_category_true_omegas_df.min()) / (all_category_true_omegas_df.max() - all_category_true_omegas_df.min())\n",
    "normalized_true_omega_data = normalized_true_omega_data.transpose()\n",
    "all_category_true_omegas_df = all_category_true_omegas_df.transpose()\n",
    "\n",
    "# hat omegas\n",
    "category_order = all_category_omegas_df.pop(all_category_omegas_df.columns[-1])\n",
    "# normalized_omega_data = all_category_omegas_df.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "# min-max scaling\n",
    "normalized_omega_data = (all_category_omegas_df - all_category_omegas_df.min()) / (all_category_omegas_df.max() - all_category_omegas_df.min())\n",
    "\n",
    "normalized_omega_data = normalized_omega_data.transpose()\n",
    "all_category_omegas_df = all_category_omegas_df.transpose()\n",
    "\n",
    "print(normalized_omega_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.patches import Rectangle, Patch\n",
    "\n",
    "\n",
    "category_colors = {\n",
    "    'basal': 'blue',\n",
    "    'her2': 'orange',\n",
    "    'luma': 'green',\n",
    "    'lumb': 'red',\n",
    "    'normal': 'purple',\n",
    "}\n",
    "\n",
    "# Map the vector categories to colors\n",
    "category_bar = category_order.map(category_colors)\n",
    "white_red_cmap = LinearSegmentedColormap.from_list('white_red', ['white', 'darkred'])\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(3, 8))\n",
    "ax = sns.heatmap(normalized_data, cmap=white_red_cmap, cbar=True, xticklabels=True, yticklabels=True)\n",
    "\n",
    "# Add the category bar\n",
    "for idx, color in enumerate(category_bar):\n",
    "    ax.add_patch(Rectangle((idx, len(normalized_data)), 1, 1, color=color, transform=ax.transData, clip_on=False))\n",
    "    \n",
    "legend_patches = [Patch(color=color, label=category) for category, color in category_colors.items()]\n",
    "ax.legend(handles=legend_patches, title='Categories', loc='upper right', bbox_to_anchor=(1.07, 1))\n",
    "\n",
    "# Adjust the plot to fit the category bar\n",
    "plt.subplots_adjust(bottom=0.0)\n",
    "plt.subplots_adjust(right=4)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(r'$\\hat{\\mu}$ Heatmap [Normalized]')\n",
    "#plt.xlabel('Patients')\n",
    "plt.ylabel('Genes')\n",
    "plt.xticks([])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make another heatmap but for counts\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(3, 8))\n",
    "ax = sns.heatmap(normalized_count_data, cmap=white_red_cmap, cbar=True, xticklabels=True, yticklabels=True)\n",
    "\n",
    "# Add the category bar\n",
    "for idx, color in enumerate(category_bar):\n",
    "    ax.add_patch(Rectangle((idx, len(normalized_count_data)), 1, 1, color=color, transform=ax.transData, clip_on=False))\n",
    "    \n",
    "legend_patches = [Patch(color=color, label=category) for category, color in category_colors.items()]\n",
    "ax.legend(handles=legend_patches, title='Categories', loc='upper right', bbox_to_anchor=(1.07, 1))\n",
    "\n",
    "# Adjust the plot to fit the category bar\n",
    "plt.subplots_adjust(bottom=0.0)\n",
    "plt.subplots_adjust(right=4)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(r'True Counts (Input Data) Heatmap [Normalized]')\n",
    "#plt.xlabel('Patients')\n",
    "plt.ylabel('Genes')\n",
    "plt.xticks([])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAM50genes = [\n",
    "    \"EGFR\",    \"CDH3\",\n",
    "    \"PHGDH\",    \"ACTR3B\",\n",
    "    \"FOXC1\",    \"MIA\",\n",
    "    \"MYC\",    \"FGFR4\",\n",
    "    \"MDM2\",    \"MLPH\",\n",
    "    \"KRT14\",    \"BCL2\",\n",
    "    \"SFRP1\",    \"KRT5\",\n",
    "    \"KRT17\",    \"SLC39A6\",\n",
    "    \"ESR1\",    \"CXXC5\",\n",
    "    \"BLVRA\",    \"FOXA1\",\n",
    "    \"GPR160\",    \"NAT1\",\n",
    "    \"MAPT\",    \"PGR\",\n",
    "    \"BAG1\",    \"TMEM45B\",\n",
    "    \"ERBB2\",    \"GRB7\",\n",
    "    \"MMP11\",    \"CDC20\",\n",
    "    \"MKI67\",    \"CCNE1\",\n",
    "    \"CENPF\",    \"NUF2\",\n",
    "    \"EXO1\",    \"KIF2C\",\n",
    "    \"ORC6\",    \"ANLN\",\n",
    "    \"CDC6\",    \"RRM2\",\n",
    "    \"UBE2T\",    \"NDC80\",\n",
    "    \"CEP55\",    \"MELK\",\n",
    "    \"TYMS\",    \"CCNB1\",\n",
    "    \"BIRC5\",    \"MYBL2\",\n",
    "    \"PTTG1\",    \"UBE2C\",\n",
    "]\n",
    "\n",
    "# re-arrange the gene order to match PAM50\n",
    "normalized_true_omega_data_re = pd.DataFrame(normalized_true_omega_data, index=PAM50genes).iloc[::-1]\n",
    "\n",
    "normalized_omega_data_re = pd.DataFrame(normalized_omega_data, index=PAM50genes).iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot the True/PREFFECT omegas side by side\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle, Patch\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 8))  # Adjust figsize as needed\n",
    "\n",
    "# Plot the first heatmap\n",
    "ax1 = sns.heatmap(\n",
    "    normalized_true_omega_data_re,\n",
    "    cmap=white_red_cmap,\n",
    "    cbar=False,\n",
    "    xticklabels=True,\n",
    "    yticklabels=True,\n",
    "    ax=axes[0]\n",
    ")\n",
    "\n",
    "# Add the category bar to the first heatmap\n",
    "for idx, color in enumerate(category_bar):\n",
    "    ax1.add_patch(Rectangle((idx, len(normalized_true_omega_data_re)), 1, 1, color=color, transform=ax1.transData, clip_on=False))\n",
    "\n",
    "# Add legend to the first heatmap\n",
    "legend_patches = [Patch(color=color, label=category) for category, color in category_colors.items()]\n",
    "#ax1.legend(handles=legend_patches, title='Categories', loc='upper right', bbox_to_anchor=(1.07, 1))\n",
    "\n",
    "# Set title and labels for the first heatmap\n",
    "ax1.set_title(r'Observed $\\Omega$ of Input Data [Min/Max Norm.]')\n",
    "ax1.set_ylabel('Genes')\n",
    "ax1.set_xticks([])\n",
    "\n",
    "# Plot the second heatmap\n",
    "ax2 = sns.heatmap(\n",
    "    normalized_omega_data_re,  \n",
    "    cmap=white_red_cmap,\n",
    "    cbar=True,\n",
    "    xticklabels=True,\n",
    "    yticklabels=True,\n",
    "    ax=axes[1]\n",
    ")\n",
    "for idx, color in enumerate(category_bar):\n",
    "    ax2.add_patch(Rectangle((idx, len(normalized_omega_data_re)), 1, 1, color=color, transform=ax2.transData, clip_on=False))\n",
    "\n",
    "# Add legend to the second heatmap\n",
    "ax2.legend(handles=legend_patches, title='Categories', loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "\n",
    "# Set title and labels for the second heatmap\n",
    "plt.title(r'$\\Omega$ of PREFFECT Model [Min/Max Norm.]')# Replace with an appropriate title\n",
    "ax2.set_ylabel('Genes')\n",
    "ax2.set_xticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot the True/PREFFECT omegas side by side\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 8))  # Adjust figsize as needed\n",
    "\n",
    "# Plot the first heatmap\n",
    "ax1 = sns.heatmap(\n",
    "    normalized_count_data,\n",
    "    cmap=white_red_cmap,\n",
    "    cbar=False,\n",
    "    xticklabels=True,\n",
    "    yticklabels=True,\n",
    "    ax=axes[0]\n",
    ")\n",
    "\n",
    "# Add the category bar to the first heatmap\n",
    "for idx, color in enumerate(category_bar):\n",
    "    ax1.add_patch(Rectangle((idx, len(normalized_count_data)), 1, 1, color=color, transform=ax1.transData, clip_on=False))\n",
    "\n",
    "# Add legend to the first heatmap\n",
    "legend_patches = [Patch(color=color, label=category) for category, color in category_colors.items()]\n",
    "#ax1.legend(handles=legend_patches, title='Categories', loc='upper right', bbox_to_anchor=(1.07, 1))\n",
    "\n",
    "# Set title and labels for the first heatmap\n",
    "ax1.set_title(r'Observed Counts of Input Data [Min/Max Norm.]')\n",
    "ax1.set_ylabel('Genes')\n",
    "ax1.set_xticks([])\n",
    "\n",
    "# Plot the second heatmap\n",
    "ax2 = sns.heatmap(\n",
    "    normalized_data,  \n",
    "    cmap=white_red_cmap,\n",
    "    cbar=True,\n",
    "    xticklabels=True,\n",
    "    yticklabels=True,\n",
    "    ax=axes[1]\n",
    ")\n",
    "for idx, color in enumerate(category_bar):\n",
    "    ax2.add_patch(Rectangle((idx, len(normalized_data)), 1, 1, color=color, transform=ax2.transData, clip_on=False))\n",
    "\n",
    "# Add legend to the second heatmap\n",
    "ax2.legend(handles=legend_patches, title='Categories', loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "\n",
    "# Set title and labels for the second heatmap\n",
    "plt.title(r'$\\hat{\\mu}$ of PREFFECT Model [Min/Max Norm.]')# Replace with an appropriate title\n",
    "ax2.set_ylabel('Genes')\n",
    "ax2.set_xticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "### edge comparison\n",
    "pr_of_interest = pr_reinstate[0]\n",
    "\n",
    "#print(pr_of_interest.train_dataset.As_mask)\n",
    "#print(pr_of_interest.train_dataset.anndatas_orig[0].obs['subtype'])\n",
    "# yeah I can see the edges that line up to subtype in this dataset\n",
    "\n",
    "# so what does it look like after being learned\n",
    "inf = pr_of_interest.inference_dict['endogenous']\n",
    "\n",
    "print(torch.min(inf.output['DAs'][0][0]).item(), torch.max(inf.output['DAs'][0][0]).item(), inf.output['DAs'][0][0].shape)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot the first heatmap\n",
    "im1 = axes[0].imshow(inf.ds.As_orig[0].cpu().float(), cmap='viridis')\n",
    "axes[0].set_title('True S-S Edges')\n",
    "fig.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Plot the second heatmap\n",
    "im2 = axes[1].imshow(inf.output['DAs'][0][0].cpu().detach().float(), cmap='viridis')\n",
    "axes[1].set_title('Recon DAs')\n",
    "fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffpe_env_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
